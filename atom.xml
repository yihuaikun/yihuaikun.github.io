<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://yihuaikun.github.io</id>
    <title>向java工程师迈进</title>
    <updated>2019-12-12T13:03:34.990Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://yihuaikun.github.io"/>
    <link rel="self" href="https://yihuaikun.github.io/atom.xml"/>
    <subtitle>温故而知新</subtitle>
    <logo>https://yihuaikun.github.io/images/avatar.png</logo>
    <icon>https://yihuaikun.github.io/favicon.ico</icon>
    <rights>All rights reserved 2019, 向java工程师迈进</rights>
    <entry>
        <title type="html"><![CDATA[接入阿里大于短信服务]]></title>
        <id>https://yihuaikun.github.io/post/jie-ru-a-li-da-yu-duan-xin-fu-wu</id>
        <link href="https://yihuaikun.github.io/post/jie-ru-a-li-da-yu-duan-xin-fu-wu">
        </link>
        <updated>2019-12-12T12:35:11.000Z</updated>
        <content type="html"><![CDATA[<p><a href="https://blog.csdn.net/cool_summer_moon/article/details/53648093">阿里云大于短信服务开发</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Solr]]></title>
        <id>https://yihuaikun.github.io/post/solr</id>
        <link href="https://yihuaikun.github.io/post/solr">
        </link>
        <updated>2019-12-12T12:30:07.000Z</updated>
        <content type="html"><![CDATA[<h1 id="1-solr入门">1. Solr入门</h1>
<h2 id="11-solr下载安装">1.1. Solr下载安装</h2>
<p>官方下载地址：https://archive.apache.org/dist/lucene/solr/</p>
<p>Windows系统下载zip包，Linux、MaxOS系统下载tgz包</p>
<figure data-type="image" tabindex="1"><img src="https://img-blog.csdnimg.cn/20191207115834376.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzg2MjI4MA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></figure>
<h2 id="111-solr目录结构">1.1.1. Solr目录结构</h2>
<p>[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-WoPP5VHl-1575691051854)(solr-folder.png)]</p>
<ul>
<li>bin： 存放solr的可执行文件</li>
<li>contrib： 存放solr提供的扩展包</li>
<li>dist: Solr运行需要的jar包</li>
<li>docs: 文档目录</li>
<li>example: 官方提供的示例目录，配合官方示例教程，体验Solr功能</li>
<li>licences: 协议目录</li>
<li>server: solr工作的主目录，里面有默认的配置，将来创建的核心也会默认存储到此目录下，Solr Admin程序也在此目录下</li>
</ul>
<h2 id="12-solr入门">1.2. Solr入门</h2>
<h3 id="121-运行官方示例项目">1.2.1. 运行官方示例项目</h3>
<p>官方示例教程文档： https://lucene.apache.org/solr/guide/8_2/solr-tutorial.html</p>
<p>官方提供了三个示例教程，从Solr怎么简单使用，到怎么创建自己的搜索库，一步一步有引导，推荐跟着练习一遍。</p>
<h3 id="122-solr-admin-ui的使用">1.2.2. Solr Admin UI的使用</h3>
<p>Solr Admin是Solr给我们提供的一个方便查询和管理Solr的Web控制台应用，通过此应用，我们不需要编写任何程序就可以对Solr的很多功能进行操作。</p>
<p>默认访问地址： http://localhost:8983/solr</p>
<figure data-type="image" tabindex="2"><img src="https://img-blog.csdnimg.cn/2019120711592061.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzg2MjI4MA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></figure>
<h4 id="1221-简单查询">1.2.2.1. 简单查询</h4>
<h4 id="1222-按照某个字段搜索">1.2.2.2. 按照某个字段搜索</h4>
<h4 id="1223-搜索短语">1.2.2.3. 搜索短语</h4>
<h4 id="1224-搜索结果中只返回某些字段">1.2.2.4. 搜索结果中只返回某些字段</h4>
<h4 id="1225-搜索结果分页">1.2.2.5. 搜索结果分页</h4>
<figure data-type="image" tabindex="3"><img src="https://img-blog.csdnimg.cn/20191207115940813.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzg2MjI4MA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></figure>
<h4 id="1226-搜索结果高亮显示">1.2.2.6. 搜索结果高亮显示</h4>
<p>搜索参数设置：<br>
<img src="https://img-blog.csdnimg.cn/20191207115958930.png" alt="在这里插入图片描述"></p>
<p>搜索结果展示：</p>
<h4 id="1227-删除solr索引库中的数据">1.2.2.7. 删除Solr索引库中的数据</h4>
<figure data-type="image" tabindex="4"><img src="https://img-blog.csdnimg.cn/20191207120017879.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzg2MjI4MA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></figure>
<h1 id="2-深入solr">2. 深入Solr</h1>
<h2 id="21-solr配置文件">2.1. Solr配置文件</h2>
<h3 id="211-managed-schema文件">2.1.1. managed-schema文件</h3>
<p>managed-schema文件是Solr中core或collection的搜索库定义配置文件，里面配置了搜索库有哪些Field和FieldType等。</p>
<p>Solr的工作流程大体如下：</p>
<ul>
<li>创建用于存储被搜索数据的core或collection(集群模式)；</li>
<li>定义创建的core有哪些字段，以及哪些字段需要索引、哪些字段只存储，不需要索引。具体来说，就是通过Solr提供的SchemaAPI去管理core中的字段；</li>
<li>将数据导入到Solr中，在此过程中，Solr会对导入的数据建索引（所以一定要先定义Schema字段，再导入数据）；</li>
<li>调用Solr的HttpAPI搜索数据</li>
</ul>
<blockquote>
<p>managed-schema文件就是用来管理某个core中有哪些字段或者字段类型，可以把Solr当成是一个数据库，里面有字段、有字段类型、能存储、能查询（搜索）</p>
</blockquote>
<h4 id="2111-solr中常用的数据类型">2.1.1.1. Solr中常用的数据类型</h4>
<p>Solr中主要的数据类型由实现类和类型定义两部分组成， 数据类型是由Solr中定义好的Java类，类型定义是在managed-schema文件中定义的，数据类型不能直接使用，必须在managed-schema中定义后才能直接在字段中引用。</p>
<p>在managed-schema中定义字段类型时，会将数据类型和其他属性（如：是否多值、是否存储）组合到一起</p>
<p>默认的managed-schema配置文件中已经定义了一些常用的数据类型，如</p>
<pre><code class="language-xml">&lt;fieldType name=&quot;string&quot; class=&quot;solr.StrField&quot; sortMissingLast=&quot;true&quot; docValues=&quot;true&quot; /&gt;
&lt;fieldType name=&quot;strings&quot; class=&quot;solr.StrField&quot; sortMissingLast=&quot;true&quot; multiValued=&quot;true&quot; docValues=&quot;true&quot; /&gt;
&lt;fieldType name=&quot;boolean&quot; class=&quot;solr.BoolField&quot; sortMissingLast=&quot;true&quot;/&gt;
&lt;fieldType name=&quot;booleans&quot; class=&quot;solr.BoolField&quot; sortMissingLast=&quot;true&quot; multiValued=&quot;true&quot;/&gt;
&lt;fieldType name=&quot;pint&quot; class=&quot;solr.IntPointField&quot; docValues=&quot;true&quot;/&gt;
&lt;fieldType name=&quot;pfloat&quot; class=&quot;solr.FloatPointField&quot; docValues=&quot;true&quot;/&gt;
&lt;fieldType name=&quot;plong&quot; class=&quot;solr.LongPointField&quot; docValues=&quot;true&quot;/&gt;
&lt;fieldType name=&quot;pdouble&quot; class=&quot;solr.DoublePointField&quot; docValues=&quot;true&quot;/&gt;

&lt;fieldType name=&quot;pints&quot; class=&quot;solr.IntPointField&quot; docValues=&quot;true&quot; multiValued=&quot;true&quot;/&gt;
&lt;fieldType name=&quot;pfloats&quot; class=&quot;solr.FloatPointField&quot; docValues=&quot;true&quot; multiValued=&quot;true&quot;/&gt;
&lt;fieldType name=&quot;plongs&quot; class=&quot;solr.LongPointField&quot; docValues=&quot;true&quot; multiValued=&quot;true&quot;/&gt;
&lt;fieldType name=&quot;pdoubles&quot; class=&quot;solr.DoublePointField&quot; docValues=&quot;true&quot; multiValued=&quot;true&quot;/&gt;
&lt;fieldType name=&quot;random&quot; class=&quot;solr.RandomSortField&quot; indexed=&quot;true&quot;/&gt;
&lt;fieldType name=&quot;pdate&quot; class=&quot;solr.DatePointField&quot; docValues=&quot;true&quot;/&gt;
&lt;fieldType name=&quot;pdates&quot; class=&quot;solr.DatePointField&quot; docValues=&quot;true&quot; multiValued=&quot;true&quot;/&gt;
&lt;fieldType name=&quot;binary&quot; class=&quot;solr.BinaryField&quot;/&gt;
</code></pre>
<p>可以看到每个字段类型定义都由类型的实现类和若干个其他属性组合而成</p>
<p>除了上面定义的简单类型之外默认的managed-schema文件中还定义了一些特殊的字段类型</p>
<pre><code class="language-xml">&lt;!-- ignored类型本身是一个StrField类型，但是将stored和indexed都定义成了false，代表不存储、不建索引，实际上就是忽略数据中的此字段不处理 --&gt;
&lt;fieldType name=&quot;ignored&quot; stored=&quot;false&quot; indexed=&quot;false&quot; multiValued=&quot;true&quot; class=&quot;solr.StrField&quot; /&gt;
</code></pre>
<p>带分词功能的字段类型</p>
<pre><code class="language-xml">&lt;!-- text_general类型和上面的字段类型定义语法一样，本身数据solr.TextField类型，但是声明时通过内部的子标签指定了数据存储索引和数据搜索索引的分词器 --&gt;
&lt;fieldType name=&quot;text_general&quot; class=&quot;solr.TextField&quot; positionIncrementGap=&quot;100&quot; multiValued=&quot;true&quot;&gt;
    &lt;analyzer type=&quot;index&quot;&gt;
        &lt;tokenizer class=&quot;solr.StandardTokenizerFactory&quot;/&gt;
        &lt;filter class=&quot;solr.StopFilterFactory&quot; ignoreCase=&quot;true&quot; words=&quot;stopwords.txt&quot; /&gt;
        &lt;!-- in this example, we will only use synonyms at query time
        &lt;filter class=&quot;solr.SynonymGraphFilterFactory&quot; synonyms=&quot;index_synonyms.txt&quot; ignoreCase=&quot;true&quot; expand=&quot;false&quot;/&gt;
        &lt;filter class=&quot;solr.FlattenGraphFilterFactory&quot;/&gt;
        --&gt;
        &lt;filter class=&quot;solr.LowerCaseFilterFactory&quot;/&gt;
    &lt;/analyzer&gt;
    &lt;analyzer type=&quot;query&quot;&gt;
        &lt;tokenizer class=&quot;solr.StandardTokenizerFactory&quot;/&gt;
        &lt;filter class=&quot;solr.StopFilterFactory&quot; ignoreCase=&quot;true&quot; words=&quot;stopwords.txt&quot; /&gt;
        &lt;filter class=&quot;solr.SynonymGraphFilterFactory&quot; synonyms=&quot;synonyms.txt&quot; ignoreCase=&quot;true&quot; expand=&quot;true&quot;/&gt;
        &lt;filter class=&quot;solr.LowerCaseFilterFactory&quot;/&gt;
    &lt;/analyzer&gt;
&lt;/fieldType&gt;
</code></pre>
<h4 id="2112-添加字段类型定义fieldtype">2.1.1.2. 添加字段类型定义(FieldType)</h4>
<p>我们添加自定义字段类型的一个重要应用场景就是当我们的字段需要支持中文分词时，指定字段的实现类型是</p>
<p>solr.TextField，然后指定数据存储索引和搜索的索引分词器为支持中文的分词器。</p>
<p>语法参见上一章节 带分词功能的字段类型，中文分词器的配置参见配置中文分词器章节</p>
<h4 id="2113-solr中的无模式模式和字段类型自动推测">2.1.1.3. Solr中的&quot;无模式&quot;模式和字段类型自动推测</h4>
<p>我们在将数据导入到Solr中时，如果事先没有添加字段，Solr会根据数据的内容，自动推测应该用什么字段类型，并且自动生成field配置标签到当前core对应的managed-schema配置文件中</p>
<h4 id="2114-添加字段field">2.1.1.4. 添加字段(Field)</h4>
<p>前面说过managed-schema中主要就是定义了fieldType和field， 在以前老版本的solr中managed-schema的名字叫做schema.xml，可以直接手动编辑文件维护其中的字段定义。</p>
<p>而在新版本的Solr中，官方不建议手动修改此文件，改用Schema API的方式来维护字段</p>
<p>配置示例</p>
<pre><code class="language-xml">&lt;field name=&quot;price&quot; type=&quot;float&quot; default=&quot;0.0&quot; indexed=&quot;true&quot; stored=&quot;true&quot;/&gt;
</code></pre>
<p>定义字段需要指定字段的名称、类型(引用上面声明的fieldType的名称)、默认值、是否存储、是否索引等。</p>
<h4 id="2115-添加拷贝字段copy-field">2.1.1.5. 添加拷贝字段(Copy Field)</h4>
<p>Solr支持通过配置Copy Field，将多个字段拷贝到某个字段上，这样在搜索时，可以只用一个字段实现同时搜索多个字段内容的效果。</p>
<p>配置示例</p>
<pre><code class="language-xml">&lt;copyField source=&quot;cat&quot; dest=&quot;text&quot; maxChars=&quot;30000&quot; /&gt;
</code></pre>
<h4 id="2116-动态字段dynamic-fields">2.1.1.6. 动态字段(Dynamic Fields)</h4>
<p>Solr可以通过配置动态字段来实现对某些名称相似的字段统一管理，因为动态字段定义时名称中允许包含通配符。</p>
<p>动态字段和普通字段作用一致，唯一不同的就是名称中允许包含通配符，Solr在索引数据时会优先查找配置中定义的准确字段(通过field配置的字段)，如果没有找到匹配的，就从动态字段中找是否有匹配的，如果找到，就用动态字段的字段定义来索引数据。</p>
<p>配置示例</p>
<pre><code class="language-xml">&lt;dynamicField name=&quot;*_i&quot; type=&quot;int&quot; indexed=&quot;true&quot;  stored=&quot;true&quot;/&gt;
</code></pre>
<h3 id="212-schema-api">2.1.2. Schema API</h3>
<p>为了减少手动编辑managed-schema文件引入的错误，新版本的Solr提供了一套基于HTTP协议的Schema API来维护managed-schema文件</p>
<p>Schema API可以完成以下操作</p>
<h4 id="2121-add-field">2.1.2.1. add-field</h4>
<p>使用示例</p>
<pre><code class="language-bash">curl -X POST -H 'Content-type:application/json' --data-binary '{
  &quot;add-field&quot;:{
     &quot;name&quot;:&quot;sell_by&quot;,
     &quot;type&quot;:&quot;pdate&quot;,
     &quot;stored&quot;:true }
}' http://localhost:8983/api/cores/gettingstarted/schema
</code></pre>
<h4 id="2122-delete-field">2.1.2.2. delete-field</h4>
<p>使用示例</p>
<pre><code class="language-bash">curl -X POST -H 'Content-type:application/json' --data-binary '{
  &quot;delete-field&quot; : { &quot;name&quot;:&quot;sell_by&quot; }
}' http://localhost:8983/api/cores/gettingstarted/schema
</code></pre>
<h4 id="2123-replace-field">2.1.2.3. replace-field</h4>
<p>使用示例</p>
<pre><code class="language-bash">curl -X POST -H 'Content-type:application/json' --data-binary '{
  &quot;replace-field&quot;:{
     &quot;name&quot;:&quot;sell_by&quot;,
     &quot;type&quot;:&quot;date&quot;,
     &quot;stored&quot;:false }
}' http://localhost:8983/api/cores/gettingstarted/schema

</code></pre>
<h4 id="2124-add-dynamic-field">2.1.2.4. add-dynamic-field</h4>
<p>使用示例</p>
<pre><code class="language-bash">curl -X POST -H 'Content-type:application/json' --data-binary '{
  &quot;add-dynamic-field&quot;:{
     &quot;name&quot;:&quot;*_s&quot;,
     &quot;type&quot;:&quot;string&quot;,
     &quot;stored&quot;:true }
}' http://localhost:8983/api/cores/gettingstarted/schema

</code></pre>
<h4 id="2125-delete-dynamic-field">2.1.2.5. delete-dynamic-field</h4>
<p>使用示例</p>
<pre><code class="language-bash">curl -X POST -H 'Content-type:application/json' --data-binary '{
  &quot;delete-dynamic-field&quot;:{ &quot;name&quot;:&quot;*_s&quot; }
}' http://localhost:8983/api/cores/gettingstarted/schema

</code></pre>
<h4 id="2126-replace-dynamic-field">2.1.2.6. replace-dynamic-field</h4>
<p>使用示例</p>
<pre><code class="language-bash">curl -X POST -H 'Content-type:application/json' --data-binary '{
  &quot;replace-dynamic-field&quot;:{
     &quot;name&quot;:&quot;*_s&quot;,
     &quot;type&quot;:&quot;text_general&quot;,
     &quot;stored&quot;:false }
}' http://localhost:8983/solr/gettingstarted/schema

</code></pre>
<h4 id="2127-add-field-type">2.1.2.7. add-field-type</h4>
<p>使用示例</p>
<pre><code class="language-bash">curl -X POST -H 'Content-type:application/json' --data-binary '{
  &quot;add-field-type&quot;:{
     &quot;name&quot;:&quot;myNewTextField&quot;,
     &quot;class&quot;:&quot;solr.TextField&quot;,
     &quot;indexAnalyzer&quot;:{
        &quot;tokenizer&quot;:{
           &quot;class&quot;:&quot;solr.PathHierarchyTokenizerFactory&quot;,
           &quot;delimiter&quot;:&quot;/&quot; }},
     &quot;queryAnalyzer&quot;:{
        &quot;tokenizer&quot;:{
           &quot;class&quot;:&quot;solr.KeywordTokenizerFactory&quot; }}}
}' http://localhost:8983/api/cores/gettingstarted/schema

</code></pre>
<h4 id="2128-delete-field-type">2.1.2.8. delete-field-type</h4>
<p>使用示例</p>
<pre><code class="language-bash">curl -X POST -H 'Content-type:application/json' --data-binary '{
  &quot;delete-field-type&quot;:{ &quot;name&quot;:&quot;myNewTxtField&quot; }
}' http://localhost:8983/api/cores/gettingstarted/schema

</code></pre>
<h4 id="2129-replace-field-type">2.1.2.9. replace-field-type</h4>
<p>使用示例</p>
<pre><code class="language-bash">curl -X POST -H 'Content-type:application/json' --data-binary '{
  &quot;replace-field-type&quot;:{
     &quot;name&quot;:&quot;myNewTxtField&quot;,
     &quot;class&quot;:&quot;solr.TextField&quot;,
     &quot;positionIncrementGap&quot;:&quot;100&quot;,
     &quot;analyzer&quot;:{
        &quot;tokenizer&quot;:{
           &quot;class&quot;:&quot;solr.StandardTokenizerFactory&quot; }}}
}' http://localhost:8983/api/cores/gettingstarted/schema

</code></pre>
<h4 id="21210-add-copy-field">2.1.2.10. add-copy-field</h4>
<p>使用示例</p>
<pre><code class="language-bash">curl -X POST -H 'Content-type:application/json' --data-binary '{
  &quot;add-copy-field&quot;:{
     &quot;source&quot;:&quot;shelf&quot;,
     &quot;dest&quot;:[ &quot;location&quot;, &quot;catchall&quot; ]}
}' http://localhost:8983/api/cores/gettingstarted/schema

</code></pre>
<h4 id="21211-delete-copy-field">2.1.2.11. delete-copy-field</h4>
<p>使用示例</p>
<pre><code class="language-bash">curl -X POST -H 'Content-type:application/json' --data-binary '{
  &quot;delete-copy-field&quot;:{ &quot;source&quot;:&quot;shelf&quot;, &quot;dest&quot;:&quot;location&quot; }
}' http://localhost:8983/api/cores/gettingstarted/schema

</code></pre>
<h3 id="213-solrconfigxml文件">2.1.3. solrconfig.xml文件</h3>
<p>solrconfig.xml文件中定义了Solr core的数据目录、需要的第三方jar包、索引配置等。一般我们修改这个配置文件主要是配置中文分词器，因为Solr官方默认没有配置支持中文分词器的字段类型。</p>
<h2 id="22-core-vs-collection">2.2. Core VS Collection</h2>
<blockquote>
<p>在单机模式启动的Solr中一个搜索数据集叫做core，而在集群模式启动的Solr中搜索数据集的名称叫做collection</p>
</blockquote>
<h3 id="221-单机模式使用solr">2.2.1. 单机模式使用Solr</h3>
<h4 id="2211-以单机模式启动solr">2.2.1.1. 以单机模式启动Solr</h4>
<pre><code class="language-bash">bin/solr start  # linux、macos
bin\solr.cmd start # windows

</code></pre>
<p>启动成功后命令行会有如下输出</p>
<pre><code>Started Solr server on port 8983. Happy searching!

</code></pre>
<h4 id="2212-创建core核心">2.2.1.2. 创建core核心</h4>
<pre><code class="language-bash">bin/solr create -c 核心名  # linux、macos
bin\solr.cmd create -c 核心名 # windows

</code></pre>
<h4 id="2213-导入数据到solr">2.2.1.3. 导入数据到Solr</h4>
<blockquote>
<p>参见使用SpringBoot操作Solr章节</p>
</blockquote>
<h4 id="2214-停止单机版solr">2.2.1.4. 停止单机版Solr</h4>
<pre><code class="language-bash">bin/solr stop -all  # linux、macos
bin\solr.cmd stop -all # windows

</code></pre>
<h3 id="222-以集群模式启动solr">2.2.2. 以集群模式启动Solr</h3>
<h4 id="2221-以集群模式启动solr">2.2.2.1. 以集群模式启动Solr</h4>
<p>以集群模式启动Solr</p>
<pre><code class="language-bash">bin/solr start -c  # linux、macos
bin\solr.cmd start -c # windows

</code></pre>
<p>以集群模式启动后，如果没指定端口号，Solr默认会启动一个8983的节点；同时还会将内置的Zookeeper服务也启动起来，运行到9983端口上</p>
<p>向Solr集群中添加节点</p>
<pre><code class="language-bash">bin/solr start -c -p 节点端口号 -z localhost:9983 # linux、macos
bin\solr.cmd start -c -p 节点端口号 -z localhost:9983 # windows

</code></pre>
<p>-p参数指定节点运行的端口号，-z参数将新创建的节点添加到集群中</p>
<blockquote>
<p>Zookeeper是一个分布式管理框架，专门用来管理集群中各节点的状态。</p>
</blockquote>
<h4 id="2222-创建collection">2.2.2.2. 创建collection</h4>
<pre><code class="language-bash">bin/solr create -c collection名称 -s 2 -rf 2  # linux、macos
bin\solr.cmd create -c collection名称 -s 2 -rf 2 # windows

</code></pre>
<p>-c 参数指定创建的collection名称</p>
<p>-s 参数表示该collection要分布到几个分片上</p>
<p>-rf 参数表示每个分片有几个副本（用于容灾）</p>
<blockquote>
<p>Solr的集群模式和Reids集群类似，每个分片都有一个master节点和若干个slave节点组成，当master节点发生故障无法对外提供服务时，Solr集群会自动选举一个slave节点作为master对外服务。</p>
</blockquote>
<h4 id="2223-导入数据到solr集群">2.2.2.3. 导入数据到Solr集群</h4>
<blockquote>
<p>参见使用SpringBoot操作Solr章节</p>
</blockquote>
<h4 id="2224-停止solr集群">2.2.2.4. 停止Solr集群</h4>
<ul>
<li>
<p>停止集群中某个节点</p>
<pre><code class="language-bash">bin/solr stop -p 要停止的节点的端口号 # linux、macos
bin\solr.cmd stop -p 要停止的节点的端口号 # windows

</code></pre>
</li>
<li>
<p>停止整个Solr集群</p>
<pre><code class="language-bash">bin/solr stop -all # linux、macos
bin\solr.cmd stop -all # windows

</code></pre>
</li>
</ul>
<h2 id="23-配置中文分词器">2.3. 配置中文分词器</h2>
<p>分词器的作用在于将搜索的文本按照词组进行分割，可以大大的提高搜索的准确度。Solr对大部分的语言分词都进行了支持，其中也包括简体中文，但是遗憾的是截止最新的8.3.0版本，官方只是提供了中文分词的jar包，但是并没有对其进行配置。这就需要我们在用的时候配置中文分词器。</p>
<p>Solr官方提供了两种中文分词器：smartcn和icu</p>
<p>以smartcn分词器为例，配置方法如下：</p>
<h3 id="231-修改solrconfigxml配置文件添加中文分词器依赖">2.3.1. 修改solrconfig.xml配置文件，添加中文分词器依赖</h3>
<pre><code class="language-xml">......
&lt;lib dir=&quot;${solr.install.dir:../../../..}/dist/&quot; regex=&quot;solr-ltr-\d.*\.jar&quot; /&gt;
&lt;!-- 添加这行 --&gt;
&lt;lib dir=&quot;${solr.install.dir:../../../..}/contrib/analysis-extras/lucene-libs&quot; regex=&quot;.*\.jar&quot; /&gt;
......

</code></pre>
<h3 id="232-修改managed-schema配置文件新建fieldtype">2.3.2. 修改managed-schema配置文件，新建fieldType</h3>
<pre><code class="language-xml">&lt;!-- 添加自定义的支持中文分词的字段类型 --&gt;
&lt;fieldType name=&quot;text_zh&quot; class=&quot;solr.TextField&quot; positionIncrementGap=&quot;100&quot;&gt;
    &lt;analyzer type=&quot;index&quot;&gt;
        &lt;tokenizer class=&quot;org.apache.lucene.analysis.cn.smart.HMMChineseTokenizerFactory&quot;/&gt;
        &lt;filter class=&quot;solr.CJKWidthFilterFactory&quot;/&gt;
        &lt;filter class=&quot;solr.StopFilterFactory&quot;
                words=&quot;org/apache/lucene/analysis/cn/smart/stopwords.txt&quot;/&gt;
        &lt;filter class=&quot;solr.PorterStemFilterFactory&quot;/&gt;
        &lt;filter class=&quot;solr.LowerCaseFilterFactory&quot;/&gt;
    &lt;/analyzer&gt;
    &lt;analyzer type=&quot;query&quot;&gt;
        &lt;tokenizer class=&quot;org.apache.lucene.analysis.cn.smart.HMMChineseTokenizerFactory&quot;/&gt;
        &lt;filter class=&quot;solr.CJKWidthFilterFactory&quot;/&gt;
        &lt;filter class=&quot;solr.StopFilterFactory&quot;
                words=&quot;org/apache/lucene/analysis/cn/smart/stopwords.txt&quot;/&gt;
        &lt;filter class=&quot;solr.PorterStemFilterFactory&quot;/&gt;
        &lt;filter class=&quot;solr.LowerCaseFilterFactory&quot;/&gt;
    &lt;/analyzer&gt;
&lt;/fieldType&gt;

</code></pre>
<blockquote>
<p>在%solr安装目录%/server/configsets/_default/conf目录下有一份默认的配置文件managed-schema、solrconfig.xml。建议配置中文分词器时直接修改这个默认配置文件。因为在新建核心时，Solr会将这里的默认配置文件拷贝一份作为新核心的配置文件。</p>
</blockquote>
<h2 id="24-使用springboot操作solr">2.4. 使用SpringBoot操作Solr</h2>
<p>添加依赖</p>
<pre><code class="language-xml">&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-data-solr&lt;/artifactId&gt;
&lt;/dependency&gt;

</code></pre>
<p>application.yml中配置</p>
<pre><code class="language-yml">spring:
  data:
    solr:
      host: http://localhost:8983/solr/

</code></pre>
<p>通过Java代码导入数据到Solr和搜索</p>
<pre><code class="language-java">@Slf4j
@Service
public class SolrService {

    @Autowired
    private SolrClient solrClient;

    @Autowired
    private MessageDao messageDao;

    public static final int BATCH_SIZE = 10;

    public static final String CORE_NAME = &quot;lanou3g&quot;;

    /**
     * 将数据批量导入Solr中
     * @throws IOException
     * @throws SolrServerException
     */
    public void importData2Solr() throws IOException, SolrServerException {
        List&lt;Message&gt; messages = messageDao.loadAllMessage();
        List&lt;SolrInputDocument&gt; batchList = new ArrayList&lt;&gt;();
        messages.forEach((message -&gt; {

            // 将message对象转换成solr的inputDocument
            SolrInputDocument inDoc = new SolrInputDocument();
            inDoc.addField(&quot;id&quot;, message.getId());
            inDoc.addField(&quot;from_id&quot;, message.getFromId());
            inDoc.addField(&quot;to_id&quot;, message.getToId());
            inDoc.addField(&quot;subject&quot;, message.getSubject());
            inDoc.addField(&quot;content&quot;, message.getContent());
            inDoc.addField(&quot;createtime&quot;, message.getCreatetime());
            inDoc.addField(&quot;status&quot;, message.getStatus());
            inDoc.addField(&quot;attachment&quot;, message.getAttachment());

            batchList.add(inDoc);
            if(batchList.size() % BATCH_SIZE == 0) {
                try {
                    solrClient.add(CORE_NAME ,batchList);
                    batchList.clear();
                    log.info(&quot;批量导入&quot;+BATCH_SIZE+&quot;条到solr.&quot;);
                } catch (SolrServerException e) {
                    e.printStackTrace();
                } catch (IOException e) {
                    e.printStackTrace();
                }
            }
        }));

        if(batchList.size() &gt; 0) {
            solrClient.add(CORE_NAME, batchList);
            log.info(&quot;批量导入&quot;+batchList.size()+&quot;条到solr.&quot;);
            batchList.clear();
        }
        log.info(&quot;数据导入完成！&quot;);

        // 提交数据到solr
//        solrClient.commit();  // 无参的需要在配置文件中将核心名称添加到solr url中，参见application.yml
        solrClient.commit(CORE_NAME);
    }


    /**
     * 从Solr中分页搜索数据
     * @param q 搜索关键字
     * @param fields 限制返回的结果集中只允许哪个字段
     * @param start 分页参数
     * @param pageSize   分页参数
     */
    public void searchFromSolr(String q, String[] fields, int start, int pageSize) {

        SolrQuery params = new SolrQuery(q);
        if(fields != null &amp;&amp; fields.length &gt; 0) {
            params.setFields(fields);
        }

        // 分页参数
        params.setStart(start);
        params.setRows(pageSize);

        // 不设置按照哪个字段搜索的时候，默认搜索哪个字段
        // （一般会将系统中所有支持检索的字段通过CopyField的方式拷贝到一个统一的字段上，用于搜索，比如下面的keywords）
        params.setParam(&quot;df&quot;, &quot;keywords&quot;);

        // 设置搜索结果高亮显示
        params.setHighlight(true);
        // 设置往搜索结果中所有匹配关键字的地方添加指定的前缀和后缀（内容随意）
        params.setHighlightSimplePre(&quot;&lt;i class=\&quot;keywords\&quot;&gt;&quot;);
        params.setHighlightSimplePost(&quot;&lt;/i&gt;&quot;);

        try {
//            QueryResponse queryResp = solrClient.query(params);
            QueryResponse queryResp = solrClient.query(CORE_NAME, params);
            SolrDocumentList results = queryResp.getResults();
            long numFound = results.getNumFound();
            System.out.println(&quot;总共搜索到&quot;+numFound+&quot;条结果&quot;);
            results.forEach((solrDoc) -&gt; {
                StringBuilder sb = new StringBuilder();
                sb.append(&quot;{&quot;);
                Collection&lt;String&gt; fieldNames = solrDoc.getFieldNames();
                fieldNames.forEach((fieldName) -&gt; {
                    Object fieldValue = solrDoc.getFieldValue(fieldName);
                    sb.append(&quot;\&quot;&quot;+fieldName+&quot;\&quot;:\&quot;&quot;+fieldValue+&quot;\&quot;,&quot;);
                });
                if(sb.length() &gt; 1) {
                    sb.deleteCharAt(sb.length() - 1);
                }
                sb.append(&quot;}&quot;);

                System.out.println(&quot;row: &quot; + sb.toString());
            });
        } catch (SolrServerException e) {
            e.printStackTrace();
        } catch (IOException e) {
            e.printStackTrace();
        }

    }
}

</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[MongoDB入门]]></title>
        <id>https://yihuaikun.github.io/post/mongodb-ru-men</id>
        <link href="https://yihuaikun.github.io/post/mongodb-ru-men">
        </link>
        <updated>2019-12-12T12:29:01.000Z</updated>
        <content type="html"><![CDATA[<h1 id="mongodb入门">MongoDB入门</h1>
<h2 id="什么是mongodb">什么是mongoDB?</h2>
<pre><code>	是一种面向文档的数据库管理系统,它是介于一个关系型数据库和非关系型数据库的之间的一种产品,MongoDb的功能丰富,它是一种支持类似JSON和BSON数据格式,既可以支持简单的数据格式,也可以存储复杂的数据类型.MongoDB最大的特点是它支持的查询语言非常强大,并且还支持数据建立索引.总体来说,mongDB是一款应用相当广泛的nosql型数据库
</code></pre>
<h2 id="mongodb的安装">MongoDB的安装</h2>
<h3 id="1下载地址是">1.下载地址是</h3>
<p><a href="https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-3.4.9.tgz">mongodb下载地址</a></p>
<pre><code class="language-linux">wget  https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-3.4.9.tgz
</code></pre>
<h3 id="2下载下来后解压缩">2.下载下来后解压缩</h3>
<pre><code class="language-linux">[root@iz2zejf0fjkrgyd7kckmfxz mongodb]# tar -zxvf mongodb-linux-x86_64-3.4.9.tgz
</code></pre>
<h3 id="3进入mongodb根目录创建db和logs">3.进入mongodb根目录创建db和logs</h3>
<pre><code class="language-linux">mkdir db
mkdir logs
</code></pre>
<h3 id="4进入bin目录配置配置文件在里面可能没有配置文件创建即可">4.进入bin目录配置配置文件,在,里面可能没有配置文件,创建即可</h3>
<pre><code class="language-linux">vim mongodb.conf
</code></pre>
<h3 id="5配置文件内容">5.配置文件内容</h3>
<pre><code class="language-linux">dbpath=/opt/mongodb/db #这个是自己的文件目录地址
logpath=/opt/mongodb/logs/mongodb.log #这个也是自己的文件目录地址
port=27017
fork=true
nohttpinterface=true
</code></pre>
<h3 id="6启动mongodb">6.启动mongodb</h3>
<pre><code class="language-linux">./mongod -f mongodb.conf
</code></pre>
<p>启动成功标识</p>
<figure data-type="image" tabindex="1"><img src="https://img-blog.csdnimg.cn/20191205170726651.png" alt="在这里插入图片描述"></figure>
<h3 id="7客户端访问">7.客户端访问</h3>
<pre><code class="language-linux">./mongo 
</code></pre>
<p>访问成功界面</p>
<figure data-type="image" tabindex="2"><img src="https://img-blog.csdnimg.cn/2019120517074226.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzg2MjI4MA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></figure>
<h3 id="8切换用户命令">8.切换用户命令</h3>
<pre><code class="language-linux">use 用户名
#退出客户端访问必须在admin用户下
use admin
db.shutdownServer()
</code></pre>
<h1 id="安全管理">安全管理</h1>
<p>上面我们所做的所有的操作都没有涉及到用户，我们在用 Oracle、MySQL 或者 MSSQL 时都有用户名密码需要登录才可以操作，MongoDB 中当然也有，但是需要我们手动添加。在添加之前，我们先来说说 MongoDB 中用户管理的几个特点：</p>
<blockquote>
<ol>
<li>MongoDB 中的账号是在某一个库里边进行设置的，我们在哪一个库里边进行设置，就要在哪一个库里边进行验证。</li>
<li>创建用户时，我们需要指定用户名、用户密码和用户角色，用户角色表示了该用户的权限。</li>
</ol>
</blockquote>
<h2 id="创建用户">创建用户</h2>
<p>给admin创建一个用户;</p>
<pre><code class="language-linux">use admin
db.createUser({user:&quot;root&quot;,pwd:&quot;123&quot;,roles:[{role:&quot;userAdminAnyDatabase&quot;,db:&quot;admin&quot;}]})
</code></pre>
<p>user 表示用户名，pwd 表示密码，role 表示角色，db 表示这个用户应用在哪个数据库上。用户的角色，有如下几种(<a href="https://www.cnblogs.com/shiyiwen/p/5552750.html">参考资料</a>)：</p>
<table>
<thead>
<tr>
<th style="text-align:left">角色名</th>
<th style="text-align:left">备注</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">Read</td>
<td style="text-align:left">允许用户读取指定数据库</td>
</tr>
<tr>
<td style="text-align:left">readWrite</td>
<td style="text-align:left">允许用户读写指定数据库</td>
</tr>
<tr>
<td style="text-align:left">dbAdmin</td>
<td style="text-align:left">允许用户在指定数据库中执行管理函数，如索引创建、删除，查看统计或访问system.profile</td>
</tr>
<tr>
<td style="text-align:left">userAdmin</td>
<td style="text-align:left">允许用户向system.users集合写入，可以找指定数据库里创建、删除和管理用户</td>
</tr>
<tr>
<td style="text-align:left">clusterAdmin</td>
<td style="text-align:left">只在admin数据库中可用，赋予用户所有分片和复制集相关函数的管理权限。</td>
</tr>
<tr>
<td style="text-align:left">readAnyDatabase</td>
<td style="text-align:left">只在admin数据库中可用，赋予用户所有数据库的读权限</td>
</tr>
<tr>
<td style="text-align:left">readWriteAnyDatabase</td>
<td style="text-align:left">只在admin数据库中可用，赋予用户所有数据库的读写权限</td>
</tr>
<tr>
<td style="text-align:left">userAdminAnyDatabase</td>
<td style="text-align:left">只在admin数据库中可用，赋予用户所有数据库的userAdmin权限</td>
</tr>
<tr>
<td style="text-align:left">dbAdminAnyDatabase</td>
<td style="text-align:left">只在admin数据库中可用，赋予用户所有数据库的dbAdmin权限。</td>
</tr>
<tr>
<td style="text-align:left">root</td>
<td style="text-align:left">只在admin数据库中可用。超级账号，超级权限</td>
</tr>
</tbody>
</table>
<p>创建用户成功后需要关闭mongodb服务,以security的方式启动.然后进入.查看dbs</p>
<pre><code class="language-linux">mongod -f /opt/mongodb/bin/mongodb.conf --auth
./mongo
show dbs
</code></pre>
<p>此时我们看到没有权限</p>
<figure data-type="image" tabindex="3"><img src="https://img-blog.csdnimg.cn/20191205170801226.png" alt="在这里插入图片描述"></figure>
<p>此时我们需要先进入到 admin 数据库中，然后授权，操作如下：</p>
<pre><code class="language-linux">use admin
db.auth(&quot;root&quot;,&quot;123&quot;)
</code></pre>
<figure data-type="image" tabindex="4"><img src="https://img-blog.csdnimg.cn/20191205170819702.png" alt="在这里插入图片描述"></figure>
<p>auth 方法执行结果返回 1 表示认证成功。然后再去执行 show dbs 就可以看到预期结果了。此时我再在 sang 库下创建一个只读用户，如下：</p>
<pre><code class="language-linux">use sang
db.createUser({user:&quot;readuser&quot;,pwd:&quot;123&quot;,roles:[{role:&quot;read&quot;,db:&quot;sang&quot;}]})
</code></pre>
<p>创建成功之后，再按照上面的流程进入到 sang 库中，使用 readuser 用户进行认证，认证成功之后一切我们就可以在 sang 库中执行查询操作了，步骤如下：</p>
<pre><code>use sang
db.auth(&quot;readuser&quot;,&quot;123&quot;)
</code></pre>
<p>做完这两步之后再执行查询操作就没有任何问题了，但是此时如果执行插入操作会提示没有权限，那我们可以创建一个有读写功能的用户执行相应的操作，这里就不再赘述。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[问题!!]]></title>
        <id>https://yihuaikun.github.io/post/wen-ti</id>
        <link href="https://yihuaikun.github.io/post/wen-ti">
        </link>
        <updated>2019-12-12T12:27:57.000Z</updated>
        <content type="html"><![CDATA[<h1 id="spring-cloud之eureka和ribbon使用问题">spring-cloud之eureka和ribbon使用问题</h1>
<h2 id="提供服务层端">提供服务层端</h2>
<pre><code class="language-java">@Service
@Slf4j
public class ContentServiceImpl implements ContentService {
    @Autowired
    private TbContentMapper tbContentMapper;
    @Autowired
    private CacheManagerService cacheManagerService;
    @Autowired
    private RedisTemplate redisTemplate;
    @Override
    public TaotaoResult getContent(Long cId) {
        List&lt;TbContent&gt; tbContents = cacheManagerService.getTbContentFromCache(cId);
        /**
         * 如果缓存中没有数据就从数据库中查
         * 查完之后将数据放入缓存,以便下次查找
         */
        if(tbContents == null){
            TbContentExample tbContentExample = new TbContentExample();
            TbContentExample.Criteria criteria = tbContentExample.createCriteria();
            criteria.andCategoryIdEqualTo(cId);
            tbContents = tbContentMapper.selectByExampleWithBLOBs(tbContentExample);
            /**
             * 将数据放入缓存
             */
            cacheManagerService.pushTbContent2Cache(cId,tbContents);
        }
        for(TbContent tbContent : tbContents){
            System.out.println(tbContent.toString());
        }
        return TaotaoResult.ok(tbContents);
    }
}

</code></pre>
<p>上面是提供服务的服务层</p>
<p>下面是提供服务的web控制层</p>
<pre><code class="language-java">@RestController
public class ContentController {
    @Autowired
    private ContentService  contentService;
    @GetMapping(&quot;/content/{cId}&quot;)
    public TaotaoResult getContent(@PathVariable Long cId){
        TaotaoResult taotaoResult = contentService.getContent(cId);
        return taotaoResult;
    }
}
</code></pre>
<p>我们把返回的结果封装在一个对象中,然后TaotaoResult的data字段我们在服务层用list存进去</p>
<h2 id="消费端">消费端</h2>
<pre><code class="language-java">@Service
@PropertySource(&quot;classpath:resources.properties&quot;)
public class AdServiceImpl implements AdService {
    /**
     * '
     * ribbon的方式
     */
    @Autowired
    private RestTemplate restTemplate;
    @Value(&quot;${INDEX_ADI_URL}&quot;)
    private String INDEX_ADI_URL;
    @Override
    public String getAdItemList() {
        //调用服务层的查询打广告的数据
        //发起http的Get请求
//        String result = HttpUtil.doGet(REST_BASE_URL+INDEX_ADI_URL);
        TaotaoResult taotaoResult = restTemplate.getForObject(&quot;http://taotao-rest-provider:8081&quot; + INDEX_ADI_URL, TaotaoResult.class);
//        System.out.println(taotaoResult.toString());
        String dataJson = JsonUtils.objectToJson(taotaoResult.getData());
        List&lt;TbContent&gt; contentList = JsonUtils.jsonToList(dataJson, TbContent.class);
        List&lt;ADItem&gt; adItemList = new ArrayList&lt;&gt;();
        for (TbContent tbContent : contentList) {
            ADItem adItem = new ADItem();
            adItem.setHeight(240);
            adItem.setWidth(670);
            adItem.setSrc(tbContent.getPic());
            adItem.setHeightB(240);
            adItem.setWidthB(550);
            adItem.setSrcB(tbContent.getPic2());
            adItem.setSrcB(tbContent.getPic2());
            adItem.setAlt(tbContent.getTitleDesc());
            adItem.setHref(tbContent.getUrl());
            adItemList.add(adItem);
        }
        return JsonUtils.objectToJson(adItemList);
    }
}
</code></pre>
<p>返回来的TaotaoResult的data字段还是ArrayList类型,但是ArrayLIst里面的每个是以LinkedhashMap存储的,就像下面这样拆分</p>
<pre><code class="language-java">		ArrayList arrayList = new ArrayList();
        LinkedHashMap map = new LinkedHashMap();
        map.put(&quot;id&quot;,101);
        map.put(&quot;name&quot;,&quot;张三&quot;);
        map.put(&quot;age&quot;,24);
        LinkedHashMap map1 = new LinkedHashMap();
        map1.put(&quot;id&quot;,102);
        map1.put(&quot;name&quot;,&quot;张三&quot;);
        map1.put(&quot;age&quot;,2);
        arrayList.add(map);
        arrayList.add(map1);
        System.out.println(arrayList);
</code></pre>
<p>所以直接用会报类型转换异常:LinkedHashMap  不能转换成某一个bean对象</p>
<p>正确的写法是</p>
<pre><code class="language-java">@Service
@PropertySource(&quot;classpath:resources.properties&quot;)
public class AdServiceImpl implements AdService {
    /**
     * '
     * ribbon的方式
     */
    @Autowired
    private RestTemplate restTemplate;
    @Value(&quot;${INDEX_ADI_URL}&quot;)
    private String INDEX_ADI_URL;
    @Override
    public String getAdItemList() {
        //调用服务层的查询打广告的数据
        //发起http的Get请求
//        String result = HttpUtil.doGet(REST_BASE_URL+INDEX_ADI_URL);
//        TaotaoResult taotaoResult = restTemplate.getForObject(&quot;http://taotao-rest-provider:8081&quot; + INDEX_ADI_URL, TaotaoResult.class);
//        String result = restTemplate.getForObject(&quot;http://taotao-rest-provider:8081&quot; + INDEX_ADI_URL, String.class);
        String result = restTemplate.getForObject(&quot;http://taotao-rest-provider&quot; + INDEX_ADI_URL, String.class);
        System.out.println(result);
        //        System.out.println(taotaoResult.toString());
        TaotaoResult taotaoResult = TaotaoResult.formatToList(result, TbContent.class);
//        System.out.println(taotaoResult.getData().getClass());
        List&lt;TbContent&gt; contentList = (List&lt;TbContent&gt;) taotaoResult.getData();
       /* String dataJson = JsonUtils.objectToJson(taotaoResult.getData());
        List&lt;TbContent&gt; contentList = JsonUtils.jsonToList(dataJson, TbContent.class);*/
        List&lt;ADItem&gt; adItemList = new ArrayList&lt;&gt;();
        for (TbContent tbContent : contentList) {
            ADItem adItem = new ADItem();
            adItem.setHeight(240);
            adItem.setWidth(670);
            adItem.setSrc(tbContent.getPic());
            adItem.setHeightB(240);
            adItem.setWidthB(550);
            adItem.setSrcB(tbContent.getPic2());
            adItem.setSrcB(tbContent.getPic2());
            adItem.setAlt(tbContent.getTitleDesc());
            adItem.setHref(tbContent.getUrl());
            adItemList.add(adItem);
        }
        return JsonUtils.objectToJson(adItemList);
    }
}

</code></pre>
<p><strong>直接把上面的data数据转换成json串,然后再转bean对象,还有就是服务不要写端口号,注册中心有端口号,不然没办法做客户端的负载均衡.</strong></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mybatis逆向工程]]></title>
        <id>https://yihuaikun.github.io/post/mybatis-ni-xiang-gong-cheng</id>
        <link href="https://yihuaikun.github.io/post/mybatis-ni-xiang-gong-cheng">
        </link>
        <updated>2019-12-12T12:27:22.000Z</updated>
        <content type="html"><![CDATA[<h1 id="mybatis逆向工程">Mybatis逆向工程</h1>
<p>mybatis需要程序员自己编写sql语句，mybatis官方提供逆向工程，可以针对单表自动生成mybatis执行所需要的代码（mapper.java、mapper.xml、pojo…），可以让程序员将更多的精力放在繁杂的业务逻辑上。</p>
<pre><code>    企业实际开发中，常用的逆向工程方式：由数据库的表生成java代码。

    之所以强调单表两个字，是因为Mybatis逆向工程生成的Mapper所进行的操作都是针对单表的，也许你可能会觉得那这就有点鸡肋了，但是在大型项目中，很少有复杂的多表关联查询，所以作用还是很大的。
</code></pre>
<p>在IDEA中的应用</p>
<h2 id="1加依赖坐标">1.加依赖(坐标)</h2>
<pre><code class="language-xml">&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt;
&lt;/dependency&gt;

&lt;dependency&gt;
    &lt;groupId&gt;mysql&lt;/groupId&gt;
    &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;
    &lt;version&gt;8.0.17&lt;/version&gt;
&lt;/dependency&gt;

&lt;build&gt;
    &lt;plugins&gt;
        &lt;plugin&gt;
            &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt;
            &lt;artifactId&gt;mybatis-generator-maven-plugin&lt;/artifactId&gt;
            &lt;version&gt;1.3.7&lt;/version&gt;
        &lt;/plugin&gt;
    &lt;/plugins&gt;
&lt;/build&gt;
</code></pre>
<h2 id="yml中的配置">yml中的配置</h2>
<pre><code class="language-yml">spring:
  application:
    name: security-unit03
  datasource:
    name: root
    url: jdbc:mysql://localhost:3306/day05?characterEncoding=utf8&amp;serverTimezone=UTC
    password: 123456
    driver-class-name: com.mysql.jdbc.Driver

mybatis:
  mapper-locations: classpath*:/mappers/*.xml

</code></pre>
<h2 id="把配置文件放在sources下">把配置文件放在sources下</h2>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;!DOCTYPE generatorConfiguration
        PUBLIC &quot;-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN&quot;
        &quot;http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd&quot;&gt;

&lt;generatorConfiguration&gt;

    &lt;!-- 引入第三方依赖包 --&gt;

    		&lt;classPathEntry location=&quot;D:\JAVAWEB\mybatis逆向工程\mybatis_genarator\lib\mysql-connector-java-8.0.12.jar&quot; /&gt;


    &lt;!--
     targetRuntime常用值:
        MyBatis3Simple(只生成基本的CRUD和少量的动态SQL)
        MyBatis3(生成完整的CRUD，包含CriteriaAPI方法Example后缀的方法)
     --&gt;
    &lt;context id=&quot;localhost_mysql&quot; targetRuntime=&quot;MyBatis3&quot;&gt;

        &lt;!-- 不生成注释 --&gt;
        &lt;commentGenerator&gt;&lt;!--注解编辑器--&gt;
            &lt;property name=&quot;suppressAllComments&quot; value=&quot;true&quot; /&gt;
        &lt;/commentGenerator&gt;

        &lt;jdbcConnection driverClass=&quot;com.mysql.cj.jdbc.Driver&quot;
                        connectionURL=&quot;jdbc:mysql://localhost:3306/day05?characterEncoding=utf8&amp;amp;serverTimezone=UTC&quot;
                        userId=&quot;root&quot;
                        password=&quot;123456&quot;&gt;
            &lt;property name=&quot;nullCatalogMeansCurrent&quot; value=&quot;true&quot;/&gt;
        &lt;/jdbcConnection&gt;

        &lt;javaTypeResolver &gt;
            &lt;property name=&quot;forceBigDecimals&quot; value=&quot;false&quot; /&gt;
        &lt;/javaTypeResolver&gt;

        &lt;!-- 生成实体类 --&gt;
        &lt;javaModelGenerator targetPackage=&quot;com.security.lession.pojo&quot; targetProject=&quot;../security-unit04/src/main/java&quot;&gt;
            &lt;property name=&quot;enableSubPackages&quot; value=&quot;false&quot; /&gt;
            &lt;property name=&quot;trimStrings&quot; value=&quot;true&quot; /&gt;
        &lt;/javaModelGenerator&gt;

        &lt;!-- 生成XML Mapper --&gt;
        &lt;sqlMapGenerator targetPackage=&quot;src/main/resources/mappers&quot; targetProject=&quot;.&quot;&gt;
            &lt;property name=&quot;enableSubPackages&quot; value=&quot;false&quot; /&gt;
        &lt;/sqlMapGenerator&gt;

        &lt;!-- 生成Mapper接口 --&gt;
        &lt;!-- 生成的Mapper类型：ANNOTATEDMAPPER（注解）、MIXEDMAPPER（混合）、XMLMAPPER（XML） --&gt;
        &lt;javaClientGenerator type=&quot;XMLMAPPER&quot; targetPackage=&quot;com.security.lession.mapper&quot;  targetProject=&quot;src/main/java&quot;&gt;
            &lt;!-- 是否将数据库中的schema作为包名的一部分，默认就是false --&gt;
            &lt;property name=&quot;enableSubPackages&quot; value=&quot;false&quot; /&gt;
        &lt;/javaClientGenerator&gt;


        &lt;!--&lt;table schema=&quot;lanou&quot; tableName=&quot;message&quot; domainObjectName=&quot;Message&quot;&gt;
            &amp;lt;!&amp;ndash; 是否用数据库中的字段名作为POJO属性名(不自动转小驼峰)，默认值是false &amp;ndash;&amp;gt;

            &amp;lt;!&amp;ndash;
            &lt;property name=&quot;useActualColumnNames&quot; value=&quot;true&quot;/&gt;
            &amp;ndash;&amp;gt;
            &amp;lt;!&amp;ndash; 生成代码时支持获取插入数据后自增的ID， 需要通过sqlStatement配置数据库类型。 &amp;ndash;&amp;gt;

            &lt;generatedKey column=&quot;id&quot; sqlStatement=&quot;mysql&quot; identity=&quot;true&quot; /&gt;

            &amp;lt;!&amp;ndash; 此标签用于在生成代码时忽略数据库中的某个字段 &amp;ndash;&amp;gt;
            &amp;lt;!&amp;ndash;
            &lt;ignoreColumn column=&quot;FRED&quot; /&gt;
            &amp;ndash;&amp;gt;
            &amp;lt;!&amp;ndash; 通过此标签重写mybatis从数据库读到的元信息，自定义列相关配置，包括(名称、类型) &amp;ndash;&amp;gt;
            &amp;lt;!&amp;ndash;
            &lt;columnOverride column=&quot;aa&quot; property=&quot;sname&quot; /&gt;
            &amp;ndash;&amp;gt;

            &lt;/table&gt;--&gt;

        &lt;table schema=&quot;&quot; tableName=&quot;student&quot;&gt;
            &lt;!-- 生成代码时支持获取插入数据后自增的ID， 需要通过sqlStatement配置数据库类型。 --&gt;
            &lt;generatedKey column=&quot;id&quot; sqlStatement=&quot;mysql&quot; identity=&quot;true&quot; /&gt;
        &lt;/table&gt;
&lt;!--        &lt;table schema=&quot;&quot; tableName=&quot;tb_content_category&quot;&gt;
            &amp;lt;!&amp;ndash; 生成代码时支持获取插入数据后自增的ID， 需要通过sqlStatement配置数据库类型。 &amp;ndash;&amp;gt;
            &lt;generatedKey column=&quot;id&quot; sqlStatement=&quot;mysql&quot; identity=&quot;true&quot; /&gt;
        &lt;/table&gt;
        &lt;table schema=&quot;&quot; tableName=&quot;tb_item&quot; &gt;
            &amp;lt;!&amp;ndash; 生成代码时支持获取插入数据后自增的ID， 需要通过sqlStatement配置数据库类型。 &amp;ndash;&amp;gt;
            &lt;generatedKey column=&quot;id&quot; sqlStatement=&quot;mysql&quot; identity=&quot;true&quot; /&gt;
        &lt;/table&gt;
        &lt;table schema=&quot;&quot; tableName=&quot;tb_item_cat&quot; &gt;
            &amp;lt;!&amp;ndash; 生成代码时支持获取插入数据后自增的ID， 需要通过sqlStatement配置数据库类型。 &amp;ndash;&amp;gt;
            &lt;generatedKey column=&quot;id&quot; sqlStatement=&quot;mysql&quot; identity=&quot;true&quot; /&gt;
        &lt;/table&gt;
        &lt;table schema=&quot;&quot; tableName=&quot;tb_item_desc&quot; &gt;
            &amp;lt;!&amp;ndash; 生成代码时支持获取插入数据后自增的ID， 需要通过sqlStatement配置数据库类型。 &amp;ndash;&amp;gt;
            &lt;generatedKey column=&quot;id&quot; sqlStatement=&quot;mysql&quot; identity=&quot;true&quot; /&gt;
        &lt;/table&gt;
        &lt;table schema=&quot;&quot; tableName=&quot;tb_item_param&quot; &gt;
            &amp;lt;!&amp;ndash; 生成代码时支持获取插入数据后自增的ID， 需要通过sqlStatement配置数据库类型。 &amp;ndash;&amp;gt;
            &lt;generatedKey column=&quot;id&quot; sqlStatement=&quot;mysql&quot; identity=&quot;true&quot; /&gt;
        &lt;/table&gt;
        &lt;table schema=&quot;&quot; tableName=&quot;tb_item_param_item&quot; &gt;
            &amp;lt;!&amp;ndash; 生成代码时支持获取插入数据后自增的ID， 需要通过sqlStatement配置数据库类型。 &amp;ndash;&amp;gt;
            &lt;generatedKey column=&quot;id&quot; sqlStatement=&quot;mysql&quot; identity=&quot;true&quot; /&gt;
        &lt;/table&gt;
        &lt;table schema=&quot;&quot; tableName=&quot;tb_order&quot; &gt;
            &amp;lt;!&amp;ndash; 生成代码时支持获取插入数据后自增的ID， 需要通过sqlStatement配置数据库类型。 &amp;ndash;&amp;gt;
            &lt;generatedKey column=&quot;id&quot; sqlStatement=&quot;mysql&quot; identity=&quot;true&quot; /&gt;
        &lt;/table&gt;
        &lt;table schema=&quot;&quot; tableName=&quot;tb_order_item&quot; &gt;
            &amp;lt;!&amp;ndash; 生成代码时支持获取插入数据后自增的ID， 需要通过sqlStatement配置数据库类型。 &amp;ndash;&amp;gt;
            &lt;generatedKey column=&quot;id&quot; sqlStatement=&quot;mysql&quot; identity=&quot;true&quot; /&gt;
        &lt;/table&gt;
        &lt;table schema=&quot;&quot; tableName=&quot;tb_order_shipping&quot; &gt;
            &amp;lt;!&amp;ndash; 生成代码时支持获取插入数据后自增的ID， 需要通过sqlStatement配置数据库类型。 &amp;ndash;&amp;gt;
            &lt;generatedKey column=&quot;id&quot; sqlStatement=&quot;mysql&quot; identity=&quot;true&quot; /&gt;
        &lt;/table&gt;
        &lt;table schema=&quot;&quot; tableName=&quot;tb_user&quot; &gt;
            &amp;lt;!&amp;ndash; 生成代码时支持获取插入数据后自增的ID， 需要通过sqlStatement配置数据库类型。 &amp;ndash;&amp;gt;
            &lt;generatedKey column=&quot;id&quot; sqlStatement=&quot;mysql&quot; identity=&quot;true&quot; /&gt;
        &lt;/table&gt;--&gt;
    &lt;/context&gt;
&lt;/generatorConfiguration&gt;
</code></pre>
<h2 id="出现的问题">出现的问题</h2>
<p>1.用完之后建议注掉插件</p>
<p>2.找不到数据库驱动,在上面的配置文件中加上</p>
<pre><code class="language-xml">    		&lt;classPathEntry location=&quot;D:\JAVAWEB\mybatis逆向工程\mybatis_genarator\lib\mysql-connector-java-8.0.12.jar&quot; /&gt;


</code></pre>
<p>上面的数据库的jar包是硬盘上的位置即可,没有的话可以去下载个,一般本地仓库都有.</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[nginx]]></title>
        <id>https://yihuaikun.github.io/post/nginx</id>
        <link href="https://yihuaikun.github.io/post/nginx">
        </link>
        <updated>2019-12-12T12:25:49.000Z</updated>
        <content type="html"><![CDATA[<h1 id="nginx学习">nginx学习</h1>
<h2 id="nginx安装">nginx安装</h2>
<p>nginx是C语言开发，建议在linux上运行，本教程使用Centos6.5作为安装环境。</p>
<p>n  gcc</p>
<p>​         安装nginx需要先将官网下载的源码进行编译，编译依赖gcc环境，如果没有gcc环境，需要安装gcc：yum install gcc-c++</p>
<p>n  PCRE</p>
<p>​         PCRE(Perl Compatible Regular Expressions)是一个Perl库，包括 perl 兼容的正则表达式库。nginx的http模块使用pcre来解析正则表达式，所以需要在linux上安装pcre库。</p>
<p><strong>yum install -y pcre pcre-devel</strong></p>
<p>注：pcre-devel是使用pcre开发的一个二次开发库。nginx也需要此库。</p>
<p>n  zlib</p>
<p>​         zlib库提供了很多种压缩和解压缩的方式，nginx使用zlib对http包的内容进行gzip，所以需要在linux上安装zlib库。</p>
<p><strong>yum install -y zlib zlib-devel</strong></p>
<p>n  openssl</p>
<p>​         OpenSSL 是一个强大的安全套接字层密码库，囊括主要的密码算法、常用的密钥和证书封装管理功能及SSL协议，并提供丰富的应用程序供测试或其它目的使用。</p>
<p>​         nginx不仅支持http协议，还支持https（即在ssl协议上传输http），所以需要在linux安装openssl库。</p>
<p><strong>yum install -y openssl openssl-devel</strong></p>
<h3 id="1-编译安装">1 .编译安装</h3>
<p>将nginx-1.8.0.tar.gz拷贝至linux服务器。</p>
<p>解压：</p>
<p>tar -zxvf nginx-1.8.0.tar.gz</p>
<p>cd nginx-1.8.0</p>
<p>1、  configure</p>
<p>./configure --help查询详细参数（参考本教程附录部分：nginx编译参数）</p>
<pre><code class="language-nginx">./configure \
--prefix=/usr/local/nginx \
--pid-path=/var/run/nginx/nginx.pid \
--lock-path=/var/lock/nginx.lock \
--error-log-path=/var/log/nginx/error.log \
--http-log-path=/var/log/nginx/access.log \
--with-http_gzip_static_module \
--http-client-body-temp-path=/var/temp/nginx/client \
--http-proxy-temp-path=/var/temp/nginx/proxy \
--http-fastcgi-temp-path=/var/temp/nginx/fastcgi \
--http-uwsgi-temp-path=/var/temp/nginx/uwsgi \
--http-scgi-temp-path=/var/temp/nginx/scgi

</code></pre>
<p><strong>注意：上边将临时文件目录指定为/var/temp/nginx</strong>**，需要在/var<strong>下创建temp及nginx目录</strong></p>
<ol start="2">
<li>编译安装</li>
</ol>
<pre><code class="language-linux">make

make  install 
</code></pre>
<p>安装成功查看安装目录 ：</p>
<figure data-type="image" tabindex="1"><img src="https://img-blog.csdnimg.cn/20191126211843957.png" alt="在这里插入图片描述"></figure>
<h1 id="3-启动nginx">3 启动nginx</h1>
<p>cd /usr/local/nginx/sbin/</p>
<p>./nginx</p>
<p>查询nginx进程：<br>
<img src="https://img-blog.csdnimg.cn/20191126212127870.jpg" alt="在这里插入图片描述"></p>
<p>15098是nginx主进程的进程id，15099是nginx工作进程的进程id</p>
<p><strong>注意：执行./nginx<strong><strong>启动nginx</strong></strong>，这里可以-c<strong><strong>指定加载的nginx</strong></strong>配置文件，如下：</strong></p>
<p><strong>./nginx -c /usr/local/nginx/conf/nginx.conf</strong></p>
<p><strong>如果不指定-c</strong>**，nginx<strong><strong>在启动时默认加载conf/nginx.conf</strong></strong>文件，此文件的地址也可以在编译安装nginx<strong><strong>时指定./configure</strong></strong>的参数（--conf-path=** <strong>指向配置文件（nginx.conf</strong>**））**</p>
<h1 id="4-停止nginx">4 停止nginx</h1>
<p>方式1，快速停止：</p>
<p>cd /usr/local/nginx/sbin</p>
<p>./nginx -s stop</p>
<p>此方式相当于先查出nginx进程id再使用kill命令强制杀掉进程。</p>
<p>方式2，完整停止(建议使用)：</p>
<p>cd /usr/local/nginx/sbin</p>
<p>./nginx -s quit</p>
<p>此方式停止步骤是待nginx进程处理任务完毕进行停止。</p>
<h1 id="5-重启nginx">5 重启nginx</h1>
<p>方式1，先停止再启动（建议使用）：</p>
<p>对nginx进行重启相当于先停止nginx再启动nginx，即先执行停止命令再执行启动命令。</p>
<p>如下：</p>
<p>./nginx -s quit</p>
<p>./nginx</p>
<p>方式2，重新加载配置文件：</p>
<p>当nginx的配置文件nginx.conf修改后，要想让配置生效需要重启nginx，使用-s reload不用先停止nginx再启动nginx即可将配置信息在nginx中生效，如下：</p>
<p>./nginx -s reload</p>
<h1 id="6-测试">6 测试</h1>
<p>nginx安装成功，启动nginx，即可访问虚拟机上的nginx：</p>
<figure data-type="image" tabindex="2"><img src="https://img-blog.csdnimg.cn/20191126212245196.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzg2MjI4MA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></figure>
<p>到这说明nginx上安装成功。</p>
<h1 id="7-开机自启动nginx">7 开机自启动nginx</h1>
<h2 id="71-编写shell脚本">7.1 编写shell脚本</h2>
<p>这里使用的是编写shell脚本的方式来处理</p>
<p>vi /etc/init.d/nginx  (输入下面的代码)</p>
<pre><code class="language-linux">#!/bin/bash
# nginx Startup script for the Nginx HTTP Server
# it is v.0.0.2 version.
# chkconfig: - 85 15
# description: Nginx is a high-performance web and proxy server.
#              It has a lot of features, but it's not for everyone.
# processname: nginx
# pidfile: /var/run/nginx.pid
# config: /usr/local/nginx/conf/nginx.conf
nginxd=/usr/local/nginx/sbin/nginx
nginx_config=/usr/local/nginx/conf/nginx.conf
nginx_pid=/var/run/nginx.pid
RETVAL=0
prog=&quot;nginx&quot;
# Source function library.
. /etc/rc.d/init.d/functions
# Source networking configuration.
. /etc/sysconfig/network
# Check that networking is up.
[ ${NETWORKING} = &quot;no&quot; ] &amp;&amp; exit 0
[ -x $nginxd ] || exit 0
# Start nginx daemons functions.
start() {
if [ -e $nginx_pid ];then
   echo &quot;nginx already running....&quot;
   exit 1
fi
   echo -n $&quot;Starting $prog: &quot;
   daemon $nginxd -c ${nginx_config}
   RETVAL=$?
   echo
   [ $RETVAL = 0 ] &amp;&amp; touch /var/lock/subsys/nginx
   return $RETVAL
}
# Stop nginx daemons functions.
stop() {
        echo -n $&quot;Stopping $prog: &quot;
        killproc $nginxd
        RETVAL=$?
        echo
        [ $RETVAL = 0 ] &amp;&amp; rm -f /var/lock/subsys/nginx /var/run/nginx.pid
}
# reload nginx service functions.
reload() {
    echo -n $&quot;Reloading $prog: &quot;
    #kill -HUP `cat ${nginx_pid}`
    killproc $nginxd -HUP
    RETVAL=$?
    echo
}
# See how we were called.
case &quot;$1&quot; in
start)
        start
        ;;
stop)
        stop
        ;;
reload)
        reload
        ;;
restart)
        stop
        start
        ;;
status)
        status $prog
        RETVAL=$?
        ;;
*)
        echo $&quot;Usage: $prog {start|stop|restart|reload|status|help}&quot;
        exit 1
esac
exit $RETVAL

</code></pre>
<p>:wq  保存并退出</p>
<h2 id="72-设置文件的访问权限">7.2 设置文件的访问权限</h2>
<p>chmod a+x /etc/init.d/nginx   (a+x ==&gt; all user can execute  所有用户可执行)</p>
<p>这样在控制台就很容易的操作nginx了：查看Nginx当前状态、启动Nginx、停止Nginx、重启Nginx…</p>
<figure data-type="image" tabindex="3"><img src="https://img-blog.csdnimg.cn/20191126212523315.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzg2MjI4MA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></figure>
<p>如果修改了nginx的配置文件nginx.conf，也可以使用上面的命令重新加载新的配置文件并运行，可以将此命令加入到rc.local文件中，这样开机的时候nginx就默认启动了</p>
<h2 id="73-加入到rclocal文件中">7.3 加入到rc.local文件中</h2>
<p>vi /etc/rc.local</p>
<p>加入一行  /etc/init.d/nginx start    保存并退出，下次重启会生效。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[redis]]></title>
        <id>https://yihuaikun.github.io/post/redis</id>
        <link href="https://yihuaikun.github.io/post/redis">
        </link>
        <updated>2019-12-04T15:38:45.000Z</updated>
        <content type="html"><![CDATA[<h1 id="1-redis介绍">1. redis介绍</h1>
<h2 id="11-什么是redis">1.1. 什么是redis</h2>
<blockquote>
<p>Redis是用C语言开发的一个开源的高性能键值对（key-value）数据库。它通过提供多种键值数据类型来适应不同场景下的存储需求</p>
</blockquote>
<h3 id="redis支持的键值数据类型">Redis支持的键值数据类型</h3>
<p>字符串类型</p>
<p>散列类型  (对应Java中的Object，它主要用来存储对象)</p>
<p>列表类型  （List）</p>
<p>集合类型    (Set)</p>
<p>有序集合类型。 (TreeSet)</p>
<h2 id="12-redis的应用场景">1.2. redis的应用场景</h2>
<p>缓存（数据查询、短连接、新闻内容、商品内容等等）。（最多使用）</p>
<p>分布式集群架构中的session分离。</p>
<p>聊天室的在线好友列表。</p>
<p>任务队列。（秒杀、抢购、12306等等）</p>
<p>应用排行榜。</p>
<p>网站访问统计。</p>
<p>数据过期处理（可以精确到毫秒）</p>
<h1 id="2-redis的安装">2. Redis的安装</h1>
<h2 id="21-在windows上安装">2.1 在Windows上安装</h2>
<p>Redis官方只提供了Linux和macos的版本，并没有提供Windows安装包，但是微软的github仓库中我们可以下载到Windows上可用的Redis程序包，但已经很久没有更新，建议仅用来作为开发练手，不要用于实际的生产环境中。</p>
<p>下载地址： https://github.com/microsoftarchive/redis/tags</p>
<p>下载后直接解压就可以用了</p>
<figure data-type="image" tabindex="1"><img src="https://img-blog.csdnimg.cn/20191125091710786.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzg2MjI4MA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></figure>
<h2 id="22-在linux上安装">2.2 在Linux上安装</h2>
<p>redis是C语言开发，建议在linux上运行，示例使用CentOS7作为安装环境。</p>
<ol>
<li>
<p>安装redis需要先将官网下载的源码进行编译，编译依赖gcc环境，如果没有gcc环境，需要安装gcc</p>
<pre><code class="language-bash">yum install gcc-c++
</code></pre>
<blockquote>
<p>阿里云的CentOS7默认已经内置了gcc，可以跳过这一步</p>
</blockquote>
</li>
<li>
<p>下载redis</p>
<p>从官网下载</p>
<p>http://download.redis.io/releases/redis-5.0.5.tar.gz</p>
<p>将redis-5.0.5.tar.gz拷贝任意路径下，如 /home/john/opt/</p>
</li>
<li>
<p>解压源码</p>
<pre><code class="language-bash">cd /home/john/opt/
tar -zxvf redis-5.0.5.tar.gz  
</code></pre>
</li>
<li>
<p>进入解压后的目录进行编译安装</p>
<pre><code class="language-bash">cd /home/john/opt/redis-5.0.5/src
make # 编译源代码
make install  # 安装
# 上面两步也可以直接通过 make &amp;&amp; make install两步并一步执行
</code></pre>
<blockquote>
<p>Redis默认的安装目录是/usr/local/bin， 我们在执行make install命令时添加prefix参数可修改默认安装位置，如： make PREFIX=/usr/local/redis install</p>
</blockquote>
</li>
</ol>
<h1 id="3-redis单机启动">3. redis单机启动</h1>
<p>redis.conf是redis的配置文件，默认在redis源码包解压后的根目录有一份redis.conf文件，我们可将其拷贝一份到上一步中redis的安装目录</p>
<pre><code class="language-bash">cp /home/john/opt/redis-5.0.5/src/redis.conf /usr/local/bin
</code></pre>
<p>我们装完redis以后，默认的安装路径是/usr/local/bin，系统会自动来此目录寻找命令，所以我们不需要在配置环境变量，在任意目录都可以使用redis相关的命令，如redis-server、redis-cli</p>
<h2 id="31-前端模式启动">3.1.   前端模式启动</h2>
<p>启动命令：</p>
<pre><code class="language-bash">redis-server /usr/local/bin/redis.conf
</code></pre>
<p>通过上面的命令启动，redis将以前端模式启动，前端模式启动的缺点是ssh命令窗口关闭则redis-server程序结束，不推荐使用此方法。</p>
<h2 id="32-后端模式启动">3.2.   后端模式启动</h2>
<h3 id="321-开启远程连接">3.2.1 开启远程连接</h3>
<ul>
<li>注释掉 bind 127.0.0.1这行</li>
<li>关闭保护模式  将protected-mode yes 改成 protected-mode no</li>
</ul>
<h3 id="322-添加密码验证">3.2.2 添加密码验证</h3>
<p>放开 # requirepass foobared 这行注释，将后面的foobared改成你自己需要设置的密码</p>
<p>客户端连接时，需要添加-a 参数指定密码才能连上来。</p>
<h3 id="323-开启后台守护进程运行模式">3.2.3 开启后台守护进程运行模式</h3>
<p>将 # daemonize no 这行放开注释， 并且改成 yes， Redis server将以后台方式运行。</p>
<h3 id="324-指定日志文件">3.2.4 指定日志文件</h3>
<p>将 logfile &quot;&quot; 改成 logfile &quot;你需要的redis日志文件名称&quot;， 默认的空字符串代表输出到前端控制台（标准输出）</p>
<p>修改redis.conf配置文件， daemonize yes 以后端模式启动。</p>
<h3 id="325-启动">3.2.5 启动</h3>
<p>启动命令和前端启动一样，只不过控制台不会输出任何信息，而且命令结束，如果没有异常会马上退出。</p>
<h1 id="5-redis集群">5.   redis集群</h1>
<figure data-type="image" tabindex="2"><img src="https://img-blog.csdnimg.cn/20191125091753812.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzg2MjI4MA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></figure>
<h2 id="51-集群原理">5.1. 集群原理</h2>
<h3 id="511-redis-cluster架构图">5.1.1.   redis-cluster架构图</h3>
<p>架构细节:</p>
<ol>
<li>所有的redis节点彼此互联(PING-PONG机制),内部使用二进制协议优化传输速度和带宽.</li>
<li>节点的fail是通过集群中超过半数的节点检测失效时才生效.</li>
<li>客户端与redis节点直连,不需要中间proxy层.客户端不需要连接集群所有节点,连接集群中任何一个可用节点即可</li>
<li>redis-cluster把所有的物理节点映射到[0-16383]slot上,cluster 负责维护node&lt;-&gt;slot&lt;-&gt;value  Redis 集群中内置了 16384 个哈希槽，当需要在 Redis 集群中放置一个 key-value 时，redis 先对 key 使用 crc16 算法算出一个结果，然后把结果对 16384 求余数，这样每个 key 都会对应一个编号在 0-16383 之间的哈希槽，redis 会根据节点数量大致均等的将哈希槽映射到不同的节点</li>
</ol>
<h3 id="512-redis-cluster投票容错">5.1.2.   redis-cluster投票:容错</h3>
<figure data-type="image" tabindex="3"><img src="https://img-blog.csdnimg.cn/20191125091815748.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzg2MjI4MA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></figure>
<ol>
<li>投票过程是集群中所有master参与,如果半数以上master节点与master节点通信超过(cluster-node-timeout),认为当前master节点挂掉.</li>
<li>什么时候整个集群不可用(cluster_state:fail)?
<ol>
<li>如果集群任意master挂掉,且当前master没有slave.集群进入fail状态,也可以理解成集群的slot映射[0-16383]不完成时进入fail状态</li>
<li>如果集群超过半数以上master挂掉，无论是否有slave集群进入fail状态.</li>
</ol>
</li>
</ol>
<blockquote>
<p>当集群不可用时,所有对集群的操作做都不可用，收到((error) CLUSTERDOWN The cluster is down)错误</p>
</blockquote>
<h2 id="53-创建集群">5.3. 创建集群</h2>
<h3 id="531-集群结点规划">5.3.1.   集群结点规划</h3>
<p>这里在同一台服务器用不同的端口表示不同的redis服务器(伪集群)，如下：</p>
<pre><code>主节点：192.168.101.3:7001 192.168.101.3:7002 192.168.101.3:7003

从节点：192.168.101.3:7004 192.168.101.3:7005 192.168.101.3:7006
</code></pre>
<h3 id="532-修改配置">5.3.2 修改配置</h3>
<p>修改redis.conf配置文件</p>
<pre><code class="language-conf">port 7001  # 将每个节点的端口号改成不一样的(因为同一台机器上一个端口只能被一个进程绑定)
cluster-enabled yes #是否开启集群模式
cluster-config-file nodes.conf	#集群配置文件名称
cluster-node-timeout 5000	#集群中节点间投票通信的超时时间
appendonly yes  #配置集群中当前节点仅开启AOF持久化模式
pidfile /var/run/redis_7001.pid  #将pid文件改成不同的名称，建议和当前节点的端口号对应
</code></pre>
<h3 id="533-创建集群目录">5.3.3 创建集群目录</h3>
<p>在/usr/local下创建redis-cluster目录，其下创建7001、7002。。7006目录，如下：</p>
<figure data-type="image" tabindex="4"><img src="https://img-blog.csdnimg.cn/20191125091842510.png" alt="在这里插入图片描述"></figure>
<p>将redis安装目录bin下的文件拷贝到每个700X目录内，并且将配置文件也拷贝一份到每个700X目录</p>
<pre><code class="language-bash">cp /usr/local/bin/redis/redis* /usr/local/redis-cluster/7001
cp /home/john/opt/redis-5.0.5/src/redis.conf /usr/local/redis-cluster/7001
</code></pre>
<p>修改每个700X目录下的redis.conf配置文件中的端口号和pid文件路径</p>
<h3 id="534-启动每个节点redis服务">5.3.4.   启动每个节点redis服务</h3>
<p>进入/usr/local/redis_cluster目录下，编写启动集群脚本：start_redis_cluster.sh</p>
<p>cd /usr/local/redis_cluster</p>
<p>vim start_redis_cluster.sh</p>
<pre><code class="language-bash">#!/bin/bash

work_dir=`pwd`

echo &quot;开始启动redis集群中的每个节点&quot;
for idx in {1..6}
do
    cd $work_dir
    cd &quot;./700$idx&quot; &amp;&amp; ./redis-server ./redis.conf
    if [ $? != 0 ] 
    then
        echo &quot;启动700$idx节点失败，停止启动集群&quot;
        exit 1
    fi  
    echo &quot;启动700$idx&quot;
done
echo &quot;所有集群节点启动完成&quot;

</code></pre>
<p>编辑完成后，按ESC切换到命令模式， 输入ZZ 或者 :wq保存退出。</p>
<p>启动Redis集群中所有节点</p>
<pre><code class="language-bash">./start_redis_cluster.sh 

</code></pre>
<p>查看redis进程：</p>
<p>ps aux | grep redis</p>
<figure data-type="image" tabindex="5"><img src="https://img-blog.csdnimg.cn/20191125091920330.png" alt="在这里插入图片描述"></figure>
<h3 id="534-执行创建集群命令">5.3.4.   执行创建集群命令</h3>
<p>Redis 5开始，集群不需要依赖Ruby，官方直接提供了集群管理支持</p>
<pre><code class="language-bash">redis-cli --cluster create 127.0.0.1:7001 127.0.0.1:7002 \
127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005 127.0.0.1:7006 \
--cluster-replicas 1

</code></pre>
<blockquote>
<p>注意，这里用127.0.0.1仅适用于在本机练习集群搭建，真实环境下需要换成外公网IP，否则无法远程连接到你的redis集群</p>
</blockquote>
<p>命令说明：</p>
<p>redis集群至少需要3个主节点，每个主节点有一个从节点总共6个节点</p>
<p>--cluster-replicas指定为1表示为集群中每个master都指定一个slave，也就是说上面6个节点会有3个主节点和对应的3个从节点</p>
<figure data-type="image" tabindex="6"><img src="https://img-blog.csdnimg.cn/20191125092008537.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzg2MjI4MA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></figure>
<p>如果一切正常，最后会看到如下输出</p>
<pre><code class="language-bash">[OK] All 16384 slots covered.

</code></pre>
<h4 id="可能会遇到的错误">可能会遇到的错误</h4>
<p>错误一：</p>
<p>如果创建redis集群的时候，ip用的是127.0.0.1，那么你在用Java客户端远程操作Redis集群的时候，会死活连不上，一直是报<strong>127.0.0.1:7001</strong>无法连接</p>
<p>解决办法：创建Redis集群时，创建命令中传入的节点IP参数列表使用外部可以访问的IP</p>
<p>错误二：</p>
<p>如果执行时报如下错误：</p>
<p>[ERR] Node XXXXXX is not empty. Either the node already knows other nodes (check with CLUSTER NODES) or contains some key in database 0</p>
<p>解决方法是删除生成的配置文件nodes.conf，如果不行则说明现在创建的节点包括了旧集群的结点信息，需要删除redis的持久化文件后再重启redis，比如：appendonly.aof、dump.rdb</p>
<h2 id="54-停止redis集群">5.4. 停止Redis集群</h2>
<p>在/usr/local/redis_cluster目录下，创建脚本文件：stop_redis_cluster.sh</p>
<p>输入以下内容：</p>
<pre><code class="language-bash">#!/bin/bash

work_dir=`pwd`

count=0
err_count=0
echo &quot;开始停止redis集群&quot;
for idx in {1..6}
do
    cd $work_dir
    cd &quot;./700$idx&quot; &amp;&amp; ./redis-cli -c -p &quot;700$idx&quot; shutdown
    if [ $? != 0 ] 
    then
        echo &quot;停止700$idx节点失败&quot;
        let err_count++
    fi  
    echo &quot;停止700$idx节点&quot;
    let count++
done
echo &quot;Redis集群一共有$count个节点，成功停止`expr $count - $err_count`个节点，有$err_count个节点停止失败.&quot;

</code></pre>
<p>执行此脚本可以停止redis集群</p>
<h2 id="55-查询集群信息">5.5. 查询集群信息</h2>
<p>集群创建成功登陆任意redis结点查询集群中的节点情况。</p>
<p>客户端以集群方式登陆：</p>
<figure data-type="image" tabindex="7"><img src="https://img-blog.csdnimg.cn/20191125092056434.png" alt="在这里插入图片描述"></figure>
<p>说明：</p>
<p><code>./redis-cli -c -h 192.168.101.3 -p 7001</code>，其中<code>-c</code>表示以集群方式连接redis，<code>-h</code>指定ip地址，<code>-p</code>指定端口号</p>
<h3 id="551-查看集群状态相关命令">5.5.1 查看集群状态相关命令</h3>
<p>cluster nodes 查询集群结点信息</p>
<p>cluster info 查询集群状态信息</p>
<h2 id="56-添加主节点">5.6. 添加主节点</h2>
<p>集群创建成功后可以向集群中添加节点，下面是添加一个master主节点</p>
<p>添加7007节点，参考集群节点规划章节添加一个“7007”目录作为新节点。</p>
<p>Redis 5 添加主节点命令：</p>
<p>语法：</p>
<pre><code>redis-cli –cluster add-node 要添加节点的ip:端口 集群中当前存在的任何一个节点的ip和端口

</code></pre>
<p>示例：</p>
<pre><code class="language-bash">redis-cli --cluster add-node 10.10.14.166:7006 10.10.14.166:7000

</code></pre>
<p>输出结果</p>
<figure data-type="image" tabindex="8"><img src="https://img-blog.csdnimg.cn/20191125092216235.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzg2MjI4MA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></figure>
<p>查看集群结点发现7007已添加到集群中：<br>
<img src="https://img-blog.csdnimg.cn/20191125092232728.png" alt="在这里插入图片描述"></p>
<p>注意：新添加的master node有以下两个特征</p>
<ol>
<li>由于它没有分配hash槽，所以该节点无法存储任何数据</li>
<li>由于它没有分配hash槽，所以在其他从节点要升级成主节点的过程中，该节点不参与投票（没有投票权）</li>
</ol>
<h3 id="561-hash槽重新分配">5.6.1.   hash槽重新分配</h3>
<p>添加完主节点需要对主节点进行hash槽分配这样该主节才可以存储数据。</p>
<p>redis集群有16384个槽，集群中的每个结点分配自已的槽，通过查看集群结点（cluster nodes命令）可以看到槽占用情况。 可以看到新添加的7007节点并没有分配到hash槽</p>
<figure data-type="image" tabindex="9"><img src="https://img-blog.csdnimg.cn/20191125092303198.png" alt="在这里插入图片描述"></figure>
<p>给刚添加的7007结点分配槽</p>
<p>第一步：连接上集群</p>
<pre><code class="language-bash">redis-cli --cluster reshard 127.0.0.1:7001  #（连接集群中任意一个可用结点就行）

</code></pre>
<p>第二步：输入要分配的槽数量</p>
<figure data-type="image" tabindex="10"><img src="https://img-blog.csdnimg.cn/20191125092413603.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzg2MjI4MA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></figure>
<p>输入 500表示分配500个槽</p>
<p>第三步：输入接收槽的结点id</p>
<figure data-type="image" tabindex="11"><img src="https://img-blog.csdnimg.cn/20191125092439556.png" alt="在这里插入图片描述"></figure>
<p>这里准备给7007分配槽，通过cluster nodes查看7007结点id为15b809eadae88955e36bcdbb8144f61bbbaf38fb</p>
<p>输入：15b809eadae88955e36bcdbb8144f61bbbaf38fb</p>
<p>第四步：输入源结点id<br>
<img src="https://img-blog.csdnimg.cn/20191125092457924.png" alt="在这里插入图片描述"></p>
<p>这里输入all</p>
<p>第五步：输入yes开始移动槽到目标结点id</p>
<figure data-type="image" tabindex="12"><img src="https://img-blog.csdnimg.cn/20191125092517748.png" alt="在这里插入图片描述"></figure>
<p>至此，新添加的7007 master节点的hash槽就分配完毕，可以存储数据了！</p>
<p>关于Redis 集群的hash slots相关知识，可以参阅：</p>
<p><a href="https://www.cnblogs.com/abc-begin/p/8203613.html">redis hash slot（虚拟桶）</a></p>
<p><a href="https://www.jianshu.com/p/fe7b7800473e">Redis Cluster及hash slot 算法</a></p>
<h2 id="57-添加从节点">5.7. 添加从节点</h2>
<p>集群创建成功后可以向集群中添加节点，下面是添加一个slave从节点。</p>
<p>添加7008从结点，将7008作为7007的从结点。</p>
<p>Redis 5中添加从节点命令：</p>
<p>语法：</p>
<pre><code class="language-bash">redis-cli –cluster add-node 要添加节点的ip:端口 集群中任意已有master的ip和端口 --cluster-slave [--cluster-master-id masterid]

</code></pre>
<p>示例：</p>
<p>添加一个从节点，不指定目标主节点</p>
<pre><code class="language-bash">redis-cli --cluster add-node 10.10.14.166:7008 10.10.14.166:7001 --cluster-slave

</code></pre>
<blockquote>
<p>注意：该命令只是向集群中添加了一个从节点，但并没有指名要作为哪个master node的从节点，Redis集群会将其添加到集群中随机挑一个从节点较少的master node上，作为其从节点</p>
</blockquote>
<p>添加一个从节点，并指定所属主节点</p>
<pre><code class="language-bash">redis-cli --cluster add-node 10.10.14.166:7008 10.10.14.166:7001 --cluster-slave --cluster-master-id 3c3a0c74aae0b56170ccb03a76b60cfe7dc1912e

</code></pre>
<blockquote>
<p>我们通过增加了一个cluster-master-id参数，指定从节点要添加到哪个主节点上。主节点的ID可以通过cluster nodes查看到</p>
</blockquote>
<p>注意：如果原来该结点在集群中的配置信息已经生成cluster-config-file指定的配置文件中（如果cluster-config-file没有指定则默认为nodes.conf），这时可能会报错：</p>
<p>[ERR] Node XXXXXX is not empty. Either the node already knows other nodes (check with CLUSTER NODES) or contains some key in database 0</p>
<p>解决方法是删除生成的配置文件nodes.conf，删除后再执行添加从节点指令</p>
<p>查看集群中的结点可以发现，刚添加的7008为7007的从节点</p>
<h2 id="58-删除结点">5.8. 删除结点：</h2>
<p>Redis5以后删除节点命令：</p>
<p>语法：</p>
<pre><code class="language-bash">redis-cli --cluster del-node ip:port node_id

</code></pre>
<blockquote>
<p>注：上面的ip:port为集群中存在的任意节点，node_id是你要删除的节点的id</p>
</blockquote>
<p>示例：</p>
<pre><code class="language-bash">redis-cli --cluster del-node 10.10.14.166:7001 d3b977fd46386db84fd85b9240deb602087c8617

</code></pre>
<p>删除已经占有hash槽的结点会失败，报错如下：</p>
<p>[ERR] Node 127.0.0.1:7005 is not empty! Reshard data away and try again.</p>
<p>需要将该结点占用的hash槽分配出去（参考hash槽重新分配章节）。</p>
<h1 id="6-redis持久化策略">6. Redis持久化策略</h1>
<h2 id="61-rdb快照模式">6.1 RDB快照模式</h2>
<p>缺省情况情况下，Redis把数据快照存放在磁盘上的二进制文件中，文件名为dump.rdb。你可以配置Redis的持久化策略，例如数据集中每N秒钟有超过M次更新，就将数据写入磁盘；或者你可以手工调用命令SAVE或BGSAVE。</p>
<h3 id="611-工作步骤">6.1.1 工作步骤</h3>
<ol>
<li>Redis forks；</li>
<li>子进程开始将数据写到临时RDB文件中；</li>
<li>当子进程完成写RDB文件，用新文件替换老文件；</li>
<li>当RedisServer重新启动时，读取RDB文件恢复到内存中。</li>
</ol>
<figure data-type="image" tabindex="13"><img src="https://img-blog.csdnimg.cn/20191125092749581.png" alt="在这里插入图片描述"></figure>
<h3 id="612-配置参数">6.1.2 配置参数</h3>
<pre><code>save 900 1           #在900秒(15分钟)之后，如果至少有1个key发生变化，则dump内存快照。

save 300 10          #在300秒(5分钟)之后，如果至少有10个key发生变化，则dump内存快照。

save 60 10000        #在60秒(1分钟)之后，如果至少有10000个key发生变化，则dump内存快照。

# save &quot;&quot;  			 # 将上面三个配置注释掉，只保留一个save &quot;&quot;， 代表禁用RDB快照模式

</code></pre>
<h2 id="62-aof模式">6.2 AOF模式</h2>
<p>快照模式并不十分健壮，当系统停止，或者无意中Redis被kill掉，最后写入Redis的数据就会丢失。这对某些应用也许不是大问题，但对于要求高可靠性的应用来说，</p>
<p>Redis就不是一个合适的选择。</p>
<p>Append-only-file 模式是另一种选择。</p>
<p>你可以在配置文件中打开AOF模式</p>
<h3 id="621-工作步骤">6.2.1 工作步骤</h3>
<ol>
<li>Redis客户端发送读写命令</li>
<li>RedisServer接收并执行命令，同时同步记录命令到AOF文件中</li>
<li>Redis重新启动时读取AOF文件，执行其中每一条指令完成数据恢复</li>
</ol>
<figure data-type="image" tabindex="14"><img src="https://img-blog.csdnimg.cn/20191125092809644.png" alt="在这里插入图片描述"></figure>
<h3 id="622-配置参数">6.2.2 配置参数</h3>
<pre><code># appendfsync always    # 命令过来后，立刻写入AOF文件（会强制flush操作系统IO缓冲）
appendfsync everysec	# 默认策略， 每秒钟将缓存的命令写入到AOF文件中
# appendfsync no        # 关闭AOF备份

</code></pre>
<h2 id="63-rdb模式与aof模式的对比">6.3 RDB模式与AOF模式的对比</h2>
<h3 id="631-rdb模式的优点">6.3.1 RDB模式的优点</h3>
<ol>
<li>一旦采用该方式，那么你的整个Redis数据库将只包含一个文件，这对于文件备份而言是非常完美的。比如，你可能打算每个小时归档一次最近24小时的数据，同时还要每天归档一次最近30天的数据。通过这样的备份策略，一旦系统出现灾难性故障，我们可以非常容易的进行恢复。</li>
<li>对于灾难恢复而言，RDB是非常不错的选择。因为我们可以非常轻松的将一个单独的文件压缩后再转移到其它存储介质上。</li>
<li>性能最大化。对于Redis的服务进程而言，在开始持久化时，它唯一需要做的只是fork出子进程，之后再由子进程完成这些持久化的工作，这样就可以极大的避免服务进程执行IO操作了。</li>
<li>相比于AOF机制，如果数据集很大，RDB的启动效率会更高。</li>
</ol>
<h3 id="632-rdb模式的缺点">6.3.2 RDB模式的缺点</h3>
<ol>
<li>如果你想保证数据的高可用性，即最大限度的避免数据丢失，那么RDB将不是一个很好的选择。因为系统一旦在定时持久化之前出现宕机现象，此前没有来得及写入磁盘的数据都将丢失。</li>
<li>由于RDB是通过fork子进程来协助完成数据持久化工作的，因此，如果当数据集较大时，可能会导致整个服务器停止服务几百毫秒，甚至是1秒钟。</li>
</ol>
<h3 id="633-aof模式的优点">6.3.3 AOF模式的优点</h3>
<ol>
<li>该机制可以带来更高的数据安全性，即数据持久性。Redis中提供了3中同步策略，即每秒同步、每修改同步和不同步。事实上，每秒同步也是异步完成的，其效率也是非常高的，所差的是一旦系统出现宕机现象，那么这一秒钟之内修改的数据将会丢失。而每修改同步，我们可以将其视为同步持久化，即每次发生的数据变化都会被立即记录到磁盘中。可以预见，这种方式在效率上是最低的。至于无同步，无需多言，我想大家都能正确的理解它。</li>
<li>由于该机制对日志文件的写入操作采用的是append模式，因此在写入过程中即使出现宕机现象，也不会破坏日志文件中已经存在的内容。然而如果我们本次操作只是写入了一半数据就出现了系统崩溃问题，不用担心，在Redis下一次启动之前，我们可以通过redis-check-aof工具来帮助我们解决数据一致性的问题。</li>
<li>如果日志过大，Redis可以自动启用rewrite机制。即Redis以append模式不断的将修改数据写入到老的磁盘文件中，同时Redis还会创建一个新的文件用于记录此期间有哪些修改命令被执行。因此在进行rewrite切换时可以更好的保证数据安全性。</li>
<li>AOF包含一个格式清晰、易于理解的日志文件用于记录所有的修改操作。事实上，我们也可以通过该文件完成数据的重建。</li>
</ol>
<h3 id="634-aof模式的缺点">6.3.4 AOF模式的缺点</h3>
<ol>
<li>对于相同数量的数据集而言，AOF文件通常要大于RDB文件。RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。</li>
<li>根据同步策略的不同，AOF在运行效率上往往会慢于RDB。总之，每秒同步策略的效率是比较高的，同步禁用策略的效率和RDB一样高效。</li>
</ol>
<blockquote>
<p>二者选择的标准，就是看系统是愿意牺牲一些性能，换取更高的缓存一致性（aof），还是愿意写操作频繁的时候，不启用备份来换取更高的性能，待手动运行save的时候，再做备份（rdb）。rdb这个就更有些 eventually consistent的意思了。</p>
</blockquote>
<blockquote>
<h4 id="如果rdb文件和aof同时存在当redis重启的时候会优先载入aof文件来恢复原始的数据因为在通常情况下aof文件保存的数据集要比rdb文件完整">如果RDB文件和AOF同时存在，当redis重启的时候会优先载入AOF文件来恢复原始的数据,因为在通常情况下AOF文件保存的数据集要比RDB文件完整</h4>
</blockquote>
<h1 id="7-通过springboot操作redis">7. 通过SpringBoot操作redis</h1>
<p>注： 下面的教程以最新的SpringBoot版本 2.2.0为例</p>
<pre><code class="language-xml">&lt;parent&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;
    &lt;version&gt;2.2.0.RELEASE&lt;/version&gt;
&lt;/parent&gt;

</code></pre>
<h2 id="71-sringboot操作单机版redis">7.1. SringBoot操作单机版Redis</h2>
<h3 id="711-引入依赖">7.1.1   引入依赖</h3>
<pre><code class="language-xml">&lt;!-- SpringBoot2以后，默认的redis客户端已经由jedis改成了lettuce，下面依赖会把lettuce-core也添加进来 --&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;
&lt;/dependency&gt;
&lt;!-- 如果项目中用到了redis连接池，需要添加如下依赖 --&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.apache.commons&lt;/groupId&gt;
    &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt;
&lt;/dependency&gt;

</code></pre>
<h3 id="712-springboot配置">7.1.2   SpringBoot配置</h3>
<p>application.yml</p>
<pre><code class="language-yml">spring:
    redis:
    host: www.taotao.com
#    port: 6379		# 如果端口号不是默认端口需要制定
#    password: xxx	# 如果redis服务端开启了口令验证，需要添加
    lettuce:
      pool:			# 如果使用redis连接池，需要添加apche的common-pool2依赖
        max-idle: 2
        max-wait: 1000ms

</code></pre>
<h3 id="713-java代码">7.1.3.   Java代码</h3>
<p>通过创建单实例jedis对象连接redis服务，如下代码：</p>
<pre><code class="language-java">@Slf4j
@SpringBootTest
public class TestRedisClient {

   @Autowired
   private StringRedisTemplate redisTemplate;

   @Test
   public void testRedis() {
      Set&lt;String&gt; keys = redisTemplate.keys(&quot;*&quot;);
      log.info(&quot;操作前存在的keys: &quot; + keys);

      String key = &quot;lanou_F4&quot;;

      redisTemplate.opsForList().rightPushAll(key, new String[]{&quot;宋超&quot;, &quot;国胜&quot;, &quot;国伟&quot;, &quot;高飞&quot;});

      long size = redisTemplate.opsForList().size(key);
      log.info(&quot;当前&quot;+key+&quot;值的数量： &quot; + size);

      List&lt;String&gt; values = redisTemplate.opsForList().range(key, 0, size);
      log.info(&quot;当前&quot; + key +&quot;的值： &quot; + values);

      keys = redisTemplate.keys(&quot;*&quot;);
      log.info(&quot;操作后存在的keys: &quot; + keys);
   }
}

</code></pre>
<h2 id="72-springboot操作redis集群">7.2. SpringBoot操作Redis集群</h2>
<h3 id="721-引入依赖">7.2.1. 引入依赖</h3>
<pre><code class="language-xml">&lt;dependencies&gt;
        &lt;!-- 添加spring-boot-starter-data-redis依赖 --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;
            &lt;!-- 排除掉lettuce客户端相关依赖 --&gt;
            &lt;!-- lettuce客户端连接阿里云上自建的redis集群会有连接超时的问题 --&gt;
            &lt;exclusions&gt;
                &lt;exclusion&gt;
                    &lt;groupId&gt;io.lettuce&lt;/groupId&gt;
                    &lt;artifactId&gt;lettuce-core&lt;/artifactId&gt;
                &lt;/exclusion&gt;
            &lt;/exclusions&gt;
        &lt;/dependency&gt;
        &lt;!-- 替换成jedis客户端 --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;redis.clients&lt;/groupId&gt;
            &lt;artifactId&gt;jedis&lt;/artifactId&gt;
        &lt;/dependency&gt;

        &lt;!-- redis连接池依赖 --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.commons&lt;/groupId&gt;
            &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt;
        &lt;/dependency&gt;
&lt;/dependencies&gt;

</code></pre>
<h3 id="722-springboot配置">7.2.2. SpringBoot配置</h3>
<p>application.yml</p>
<pre><code class="language-yml">spring:
  redis:
    jedis:
      pool: # 配置redis连接池相关参数
        max-idle: 2
        max-active: 10
        min-idle: 1
    cluster:
      nodes: teacher.lanou.com:7001,teacher.lanou.com:7002,teacher.lanou.com:7003,teacher.lanou.com:7004,teacher.lanou.com:7005,teacher.lanou.com:7006

</code></pre>
<h3 id="723-java代码">7.2.3. Java代码</h3>
<pre><code class="language-java">@SpringBootTest
class SpringbootRedisApplicationTests {

    @Autowired
    private StringRedisTemplate redisTemplate;


    @Test
    public void testPutKV() {
        ValueOperations&lt;String, String&gt; ops = redisTemplate.opsForValue();
        ops.set(&quot;name&quot;, &quot;张三&quot;);
        String name = ops.get(&quot;name&quot;);
        Assertions.assertEquals(&quot;张三&quot;, name, &quot;应该返回张三&quot;);
    }

    @Test
    public void testOpsForList() {
        ListOperations&lt;String, String&gt; ops = redisTemplate.opsForList();
        ops.rightPush(&quot;yanfa3&quot;, &quot;王康健&quot;);
        ops.leftPush(&quot;yanfa3&quot;, &quot;于漫漫&quot;);
        ops.rightPushAll(&quot;yanfa3&quot;, &quot;李光&quot;, &quot;星辰&quot;, &quot;鹏杰&quot;, &quot;士军&quot;);

        Assertions.assertEquals(6, ops.size(&quot;yanfa3&quot;), &quot;应该是由6个元素才对&quot;);

        List&lt;String&gt; stuNames = ops.range(&quot;yanfa3&quot;, 0, -1);
        stuNames.forEach((v) -&gt; {
            System.out.println(v);
        });

    }
}

</code></pre>
<blockquote>
<p>集群模式只是依赖和配置不同，在代码中使用的API没有什么区别</p>
</blockquote>
<h2 id="73-外部连接不上redis的解决方法">7.3. 外部连接不上redis的解决方法</h2>
<p>由于linux防火墙默认开启，redis的服务端口6379并不在开放规则之内，所有需要将此端口开放访问或者关闭防火墙。</p>
<p>查看防火墙状态：sevice iptables status</p>
<p>关闭防火墙命令：sevice iptables stop</p>
<p>如果是修改防火墙规则，可以修改：/etc/sysconfig/iptables文件</p>
<h1 id="8-系统添加缓存逻辑示例">8.   系统添加缓存逻辑示例</h1>
<p>添加缓存逻辑的原则：缓存逻辑不能影响正常的业务逻辑执行。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[单点登陆与redis集群缓存]]></title>
        <id>https://yihuaikun.github.io/post/dan-dian-deng-lu-yu-redis-ji-qun-huan-cun</id>
        <link href="https://yihuaikun.github.io/post/dan-dian-deng-lu-yu-redis-ji-qun-huan-cun">
        </link>
        <updated>2019-12-02T09:48:31.000Z</updated>
        <content type="html"><![CDATA[<h1 id="单点登录sso">单点登录SSO</h1>
<p>​		单点登录:SSO英文全称Single Sign On，单点登录。SSO是在多个应用系统中，用户只需要登录一次就可以访问所有相互信任的应用系统。它包括可以将这次主要的登录映射到其他应用中用于同一个用户的登录的机制。它是目前比较流行的企业业务整合的解决方案之一。</p>
<p>​		单点登录解决的问题:分布式session的共享问题,简单的说是解决了一个服务器一登陆的问题,实现多功能系统的一次登陆可访问多个服务的问题.</p>
<h2 id="环境的搭配">环境的搭配</h2>
<p>需要的依赖</p>
<pre><code class="language-xml">    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt;
            &lt;version&gt;2.2.1.RELEASE&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.commons&lt;/groupId&gt;
            &lt;artifactId&gt;commons-lang3&lt;/artifactId&gt;
            &lt;version&gt;3.9&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;com.alibaba&lt;/groupId&gt;
            &lt;artifactId&gt;fastjson&lt;/artifactId&gt;
            &lt;version&gt;1.2.62&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;redis.clients&lt;/groupId&gt;
            &lt;artifactId&gt;jedis&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.commons&lt;/groupId&gt;
            &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;
            &lt;artifactId&gt;lombok&lt;/artifactId&gt;
            &lt;optional&gt;true&lt;/optional&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;
            &lt;scope&gt;test&lt;/scope&gt;
            &lt;exclusions&gt;
                &lt;exclusion&gt;
                    &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt;
                    &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt;
                &lt;/exclusion&gt;
            &lt;/exclusions&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;io.lettuce&lt;/groupId&gt;
            &lt;artifactId&gt;lettuce-core&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;mysql&lt;/groupId&gt;
            &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.tomcat.embed&lt;/groupId&gt;
            &lt;artifactId&gt;tomcat-embed-jasper&lt;/artifactId&gt;
            &lt;scope&gt;provided&lt;/scope&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;
</code></pre>
<p>1.redis集群的搭建</p>
<p>2.在java中的配置</p>
<pre><code class="language-yml">server:
  port: 10000
spring:
  datasource:
    username: root
    url: jdbc:mysql://localhost:3306/taotao?characterEncoding=utf8&amp;serverTimezone=UTC
    password: 123456
    driver-class-name: com.mysql.cj.jdbc.Driver
  redis:
    #    redis.cluster集群的节点
    cluster:
      nodes: 
      # 这里写你的redis集群的ip和端口号以&quot;,&quot;分割
    jedis:
      pool:
        #      连接池最大数量
        max-active: 10
        #        连接池最小空闲连接
        min-idle: 1
        max-idle: 2
        #        连接池最大阻塞时间
        max-wait: -1
    password: xxxxx
    host: redis集群的ip地址
    timeout: 1000
    commandTimeout: 5000
</code></pre>
<p>3.在java中的配置文件</p>
<pre><code class="language-java">package com.sso.taotaossostudying;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.boot.autoconfigure.condition.ConditionalOnClass;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.stereotype.Component;
import redis.clients.jedis.HostAndPort;
import redis.clients.jedis.JedisCluster;
import redis.clients.jedis.JedisPoolConfig;

import java.util.HashSet;
import java.util.Set;

@Configuration
@ConditionalOnClass({JedisCluster.class})
@Component
public class RedisConfig {
    @Value(&quot;${spring.redis.cluster.nodes}&quot;)
    private String clusterNodes;
    @Value(&quot;${spring.redis.password}&quot;)
    private String password;
    @Value(&quot;${spring.redis.timeout}&quot;)
    private int timeout;
    @Value(&quot;${spring.redis.commandTimeout}&quot;)
    private int commandTimeout;
    @Bean
    public JedisCluster getJedisCluster() {
        String[] cNodes = clusterNodes.split(&quot;,&quot;);
        Set&lt;HostAndPort&gt; nodes = new HashSet&lt;&gt;();
        //分割出集群节点
        for (String node : cNodes) {
            String[] hp = node.split(&quot;:&quot;);
            nodes.add(new HostAndPort(hp[0], Integer.parseInt(hp[1])));
        }
        JedisPoolConfig jedisPoolConfig = new JedisPoolConfig();
        //创建集群对象。没有密码的请使用这一个
        // JedisCluster jedisCluster = new JedisCluster(nodes,commandTimeout);
        //有密码的请使用这一个。 我这里是redis有密码的所以我使用的这一个
        return new JedisCluster(nodes,commandTimeout,commandTimeout,5,password, jedisPoolConfig);
    }
}

</code></pre>
<p>ps:需要注意的是上面解决了jedis和jediscluster的一些问题得到的配置,redis集群加密的配置.</p>
<h2 id="单点登陆流程图">单点登陆流程图</h2>
<figure data-type="image" tabindex="1"><img src="https://img-blog.csdnimg.cn/20191125090924348.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzg2MjI4MA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></figure>
<h2 id="代码实现方面">代码实现方面</h2>
<h3 id="登陆界面的实现">登陆界面的实现</h3>
<pre><code class="language-java">@Controller
public class LoginUriController {
    @RequestMapping(&quot;/user/login&quot;)
    public String uritoLogin(HttpServletRequest req, @RequestParam(required = false) String url , Model model){
        try {
            req.setCharacterEncoding(&quot;utf-8&quot;);
        } catch (UnsupportedEncodingException e) {
            e.printStackTrace();
        }
        System.out.println(url);
        //把请求的uri放进来用于登陆成功后返回登陆时的页面
        model.addAttribute(&quot;url&quot;,url);
        return &quot;login&quot;;
    }
}

</code></pre>
<p>需要注意的是:</p>
<p>​	<strong>url和uri的区别:</strong></p>
<p>​		1.url在java中指是请求的全路径,uri指的是请求lujing,及handler上面的拦截路径</p>
<p>​		2.URI，是uniform resource identifier，统一资源标识符，用来唯一的标识一个资源。而URL是uniform resource locator，统一资源定位器，它是一种具体的URI，即URL可以用来标识一个资源，而且还指明了如何locate这个资源。</p>
<p>​	<strong>一定要获得请求的路径</strong></p>
<p>​		获得请求的路径,通过location.href=xxx.xxx.com,来返回登陆处的功能,用户体验更好一些,</p>
<p>京东,淘宝都是这样做的.以参数的方式来获得从哪里得到发起请求的地址url,然后登陆后重新回到登陆处,比如去购物车去付款发现没登陆账号,然后去登陆,登陆后重新回到支付的页面进行购物.</p>
<h3 id="前端部分">前端部分</h3>
<pre><code class="language-html">&lt;!DOCTYPE html&gt;
&lt;html lang=&quot;en&quot; xmlns:th=&quot;http://thymeleaf.org&quot; &gt;
&lt;head&gt;
    &lt;meta charset=&quot;UTF-8&quot;&gt;
    &lt;title&gt;登陆界面&lt;/title&gt;
&lt;/head&gt;
&lt;script src=&quot;https://cdn.bootcss.com/jquery/3.4.1/jquery.min.js&quot;&gt;&lt;/script&gt;
&lt;body&gt;
&lt;form action=&quot;/login&quot;&gt;
    用户名: &lt;input type=&quot;text&quot; name=&quot;username&quot; &gt; &lt;/br&gt;
    密码:   &lt;input type=&quot;password&quot; name=&quot;password&quot; &gt; &lt;/br&gt;
    &lt;input type=&quot;submit&quot;&gt; &lt;a href=&quot;register.html&quot;&gt;注册&lt;/a&gt;
&lt;/form&gt;
&lt;/body&gt;
&lt;script&gt;
    //注意这里的thymeleaf的取值方式
    var url = $(&quot;#uri&quot;).val();
    console.log(url)
    function login() {
        var data = $(&quot;form&quot;).serialize();
        console.log(data);
        $.getJSON(&quot;/login&quot;,data,function (ret) {
            if(ret.status == 200){
                if(url == undefined){
                    location.href = &quot;http://localhost:10001&quot;;
                }else{
                    location.href = url;
                }
            }else{
                alert(ret.msg);
            }
        })
    }
    $(&quot;form&quot;).submit( function () {
        login();
        return false;
    } );
&lt;/script&gt;
&lt;/html&gt;
</code></pre>
<p>需要注意的是:</p>
<p>1.注意ajax的使用</p>
<p>2.登陆按钮的禁止跳转</p>
<p>3.前端做非空和非法判断</p>
<h3 id="登陆信息的处理">登陆信息的处理</h3>
<p>controller层的处理</p>
<pre><code class="language-java"> @RequestMapping(&quot;/login&quot;)
    public SSOResult login(String username, String password, HttpServletResponse resp){
        return loginService.login(username,password,resp);
    }
</code></pre>
<p>需要注意的是:</p>
<p>​	<strong>要把用户信息保存在session或cookie中,需要用到HttpServletResponse的对象</strong></p>
<p>service层对信息的处理</p>
<p>1.校验用户信息的正确性(即密码的校验需要连接数据库),正确后生成token(UUID)</p>
<p>2.把用户信息封装成对象(可以用md5堆成加密对用户信息加密),然后放到redis中</p>
<p><strong>注意</strong>:最好不要把密码放进去,因为上面已经验证过密码的正确性,所以最好就是把用户不隐私的信息放进去即可.token做key,用户对像做value</p>
<p>3.把token放到cookie中即可.</p>
<p>​		注意:cookie是在分布式的一级域名下,达到系统共享,访问其他服务,能从cookie中拿到token,然后去redis中拿用户信息.</p>
<p>4.需要注意的还有就是cookie和redis的有效期的设置,redis对内存要求比较高,这样的话我们对redis处理应该细致化.cookie中的token能否有效取决于redis中(token,用户对象)是否存在.不存在就失效或连接超时,需要重新登陆.</p>
<pre><code class="language-java">    @Override
    public SSOResult login(String username, String password, HttpServletResponse resp) {
        /**
         * 去数据库查找数据
         */
        if(StringUtils.isBlank(username) || StringUtils.isBlank(password)){
            return new SSOResult(&quot;用户名或密码不能为空&quot;,500);
        }
        if(StringUtils.isBlank(username)){
            return new SSOResult(&quot;用户名不能为空&quot;,500);
        }
        if(StringUtils.equals(username,&quot;zahngsan&quot;) &amp;&amp; !StringUtils.equals(password,&quot;123456&quot;)){
            return new SSOResult(&quot;密码不正确&quot;,500);
        }
        /**
         * 登陆成功后封装数据
         */
        //设置token
        String token = UUID.randomUUID().toString();
        UserInfo userInfo= new UserInfo();
        userInfo.setNickname(&quot;laozhang&quot;);
        userInfo.setUsername(&quot;zhangsan&quot;);

        String user = JSON.toJSONString(userInfo);

        //一般情况下不把password放在redis中,不安全
       // userInfo.setPassword(&quot;123456&quot;);
        jedis.setex(token,60,user);

        /**
         * 将token放入cookie,cookie的domain一般是一级域名下
         * 如果不知道domain是什么,启动一下项目,去application中找一下就行
         * 只是把token放到cookie中,然后其他服务用到,只能拿token去redis中拿数据,
         * 如果redis的keyshixiao了,那就要重新返回登陆界面重新登陆
         */
        Cookie tokenCookie = new Cookie(&quot;token&quot;,token);
        tokenCookie.setDomain(&quot;localhost&quot;);
        tokenCookie.setMaxAge(60);
        resp.addCookie(tokenCookie);
        return new SSOResult(&quot;登陆成功&quot;,200);
    }

</code></pre>
<p>总结:这里,面最后的返回码和上边前端相吻合,通过后处理后 返回到登陆时的界面.</p>
<p><strong>到此简单的登陆就做好了,对单点登陆应用是在拦截器中的使用</strong></p>
<h3 id="登陆的效果实现">登陆的效果实现</h3>
<p>在门户系统中开登陆的口</p>
<pre><code class="language-html">&lt;!DOCTYPE html&gt;
&lt;html lang=&quot;en&quot;&gt;
&lt;head&gt;
    &lt;meta charset=&quot;UTF-8&quot;&gt;
    &lt;title&gt;Title&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;a href=&quot;http://localhost:10000/user/login&quot;&gt;登陆&lt;/a&gt;
&lt;/body&gt;
&lt;/html&gt;
</code></pre>
<p>服务到sso做上边的登陆处理之后回到门户</p>
<h2 id="比如订单的处理">比如订单的处理</h2>
<p>看订单我们需要有用户信息,然后验证通过后才能看订单,这样我们就要在拦截器中来让用户的看订单请求去sso拿用户信息</p>
<p>请求接口前端:</p>
<pre><code class="language-java">&lt;!DOCTYPE html&gt;
&lt;html lang=&quot;en&quot;&gt;
&lt;head&gt;
    &lt;meta charset=&quot;UTF-8&quot;&gt;
    &lt;title&gt;Title&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;!--请求查看订单页面--&gt;
&lt;a href=&quot;/order/all&quot; &gt;查看订单&lt;/a&gt;
&lt;/body&gt;
&lt;/html&gt;

</code></pre>
<p>拦截这个路径处理用户身份信息,这是我们只有能唯一得到的时存储用户信息的cookie</p>
<p>拦截器的配置</p>
<pre><code class="language-java">@SpringBootApplication
public class SsoDoorApplication implements WebMvcConfigurer 
    @Autowired
    private OrderInterceptor orderInterceptor;
    @Bean
    public RestTemplate restTemplate(){
        return new RestTemplate();
    }
    @Override
    public void addInterceptors(InterceptorRegistry registry) {
        registry.addInterceptor(orderInterceptor).addPathPatterns(&quot;/order/**&quot;);
    }
    public static void main(String[] args) {
        SpringApplication.run(SsoDoorApplication.class, args);
    }
}


</code></pre>
<p>在拦截器中的请求</p>
<pre><code class="language-java">@Component
public class OrderInterceptor implements HandlerInterceptor {
    private String url = &quot;http://localhost:10000/user/login&quot;;
    private String getDataUrl = &quot;http://localhost:10000/get_user_by_token&quot;;
    @Autowired
    private RestTemplate restTemplate;
    @Override
    public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception {
        StringBuffer requestURL = request.getRequestURL();
        response.setContentType(&quot;text/html;charset=UTF-8&quot;);
        PrintWriter writer = response.getWriter();
        /**
         * 拿到cookie获得token
         * 两种结果cookie过期,然后重定向到登陆界面
         * token存在,拿着token去sso服务要用户信息
         */
        Cookie[] cookies = request.getCookies();
        String token = null;
        String restUri = url + &quot;?&quot; + requestURL;
        if (cookies == null) {
            writer.println(&quot;&lt;script&gt; alert('你还没登陆,请登陆!');location.href='&quot; + restUri + &quot;'&lt;/script&gt;&quot;);
        } else {
            for (Cookie cookie : cookies) {
                /**
                 *拿到token
                 */
                if (cookie.getName().equals(&quot;token&quot;)) {
                    token = cookie.getValue();
                    break;
                } else {
                    continue;
                }
            }
        }

        if (token == null) {
            writer.println(&quot;&lt;script&gt; alert('会话超时,请重新登陆!');location.href='&quot; + restUri + &quot;'&lt;/script&gt;&quot;);
            return false;
        }
        /**
         * 判断token是否存在
         */
        if (token != null) {
            /**
             * 存在的话就发起请求去sso拿信息
             */
            CloseableHttpClient httpClient = HttpClients.createDefault();
            HttpGet httpGet = new HttpGet(getDataUrl+&quot;token=&quot;+token);
            CloseableHttpResponse resp = httpClient.execute(httpGet);
            HttpEntity entity = resp.getEntity();
            String userInfo = EntityUtils.toString(entity);
            UserInfo user = JSON.parseObject(userInfo, UserInfo.class);
            /**
             * 两种情况,一种是redis中的key过期了,一种是获得了用户的信息
             * 没有获得告诉用户,会话超时请重新登陆
             * 正常情况下让它通过去该处理的controller
             */
            if (userInfo != null) {
                return true;
            }else {
                writer.println(&quot;&lt;script&gt; alert('会话超时,请重新登陆!');location.href='&quot; + url + &quot;'&lt;/script&gt;&quot;);
                return false;
            }
        }
        return false;
    }
}

</code></pre>
<p><strong>上面需要注意的时情况的划分,然后就是带参数的script语句的拼写</strong></p>
<p><strong>还有就是HttpClient的使用,省时间url直接写上去</strong></p>
<p>获得信息的接口(sso中)</p>
<pre><code class="language-java">  @RequestMapping(&quot;/get_user_by_token&quot;)
    public UserInfo getData(@RequestParam String token){
        return loginService.getData(token);
    }

</code></pre>
<p>service中</p>
<pre><code class="language-java">    /**
     * 本文档用于查找用户信息,从redis中查找,如果没有返回null
     * @param token
     * @return
     */
    @Override
    public UserInfo getData(String token) {
        String user = jedis.get(token);
        UserInfo userInfo = JSON.parseObject(user, UserInfo.class);
        if(userInfo != null){
            return userInfo;
        }
        return null;
    }

</code></pre>
<p>所有的处理结束后</p>
<p>zhengque放行,不zhengque就返回就登陆界面</p>
<p>zhengque后的简单处理</p>
<pre><code class="language-java">@Controller
public class OrderController {

    @RequestMapping(&quot;/order/all&quot;)
    public String toOrder(){
        return &quot;order&quot;;
    }

}


</code></pre>
<p>前端展示xiaog</p>
<pre><code class="language-html">&lt;!DOCTYPE html&gt;
&lt;html lang=&quot;en&quot;&gt;
&lt;head&gt;
    &lt;meta charset=&quot;UTF-8&quot;&gt;
    &lt;title&gt;订单页面&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;
    &lt;pre&gt;
         1.香蕉50斤
         2.苹果50斤
         3.三只松鼠50包
         4.提子50斤
         5.瓜子50斤
            共计250
    &lt;/pre&gt;
&lt;/body&gt;
&lt;/html

</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[SpringCloud]]></title>
        <id>https://yihuaikun.github.io/post/springcloud</id>
        <link href="https://yihuaikun.github.io/post/springcloud">
        </link>
        <updated>2019-09-02T14:41:20.000Z</updated>
        <content type="html"><![CDATA[<h1 id="springcloud之netflix">springcloud之Netflix</h1>
<h2 id="netflix体系简介">Netflix体系简介</h2>
<p>Netflix这可是个大boss，地位仅次于老大，老大各项服务依赖与它，与各种Netflix OSS组件集成，组成微服务的核心，它的小弟主要有Eureka, Hystrix, Zuul, Archaius… 太多了</p>
<h3 id="核心成员">核心成员</h3>
<h4 id="netflix-eureka">Netflix Eureka</h4>
<p>服务中心，云端服务发现，一个基于  REST  的服务，用于定位服务，以实现云端中间层服务发现和故障转移。这个可是springcloud最牛鼻的小弟，服务中心，任何小弟需要其它小弟支持什么都需要从这里来拿，同样的你有什么独门武功的都赶紧过报道，方便以后其它小弟来调用；它的好处是你不需要直接找各种什么小弟支持，只需要到服务中心来领取，也不需要知道提供支持的其它小弟在哪里，还是几个小弟来支持的，反正拿来用就行，服务中心来保证稳定性和质量。</p>
<h4 id="netflix-ribbon">Netflix Ribbon</h4>
<p>Ribbon是一个客户端负载均衡组件，帮我们实现后端服务节点动态扩容，而不影响调用方。</p>
<h4 id="netflix-hystrix">Netflix Hystrix</h4>
<p>熔断器，容错管理工具，旨在通过熔断机制控制服务和第三方库的节点,从而对延迟和故障提供更强大的容错能力。比如突然某个小弟生病了，但是你还需要它的支持，然后调用之后它半天没有响应，你却不知道，一直在等等这个响应；有可能别的小弟也正在调用你的武功绝技，那么当请求多之后，就会发生严重的阻塞影响老大的整体计划。这个时候Hystrix就派上用场了，当Hystrix发现某个小弟不在状态不稳定立马马上让它下线，让其它小弟来顶上来，或者给你说不用等了这个小弟今天肯定不行，该干嘛赶紧干嘛去别在这排队了。</p>
<h4 id="netflix-zuul">Netflix Zuul</h4>
<p>Zuul  是在云平台上提供动态路由,监控,弹性,安全等边缘服务的框架。Zuul 相当于是设备和 Netflix 流应用的 Web  网站后端所有请求的前门。当其它门派来找大哥办事的时候一定要先经过zuul,看下有没有带刀子什么的给拦截回去，或者是需要找那个小弟的直接给带过去。</p>
<h4 id="netflix-archaius">Netflix Archaius</h4>
<p>配置管理API，包含一系列配置管理API，提供动态类型化属性、线程安全配置操作、轮询框架、回调机制等功能。可以实现动态获取配置，   原理是每隔60s（默认，可配置）从配置源读取一次内容，这样修改了配置文件后不需要重启服务就可以使修改后的内容生效，前提使用archaius的API来读取。</p>
<h1 id="eureka和ribbon">Eureka和Ribbon</h1>
<h3 id="单机模式的eureka和ribbon">单机模式的Eureka和Ribbon</h3>
<h4 id="前置工作">前置工作</h4>
<h5 id="1首先是依赖的搭配使用">1.首先是依赖的搭配使用</h5>
<p>详细介绍参见<a href="https://spring.io/projects/spring-cloud">Springcloud依赖版本搭配配置参见</a></p>
<h5 id="2然后再公用模块加依赖">2.然后再公用模块加依赖</h5>
<pre><code class="language-xml">  &lt;properties&gt;
        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;
        &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt;
        &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt;
        &lt;springboot.version&gt;2.1.6.RELEASE&lt;/springboot.version&gt;
        &lt;springcloud.version&gt;Greenwich.SR2&lt;/springcloud.version&gt;
    &lt;/properties&gt;
    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;junit&lt;/groupId&gt;
            &lt;artifactId&gt;junit&lt;/artifactId&gt;
            &lt;version&gt;4.12&lt;/version&gt;
            &lt;scope&gt;test&lt;/scope&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;
            &lt;artifactId&gt;lombok&lt;/artifactId&gt;
            &lt;version&gt;1.18.10&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt;
            &lt;artifactId&gt;logback-classic&lt;/artifactId&gt;
            &lt;version&gt;1.2.3&lt;/version&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;
    &lt;dependencyManagement&gt;
        &lt;dependencies&gt;
            &lt;dependency&gt;
                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
                &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;
                &lt;!-- 注意：SpringCloud最新的Greenwich版本是基于SpringBoot2.1.x(Greenwich)版本构建的
                    所以这里不支持SpringBoot2.2.x版本
                    具体SpringBoot与SpringCloud版本对应关系参见：https://spring.io/projects/spring-cloud页面最下方的Release Trains
                 --&gt;
                &lt;!--&lt;version&gt;2.2.1.RELEASE&lt;/version&gt;--&gt;
                &lt;version&gt;${springboot.version}&lt;/version&gt;
                &lt;type&gt;pom&lt;/type&gt;
                &lt;scope&gt;import&lt;/scope&gt;
            &lt;/dependency&gt;

            &lt;dependency&gt;
                &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
                &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt;
                &lt;version&gt;${springcloud.version}&lt;/version&gt;
                &lt;type&gt;pom&lt;/type&gt;
                &lt;scope&gt;import&lt;/scope&gt;
            &lt;/dependency&gt;
        &lt;/dependencies&gt;
    &lt;/dependencyManagement&gt;
</code></pre>
<h3 id="然后创建euraka-server模块">然后创建Euraka-server模块</h3>
<h4 id="1创建项目启动类">1.创建项目启动类</h4>
<pre><code class="language-java">@SpringBootApplication
//这是开启Eureka的注解
@EnableEurekaServer
public class EurekaApplication {
    public static void main(String[] args) throws IOException {
        SpringApplication.run(EurekaApplication.class,args);
    }
}

</code></pre>
<p>需要注意的是,这两个注解一个是统用的,一个是专用的.</p>
<pre><code class="language-java">@EnableDiscoveryClient
@EnableEurekaServer
</code></pre>
<h4 id="2然后配置下yml文件">2.然后配置下yml文件</h4>
<pre><code class="language-yml">server:
  port: 8761

spring:
  application:
    name: eureka-server
eureka:
  instance:
    prefer-ip-address: true
    hostname: localhost
  client:
 # 这个是要不要注册当前的服务注册到eureka中
    register-with-eureka: false
 # 是否从eureka中拉取服务表,即当前服务取注册中心拉取服务   
    fetch-registry: false
    service-url:
      defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/
</code></pre>
<p>[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-nmBlNO8h-1576064827399)(D:\总结\springcloud\eureks名字.png)]</p>
<h4 id="3启动项目访问eureka日志中的地址出现管理界面">3.启动项目访问Eureka日志中的地址出现管理界面</h4>
<h3 id="创建服务提供者">创建服务提供者</h3>
<h4 id="1创建模块启动类">1.创建模块启动类</h4>
<pre><code class="language-java">@SpringBootApplication
@EnableEurekaClient
public class EurekaProviderApplication {
    public static void main(String[] args) {
        SpringApplication.run(EurekaProviderApplication.class,args);
    }
}

</code></pre>
<h4 id="2配置yml文件">2.配置yml文件</h4>
<pre><code class="language-yml">spring:
  application:
    name: eureka-provider

eureka:
#  这个是客户端的配置
  client:
#    这个是是否把当前服务注册到注册中心
    register-with-eureka: true
#    这个是是否要拉取服务,一般在集群中用到
    fetch-registry: false
    service-url:
#      这个是服务要提交服务所到的地址,同时也是eureka在浏览器的访问地址,一般是和eureka的server保持一致,
#      表明提交服务到的地址是eureka-server的地址
      defaultZone: http://${eureka.instance.hostname}:8761/eureka/
#      这个是实例,即你的服务的相关配置
  instance:
    hostname: localhost
    prefer-ip-address: true
#    这个是实例在注册中心的id
    instance-id: ${spring.application.name}:${spring.application.instance_id:${server.port}}
server:
  port: 8082
</code></pre>
<h4 id="3启动模块查看eureka控制home实例">3.启动模块,查看eureka控制home实例</h4>
<h3 id="创建consumer模块">创建consumer模块</h3>
<h4 id="1创建模块启动类-2">1.创建模块启动类</h4>
<pre><code class="language-java">@SpringBootApplication
@EnableEurekaClient
public class EurekaConsumerApplication {
    public static void main(String[] args) {
        SpringApplication.run(EurekaConsumerApplication.class,args);
    }
}
</code></pre>
<h4 id="2配置yml文件-2">2.配置yml文件</h4>
<pre><code class="language-yml">server:
  port: 8081

spring:
  application:
    name: eureka-consumer

eureka:
  client:
#    这个是要把服务注册到eureka-server的地址
    service-url: http://${eureka.instance.hostname}:8761/eureka/
#      这个是是否把自己的服务注册到注册中心
    register-with-eureka: true
#    这个是启动时是否拉取服务列表
    fetch-registry: false
  instance:
    hostname: localhost
    instance-id: ${spring.application.name}:${spring.application.instance_id:${server.port}}
#     在某些情况下，Eureka优先使用IP地址而不是主机名
#    。设置为true，当应用程序向eureka注册时，它将使用其IP地址而不是其主机名
    prefer-ip-address: true

</code></pre>
<h4 id="3启动模块查看服务是否注册成功">3.启动模块查看服务是否注册成功.</h4>
<h4 id="4访问localhost8081看服务有问题否">4.访问localhost:8081,看服务有问题否</h4>
<h2 id="出现的问题总结">出现的问题总结:</h2>
<h3 id="1ribbon的理解">1.Ribbon的理解</h3>
<p>​		**ribbon:**是在客户端的负载均衡,也就是说ribbon的负载均衡不在服务端,而是在客户端,这样它启动后就是先拉取服务,放在缓存中,,第二次用的就是缓存中的服务列表,然后即使服务器挂了,本地还有缓存中的服务列表,短暂的也不会影响客户端的使用</p>
<p>​		这样上面的配置就有问题:fetch-registry: false:表示不拉取服务,这样就会访问localhost:8081出现500错误,错误信息是没有instances可用,所以把fetch-registry: true即可则会正常访问</p>
<h1 id="eureka集群的搭建">Eureka集群的搭建</h1>
<p>模块的启动类:注意启动不同的节点要改变生产环境</p>
<pre><code class="language-java">@SpringBootApplication
@EnableEurekaServer
public class EurekaCloudApplication {
    public static void main(String[] args) {
        SpringApplication.run(EurekaCloudApplication.class,args);
    }
}

</code></pre>
<p>主要的配置文件如下:</p>
<p>这样节能直接启动:</p>
<p>​     <strong>注意:</strong> 1.启动不同的节点要改变生产环境</p>
<p>​				2.注意节点启动时会报错,因为还没启动完,最后一个启动不会报错,因为他们之间会互相拉取数据.</p>
<pre><code class="language-yml">spring:
  application:
    name:eureka-cloud-server
  profiles:
    active:

#eureka集群的搭建
eureka:
  client:
#    首先这两个要打开,一个是把当前服务注册到注册中心,一个是拉取其他注册中心的服务
#    高可用
    fetch-registry: true
    register-with-eureka: true
  instance:
    prefer-ip-address: true

---

spring:
  profiles: dev

eureka:
  client:
    service-url:
      defaultZone: http://ip2:port/eureka/,http://ip3:port/eureka/
  instance:
  instance:
    hostname: 主机的ip或主机名

---
spring:
  profiles: node1

eureka:
  client:
    service-url: 
      defaultZone: http://ip1:port/eureka/,http://ip3:port/eureka/
  instance:
    hostname: 主机的ip或主机名
---
spring:
  profiles: node2

eureka:
  client:
    service-url:
      defaultZone: http://ip1:port/eureka/,http://ip2:port/eureka/
  instance:
    hostname: 主机的ip或主机名
</code></pre>
<h1 id="spring-cloud">Spring-Cloud</h1>
<h2 id="netflix-feign组件">netflix---Feign(组件)</h2>
<h3 id="使用底层封装了httpclient">使用:底层封装了HttpClient</h3>
<h4 id="1添加依赖">1.添加依赖</h4>
<pre><code class="language-xml">      &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-starter-feign&lt;/artifactId&gt;
            &lt;version&gt;1.4.6.RELEASE&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
        &lt;/dependency&gt;

</code></pre>
<h4 id="2模块启动类">2.模块启动类</h4>
<pre><code class="language-java">@SpringBootApplication
//@EnableEurekaClient
@EnableFeignClients
public class EurekaFeignConsumerApplication {
    public static void main(String[] args) {
        SpringApplication.run(EurekaFeignConsumerApplication.class,args);
    }
}

</code></pre>
<h4 id="3service层的使用">3.service层的使用</h4>
<pre><code class="language-java">@FeignClient(&quot;eureka-provider:8082&quot;)
@Service
public interface CalcService {
    @GetMapping(&quot;/calc/add/{num1}/{num2}&quot;)
    public ResponseInfo add(@PathVariable(&quot;num1&quot;) int num1, @PathVariable(&quot;num2&quot;) int num2);
}
</code></pre>
<p>4.controller层</p>
<pre><code class="language-java">@Controller
@RequestMapping(&quot;/calc&quot;)
@Slf4j
public class CalcController {


    @Autowired
    private CalcService calcService;

    @RequestMapping(&quot;/add&quot;)
    public String add(@RequestParam int num1, @RequestParam int num2, Model model) {

        System.out.println(num1+ &quot;    &quot; + num2);
        // 以前使用SpringMVC方式，直接通过IP+端口号来调用服务
//        ResponseEntity&lt;ResponseInfo&gt; entity = restTemplate.getForEntity(&quot;http://localhost:8081/calc/add/&quot;+num1+&quot;/&quot;+num2, ResponseInfo.class);
        // 引入Ribbon后，通过微服务ID访问远程服务
//        ResponseEntity&lt;ResponseInfo&gt; entity = restTemplate.getForEntity(&quot;http://eureka-provider:8082/calc/add/&quot;+num1+&quot;/&quot;+num2, ResponseInfo.class);
        ResponseInfo info = calcService.add(num1, num2);
//        ResponseInfo info = entity.getBody();
        Map data = (Map) info.getData();
        model.addAttribute(&quot;result&quot;, data.get(&quot;result&quot;));
        model.addAttribute(&quot;num1&quot;, num1);
        model.addAttribute(&quot;num2&quot;, num2);

        return &quot;index&quot;;
    }
}

</code></pre>
<p>4.yml的配置</p>
<pre><code class="language-yml">spring:
  application:
    name: eureka-feign-consumer

eureka:
  #  这个是客户端的配置
  client:
    #    这个是是否把当前服务注册到注册中心
    register-with-eureka: true
    #    这个是是否要拉取服务,一般在集群中用到
    fetch-registry: true
    service-url:
      #      这个是服务要提交服务所到的地址,同时也是eureka在浏览器的访问地址,一般是和eureka的server保持一致,
      #      表明提交服务到的地址是eureka-server的地址
      defaultZone: http://${eureka.instance.hostname}:8761/eureka/
  #      这个是实例,即你的服务的相关配置
  instance:
    hostname: localhost
    prefer-ip-address: true
    #    这个是实例在注册中心的id
    instance-id: ${spring.application.name}:${spring.application.instance_id:${server.port}}
server:
  port: 8088
  
feign:
  client:
    config:
      #      calc-service-provider:  这一级可以写具体的微服务名称或者default，default代表全局配置，影响所有微服务的调用
      default:
        connectTimeout: 1000
        readTimeout: 2000  
</code></pre>
<h4 id="5提供者和eureka服务的创建">5.提供者和Eureka服务的创建</h4>
<h1 id="spring-cloud-hystrix组件">Spring-Cloud---hystrix(组件)</h1>
<p><strong>两种方式分别是:hystrix和riboon的整合使用;hystrix和feign整合使用</strong></p>
<h2 id="hystrix熔断器和ribbon的整合使用">Hystrix(熔断器)和Ribbon的整合使用</h2>
<p>​		Hystrix和ribbon的使用主要是hystrix和ReatTemplate的使用.</p>
<p>什么是hystrix?</p>
<blockquote>
<p>在分布式环境中，许多服务依赖项中的一些不可避免地会失败。<br>
Hystrix是一个库，可通过添加延迟容错和容错逻辑来帮助您控制这些分布式服务之间的交互。<br>
Hystrix通过隔离服务之间的访问点，阻止它们之间的级联故障以及提供后备选项来实现这一目标，这些都可以提高系统的整体恢复能力</p>
</blockquote>
<blockquote>
<p>通俗的说Hystrix是Netflix公司开源的一个用于服务调用的断路器组件，给我们提供了包括服务熔断、降级、超时、资源隔离在内的完整解决方案。</p>
</blockquote>
<h2 id="具体使用">具体使用</h2>
<h3 id="1导入用到的依赖">1.导入用到的依赖</h3>
<pre><code class="language-xml">    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;
            &lt;version&gt;2.1.2.RELEASE&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;
</code></pre>
<h3 id="2启动类开启hystrix熔断">2.启动类开启Hystrix熔断</h3>
<pre><code class="language-java">@SpringBootApplication
@EnableCircuitBreaker //开启熔断
@EnableEurekaClient
public class HystrixRestTemplateApplication {
    @LoadBalanced //tibbon的使用,主要用来请求远程服务和负载均衡使用
    @Bean
    public RestTemplate restTemplate(){
        return new RestTemplate();
    }
    public static void main(String[] args) {
        SpringApplication.run(HystrixRestTemplateApplication.class,args);
    }
}

</code></pre>
<h3 id="3web控制层的使用">3.web控制层的使用</h3>
<pre><code class="language-java">/**
 * 计算器
 */
@Controller
@RequestMapping(&quot;/calc&quot;)
@Slf4j
public class CalcController {
    @Autowired
    private RestTemplate restTemplate;
    /**
     * 下面是熔断的使用
     * @param num1
     * @param num2
     * @param model
     * @return
     */
    @HystrixCommand(
            /**
             * 这是熔断点的定义
            */
            fallbackMethod = &quot;addFallback&quot;,
            /**
             * commandKey用于在Properties文件中配置此Command的参数，也可以直接用注解在这里配置参数
            */
            commandKey = &quot;calc_add_command&quot;
    )
    @RequestMapping(&quot;/add&quot;)
    public String add(@RequestParam int num1, @RequestParam int num2, Model model) {

        System.out.println(num1+ &quot;    &quot; + num2);
        // 以前使用SpringMVC方式，直接通过IP+端口号来调用服务
//        ResponseEntity&lt;ResponseInfo&gt; entity = restTemplate.getForEntity(&quot;http://localhost:8081/calc/add/&quot;+num1+&quot;/&quot;+num2, ResponseInfo.class);
        // 引入Ribbon后，通过微服务ID访问远程服务
        ResponseEntity&lt;ResponseInfo&gt; entity = restTemplate.getForEntity(&quot;http://eureka-provider:8082/calc/add/&quot;+num1+&quot;/&quot;+num2, ResponseInfo.class);
        ResponseInfo info = entity.getBody();
        Map data = (Map) info.getData();

        model.addAttribute(&quot;result&quot;, data.get(&quot;result&quot;));
        model.addAttribute(&quot;num1&quot;, num1);
        model.addAttribute(&quot;num2&quot;, num2);
        return &quot;index&quot;;
    }
    /**
     * 熔断方法,当服务发生熔断是调用此方法
     * @param num1
     * @param num2
     * @param model
     * @return
     */
    public String addFallback(@RequestParam int num1, @RequestParam int num2, Model model){
        model.addAttribute(&quot;num1&quot;, num1);
        model.addAttribute(&quot;num2&quot;, num2);
        model.addAttribute(&quot;result&quot;, &quot;-1&quot;);
        return &quot;index&quot;;
    }
}
</code></pre>
<p><strong>注意</strong>:这里的 @HystrixCommand中的参数commandkey的使用是,用于在Properties文件中配置此Command的参数，也可以直接用注解在这里配置参数.</p>
<h3 id="4最重要的yml中的配置">4.最重要的yml中的配置</h3>
<pre><code class="language-yml">spring:
  application:
    name: eureka-consumer-rest_template-hystrix
    
eureka:
  #  这个是客户端的配置
  client:
    #    这个是是否把当前服务注册到注册中心
    register-with-eureka: true
    #    这个是是否要拉取服务,一般在集群中用到
    fetch-registry: true
    service-url:
      #      这个是服务要提交服务所到的地址,同时也是eureka在浏览器的访问地址,一般是和eureka的server保持一致,
      #      表明提交服务到的地址是eureka-server的地址
      defaultZone: http://${eureka.instance.hostname}:8761/eureka/
  #      这个是实例,即你的服务的相关配置
  instance:
    hostname: localhost
    prefer-ip-address: true
    #    这个是实例在注册中心的id
    instance-id: ${spring.application.name}:${spring.application.instance_id:${server.port}}
    # hystrix中的核心配置
hystrix:
  command:
    calc_add_command:
      execution:
        isolation:
          thread:
            timeoutInMilliseconds: 2000 #设置熔断器判定超时的时间，超过此时间的请求会执行降级逻辑，默认1s
      circuitBreaker:
        requestVolumeThreshold: 2 #设置熔断阈值，在熔断统计窗口期内，错误请求（超时、异常）次数达到阈值就会触发熔断，执行降级逻辑，默认20
        sleepWindowInMilliseconds: 10000  #设置熔断器多久进入半开状态，然后再次尝试确定熔断器是否应再次关闭，默认5s
        errorThresholdPercentage: 50  #设置在熔断统计窗口期内，错误请求达到百分之多少触发熔断，默认50
      metrics:
        rollingStats:
          timeInMilliseconds: 5000 #熔断度量窗口期时间， 默认10s
server:
  port: 8099
</code></pre>
<h3 id="5启动项目测试">5.启动项目测试</h3>
<h2 id="hystrix和feign的整合使用">Hystrix和Feign的整合使用</h2>
<h3 id="1导入依赖">1.导入依赖</h3>
<pre><code class="language-xml">&lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;
</code></pre>
<h3 id="2web控制层">2.web控制层</h3>
<pre><code class="language-java">@Controller
@RequestMapping(&quot;/calc&quot;)
@Slf4j
public class CalcController {
    @Autowired
    private CalcService calcService;

    @RequestMapping(&quot;/add&quot;)
    public String add(@RequestParam int num1, @RequestParam int num2, Model model) {
        System.out.println(num1+ &quot;    &quot; + num2);
        // 以前使用SpringMVC方式，直接通过IP+端口号来调用服务
//        ResponseEntity&lt;ResponseInfo&gt; entity = restTemplate.getForEntity(&quot;http://localhost:8081/calc/add/&quot;+num1+&quot;/&quot;+num2, ResponseInfo.class);
        // 引入Ribbon后，通过微服务ID访问远程服务
//        ResponseEntity&lt;ResponseInfo&gt; entity = restTemplate.getForEntity(&quot;http://eureka-provider:8082/calc/add/&quot;+num1+&quot;/&quot;+num2, ResponseInfo.class);
        ResponseInfo info = calcService.add(num1, num2);
//        ResponseInfo info = entity.getBody();
        Map data = (Map) info.getData();
        model.addAttribute(&quot;result&quot;, data.get(&quot;result&quot;));
        model.addAttribute(&quot;num1&quot;, num1);
        model.addAttribute(&quot;num2&quot;, num2);
        return &quot;index&quot;;
    }
}
</code></pre>
<h3 id="3service层">3.service层</h3>
<pre><code class="language-java">@FeignClient(value = &quot;eureka-provider:8082&quot;,fallback = FallbackClient.class)
@Service
public interface CalcService {
    @GetMapping(&quot;/calc/add/{num1}/{num2}&quot;)
    public ResponseInfo add(@PathVariable(&quot;num1&quot;) int num1,@PathVariable(&quot;num2&quot;) int num2);
}
</code></pre>
<p>需要注意的是fallback熔断方法的实现要和实现的接口的请求地址分开,因为实现接口会默认继承GetMappig 的请求地址,防止出现暧昧关系</p>
<p>熔断方法</p>
<pre><code class="language-java">@Component
@RequestMapping(&quot;/fallback&quot;)
public class FallbackClient implements CalcService {
    @Override
    public ResponseInfo add(int num1, int num2) {
        Map data = new HashMap();
        data.put(&quot;num1&quot;, num1);
        data.put(&quot;num2&quot;, num2);
        data.put(&quot;result&quot;, -1);
        ResponseInfo responseInfo = new ResponseInfo(203,  &quot;降级结果&quot;, data);
        return responseInfo;
    }
}
</code></pre>
<h3 id="4配置文件">4.配置文件</h3>
<pre><code class="language-yml">spring:
  application:
    name: eureka-consumer-feign-hystrix


eureka:
  #  这个是客户端的配置
  client:
    #    这个是是否把当前服务注册到注册中心
    register-with-eureka: true
    #    这个是是否要拉取服务,一般在集群中用到
    fetch-registry: true
    service-url:
      #      这个是服务要提交服务所到的地址,同时也是eureka在浏览器的访问地址,一般是和eureka的server保持一致,
      #      表明提交服务到的地址是eureka-server的地址
      defaultZone: http://${eureka.instance.hostname}:8761/eureka/
  #      这个是实例,即你的服务的相关配置
  instance:
    hostname: localhost
    prefer-ip-address: true
    #    这个是实例在注册中心的id
    instance-id: ${spring.application.name}:${spring.application.instance_id:${server.port}}

hystrix:
  command:
#    default:  # 设置全局熔断参数
    CalcService#add(int,int): #设置某个feign client的熔断参数
      execution:
        isolation:
          thread:
            timeoutInMilliseconds: 2000 #设置熔断器判定超时的时间，超过此时间的请求会执行降级逻辑，默认1s
        circuitBreaker:
          requestVolumeThreshold: 2 #设置熔断阈值，在熔断统计窗口期内，错误请求（超时、异常）次数达到阈值就会触发熔断，执行降级逻辑，默认20
          sleepWindowInMilliseconds: 10000  #设置熔断器多久进入半开状态，然后再次尝试确定熔断器是否应再次关闭，默认5s
          errorThresholdPercentage: 50  #设置在熔断统计窗口期内，错误请求达到百分之多少触发熔断，默认50
        metrics:
          rollingStats:
            timeInMilliseconds: 5000 #熔断度量窗口期时间， 默认10s

feign:
  client:
    config:
      #      calc-service-provider:  这一级可以写具体的微服务名称或者default，default代表全局配置，影响所有微服务的调用
      default:
        connectTimeout: 1000
        readTimeout: 2000
  hystrix:
    enabled: true
server:
  port: 8100

</code></pre>
<h3 id="5需要注意的问题">5.需要注意的问题</h3>
<p>​		在feign中默认的hystrix是默认关闭的,如果不打开的话,会出现找不到fallback的错误,错误类型是500.</p>
<h1 id="监控工具">监控工具</h1>
<h2 id="springboot-actuator">SpringBoot Actuator</h2>
<p>SpringBoot Actuactor是SpringBoot提供的一个监控工具，通过他我们可以看到应用运行工程中的很多有用的信息：</p>
<table>
<thead>
<tr>
<th style="text-align:left">ID</th>
<th style="text-align:left">Description</th>
<th style="text-align:left">Enabled by default</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">auditevents</td>
<td style="text-align:left">Exposes audit events information for the current application.</td>
<td style="text-align:left">Yes</td>
</tr>
<tr>
<td style="text-align:left">beans</td>
<td style="text-align:left">Displays a complete list of all the Spring beans in your application.</td>
<td style="text-align:left">Yes</td>
</tr>
<tr>
<td style="text-align:left">conditions</td>
<td style="text-align:left">Shows the conditions that were evaluated on configuration and auto-configuration classes and the reasons why they did or did not match.</td>
<td style="text-align:left">Yes</td>
</tr>
<tr>
<td style="text-align:left">configprops</td>
<td style="text-align:left">Displays a collated list of all <code class="literal">@ConfigurationProperties</code>.</td>
<td style="text-align:left">Yes</td>
</tr>
<tr>
<td style="text-align:left">env</td>
<td style="text-align:left">Exposes properties from Spring’s <code class="literal">ConfigurableEnvironment</code>.</td>
<td style="text-align:left">Yes</td>
</tr>
<tr>
<td style="text-align:left">flyway</td>
<td style="text-align:left">Shows any Flyway database migrations that have been applied.</td>
<td style="text-align:left">Yes</td>
</tr>
<tr>
<td style="text-align:left">health</td>
<td style="text-align:left">Shows application health information.</td>
<td style="text-align:left">Yes</td>
</tr>
<tr>
<td style="text-align:left">httptrace</td>
<td style="text-align:left">Displays HTTP trace information (by default, the last 100 HTTP request-response exchanges).</td>
<td style="text-align:left">Yes</td>
</tr>
<tr>
<td style="text-align:left">info</td>
<td style="text-align:left">Displays arbitrary application info.</td>
<td style="text-align:left">Yes</td>
</tr>
<tr>
<td style="text-align:left">loggers</td>
<td style="text-align:left">Shows and modifies the configuration of loggers in the application.</td>
<td style="text-align:left">Yes</td>
</tr>
<tr>
<td style="text-align:left">liquibase</td>
<td style="text-align:left">Shows any Liquibase database migrations that have been applied.</td>
<td style="text-align:left">Yes</td>
</tr>
<tr>
<td style="text-align:left">metrics</td>
<td style="text-align:left">Shows ‘metrics’ information for the current application.</td>
<td style="text-align:left">Yes</td>
</tr>
<tr>
<td style="text-align:left">mappings</td>
<td style="text-align:left">Displays a collated list of all <code class="literal">@RequestMapping paths</code>.</td>
<td style="text-align:left">Yes</td>
</tr>
<tr>
<td style="text-align:left">scheduledtasks</td>
<td style="text-align:left">Displays the scheduled tasks in your application.</td>
<td style="text-align:left">Yes</td>
</tr>
<tr>
<td style="text-align:left">sessions</td>
<td style="text-align:left">Allows retrieval and deletion of user sessions from a Spring Session-backed session store. Not available when using Spring Session’s support for reactive web applications.</td>
<td style="text-align:left">Yes</td>
</tr>
<tr>
<td style="text-align:left">shutdown</td>
<td style="text-align:left">Lets the application be gracefully shutdown.</td>
<td style="text-align:left">No</td>
</tr>
<tr>
<td style="text-align:left">threaddump</td>
<td style="text-align:left">Performs a thread dump.</td>
<td style="text-align:left">Yes</td>
</tr>
</tbody>
</table>
<p><font color="orange">如果应用是一个Web应用（指引入了SpringMVC、Spring WebFlux或者Jersey），就可以用下面这些监控端点</font></p>
<table>
<thead>
<tr>
<th style="text-align:left">ID</th>
<th style="text-align:left">Description</th>
<th style="text-align:left">Enabled by default</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">heapdump</td>
<td style="text-align:left">Returns an hprof heap dump file.</td>
<td style="text-align:left">Yes</td>
</tr>
<tr>
<td style="text-align:left">jolokia</td>
<td style="text-align:left">Exposes JMX beans over HTTP (when Jolokia is on the classpath, not available for WebFlux).</td>
<td style="text-align:left">Yes</td>
</tr>
<tr>
<td style="text-align:left">logfile</td>
<td style="text-align:left">Returns the contents of the logfile (if logging.file or logging.path properties have been set). Supports the use of the HTTP Range header to retrieve part of the log file’s content.</td>
<td style="text-align:left">Yes</td>
</tr>
<tr>
<td style="text-align:left">prometheus</td>
<td style="text-align:left">Exposes metrics in a format that can be scraped by a Prometheus server.</td>
<td style="text-align:left">Yes</td>
</tr>
</tbody>
</table>
<p>除了上面列出来的，其他第三方模块还会提供一些特有的监控端点，如zuul提供的/routes</p>
<h1 id="springcloud-zuul路由网关">Springcloud-zuul(路由网关)</h1>
<h2 id="zuul介绍">Zuul介绍</h2>
<blockquote>
<p>Zuul是Netflx开源的微服务网关。可以和Eureka、Ribbon、Hystrix配合使用，一个主要的功能就是可以将后端众多的微服务屏蔽、整合，对前端提供一套统一的服务(有点像是后端的Facade)。</p>
</blockquote>
<p>Zuul提供了以下几项支持：</p>
<ul>
<li>认证安全: 识别每一个资源的验证要求，并拒绝那些不符的请求</li>
<li>监控</li>
<li>动态路由: 动态将请求路由到不同后端集群</li>
<li>压力测试: 逐渐增加指向集群的流量，以了解性能</li>
<li>金丝雀测试: 灰度发布</li>
<li>流量控制: 为每一种负载类型分配对应容量，并弃用超出限定值的请求</li>
<li>服务迁移</li>
<li>静态资源响应处理: 边缘位置进行响应，避免转发到内部集群</li>
</ul>
<h2 id="zuul用的地方是">zuul用的地方是</h2>
<p>一般用在服务的提供者</p>
<h3 id="1加依赖">1.加依赖</h3>
<pre><code class="language-xml">     &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;
        &lt;/dependency&gt;
</code></pre>
<h3 id="2创建springcloud-zuul">2.创建springcloud-zuul</h3>
<pre><code class="language-java">@SpringBootApplication
@EnableZuulProxy
@EnableEurekaClient
public class ZuulApplication {
    public static void main(String[] args) {
        SpringApplication.run(ZuulApplication.class, args);
    }

}
</code></pre>
<h3 id="3配置">3.配置</h3>
<pre><code class="language-yml">server:
  port: 10003
spring:
  application:
    name: zuul-server

eureka:
  #  这个是客户端的配置
  client:
    #    这个是是否把当前服务注册到注册中心
    register-with-eureka: true
    #    这个是是否要拉取服务,一般在集群中用到
    fetch-registry: true
    service-url:
      #      这个是服务要提交服务所到的地址,同时也是eureka在浏览器的访问地址,一般是和eureka的server保持一致,
      #      表明提交服务到的地址是eureka-server的地址
      defaultZone: http://${eureka.instance.hostname}:8761/eureka/
  #      这个是实例,即你的服务的相关配置
  instance:
    hostname: localhost
    prefer-ip-address: true
    #    这个是实例在注册中心的id
    instance-id: ${spring.application.name}:${spring.application.instance_id:${server.port}}
management:
  endpoints:
    web:
      exposure:
        include: &quot;*&quot;
zuul:
  routes:
    # 这种方式配置路由规则：前面的key是微服务名称，后面是匹配路径
    #    calc-service-provider: /calcApi/**
    # 这种方式配置路由规则：第一级的key可以随便取（路由名称），下面可以配置更多key、value（相比上面一种配置更强大）
    calc-proxy:
      serviceId: eureka-provider # 有效的微服务名称
      path: /calc/**  # 访问路径
      strip-prefix: false # 是否在网关层面消耗掉指定服务的路由规则前缀
    #    taotao-rest-proxy:
    #      serviceId: taotao-rest
    #      path: /rest/**

</code></pre>
<p><strong>注意上上面的strip-prefix: 值的用法</strong></p>
<p>1.上面的strip-prefix: false设置false代表你访问**localhost:10003/calc/****会跳转到对应的服务是eureka-provider,然后到注册中心找到对应的服务,localhost:8082/calc/add/55/66</p>
<pre><code>2.   上面的strip-prefix: false设置false代表你访问localhost:**10003/calc/calc/****会跳转到对应的服务是eureka-provider,然后到注册中心找到对应的服务,localhost:8082/calc/add/55/66
</code></pre>
<h3 id="代理传统的服务">代理传统的服务</h3>
<p>配置如下</p>
<pre><code class="language-yml">server:
  port: 9100
spring:
  application:
    name: zuul-server

eureka:
  client:
    service-url:
      defaultZone: http://${eureka.instance.hostname}:${eureka.client.eureka-server-port}/eureka/
    eureka-server-port: 8761
  instance:
    prefer-ip-address: true #在某些情况下，Eureka优先使用IP地址而不是主机名。设置为true，当应用程序向eureka注册时，它将使用其IP地址而不是其主机名
    instance-id: ${spring.application.name}:${spring.application.instance_id:${server.port}}
    hostname: node1.john.com

management:
  endpoints:
    web:
      exposure:
        include: &quot;*&quot;

zuul:
  routes:
    # 这种方式配置路由规则：前面的key是微服务名称，后面是匹配路径
#    calc-service-provider: /calcApi/**
    # 这种方式配置路由规则：第一级的key可以随便取（路由名称），下面可以配置更多key、value（相比上面一种配置更强大）
    calc-proxy:
      serviceId: calc-service-provider # 有效的微服务名称
      path: /calc/**  # 访问路径
      strip-prefix: false # 是否在网关层面消耗掉指定服务的路由规则前缀
      #代理传统的服务:
#    taotao-rest-proxy:
#      serviceId: taotao-rest
#      path: /rest/**
    taotao-rest-proxy-forward: # 使用forward本地转发(就是将匹配到路由规则的请求，转发到网关本地应用中去处理)
      path: /rest-f/**
      url: forward:/rest
    # 比如浏览器访问：http://localhost:9100/api/rest-f/content/getall/89
    # 会被转发到：http://localhost:9100/rest/content/getall/89


  ignored-services: &quot;*&quot; # 忽略所有未显示配置路由规则的微服务
  prefix: /api
  strip-prefix: true  # 是否在网关层面消耗掉全局前缀


# 使用Zuul代理未接入Eureka的传统服务
taotao-rest:
  ribbon:
    NIWSServerListClassName: com.netflix.loadbalancer.ConfigurationBasedServerList #如果不配置ServerList类型为ConfigurationBasedServerList的话就需要禁用ribbon的eureka支持
    ConnectTimeout: 500
    ReadTimeout: 2000
    listOfServers: http://localhost:8081

calc-service-provider:
  ribbon:
    ReadTimeout: 2000
    ConnectTimeout: 500

</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[ Mybatis实现批量插入]]></title>
        <id>https://yihuaikun.github.io/post/mybatis-shi-xian-pi-liang-cha-ru</id>
        <link href="https://yihuaikun.github.io/post/mybatis-shi-xian-pi-liang-cha-ru">
        </link>
        <updated>2019-08-23T15:39:49.000Z</updated>
        <content type="html"><![CDATA[<h1 id="mybatis实现批量插入">Mybatis实现批量插入</h1>
<p>环境配置</p>
<p>1.依赖</p>
<pre><code class="language-xml"> &lt;!-- https://mvnrepository.com/artifact/org.mybatis/mybatis --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.mybatis&lt;/groupId&gt;
            &lt;artifactId&gt;mybatis&lt;/artifactId&gt;
            &lt;version&gt;3.5.2&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;!-- https://mvnrepository.com/artifact/mysql/mysql-connector-java --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;mysql&lt;/groupId&gt;
            &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;
            &lt;version&gt;5.1.47&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;!-- https://mvnrepository.com/artifact/mysql/mysql-connector-java --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;mysql&lt;/groupId&gt;
            &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;
            &lt;version&gt;5.1.47&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;!-- https://mvnrepository.com/artifact/com.alibaba/druid --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;com.alibaba&lt;/groupId&gt;
            &lt;artifactId&gt;druid&lt;/artifactId&gt;
            &lt;version&gt;1.1.20&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;
            &lt;artifactId&gt;lombok&lt;/artifactId&gt;
            &lt;version&gt;1.18.10&lt;/version&gt;
        &lt;/dependency&gt;
</code></pre>
<p>2.application.xml中的配置</p>
<pre><code class="language-yml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;
&lt;!DOCTYPE configuration
        PUBLIC &quot;-//mybatis.org//DTD Config 3.0//EN&quot;
        &quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;&gt;
&lt;configuration&gt;
    &lt;properties resource=&quot;jdbc.properties&quot; /&gt;
    &lt;settings&gt;
        &lt;setting name=&quot;mapUnderscoreToCamelCase&quot; value=&quot;true&quot;/&gt;
&lt;!--        &lt;setting name=&quot;cacheEnabled&quot; value=&quot;true&quot;/&gt;--&gt;
&lt;!--        &lt;setting name=&quot;localCacheScope&quot; value=&quot;SESSION&quot;/&gt;--&gt;
    &lt;/settings&gt;
    &lt;environments default=&quot;development&quot;&gt;
        &lt;environment id=&quot;development&quot;&gt;
            &lt;transactionManager type=&quot;JDBC&quot;/&gt;
            &lt;dataSource type=&quot;POOLED&quot;&gt;
                &lt;property name=&quot;driver&quot; value=&quot;${jdbc.driver}&quot;/&gt;
                &lt;property name=&quot;url&quot; value=&quot;${jdbc.url}&quot;/&gt;
                &lt;property name=&quot;username&quot; value=&quot;${jdbc.user}&quot;/&gt;
                &lt;property name=&quot;password&quot; value=&quot;${jdbc.password}&quot;/&gt;
            &lt;/dataSource&gt;
        &lt;/environment&gt;
    &lt;/environments&gt;
    &lt;mappers&gt;
        &lt;mapper resource=&quot;mappers/studentMapper.xml&quot;/&gt;
        &lt;mapper resource=&quot;mappers/userMapper.xml&quot;/&gt;
    &lt;/mappers&gt;
&lt;/configuration&gt;
</code></pre>
<p>2.jdbc.properties</p>
<pre><code class="language-properties">jdbc.driver=com.mysql.jdbc.Driver
jdbc.url=jdbc:mysql://localhost/day03?characterEncoding=utf-8
jdbc.user=root
jdbc.password=123456
</code></pre>
<p>6.创建数据库student</p>
<h2 id="实现技术mybatis的动态sql">实现技术:Mybatis的动态sql</h2>
<h3 id="第一种是mapperxml中的foreach动态sql语句">第一种是mapper.xml中的foreach动态sql语句</h3>
<p>1.首先创建测试类:Student</p>
<pre><code class="language-java">@Setter
@Getter
@ToString
public class Student {
    private int sId;
    private String sName;
    private String sex;
    private int age;
    private String subject;
    private String phone;

    public Student() {
    }

    public Student(int sId, String sName, String sex, int age, String subject, String phone) {
        this.sId = sId;
        this.sName = sName;
        this.sex = sex;
        this.age = age;
        this.subject = subject;
        this.phone = phone;
    }

    public Student(String sName, String sex, int age, String subject, String phone) {
        this.sName = sName;
        this.sex = sex;
        this.age = age;
        this.subject = subject;
        this.phone = phone;
    }
    public Student(int sId, String sName) {
        this.sId = sId;
        this.sName = sName;
    }
}
</code></pre>
<p>2.然后创建mapper接口</p>
<pre><code class="language-java">public interface StudentMapper {
    int insert(List&lt;Student&gt; studentList);
}
</code></pre>
<p>3.然后配置mapper.xml</p>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;
&lt;!DOCTYPE mapper
        PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot;
        &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;
&lt;mapper namespace=&quot;com.lanou.mapper.StudentMapper&quot;&gt;

&lt;!--    &lt;cache/&gt;--&gt;
&lt;!--  这是测试forEach的第一种  --&gt;
    &lt;insert id=&quot;insert&quot; &gt;
        insert into student(s_name,sex,age,subject,phone) values
        &lt;foreach collection=&quot;list&quot; item=&quot;stu&quot; separator=&quot;,&quot; &gt;
           ( #{stu.sName},
            #{stu.sex},
            #{stu.age},
            #{stu.subject},
            #{stu.phone})
        &lt;/foreach&gt;
    &lt;/insert&gt;
&lt;/mapper&gt;
</code></pre>
<p>3.然后测试一下</p>
<pre><code class="language-java">    /**
     *这是测试forEach的第一种方法:
     */
    @Test
    public void testForEacher(){
        String xmlPath= &quot;mybatis-config.xml&quot;;
        try {
            InputStream inputStream = Resources.getResourceAsStream(xmlPath);
            SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream);
            //开启自动提交:如果不开启则会看到一级缓存的作用true
            SqlSession sqlSession = sqlSessionFactory.openSession();
            StudentMapper studentMapper = sqlSession.getMapper(StudentMapper.class);
            //String sName, String sex, int age, String subject, String phone
            List&lt;Student&gt; studentList = new ArrayList&lt;&gt;();
            Collections.addAll(studentList,
                    new Student(&quot;黄三&quot;,&quot;女&quot;,23,&quot;蓝翔挖掘机&quot;,&quot;11111111111&quot;),
                    new Student(&quot;黄四&quot;,&quot;男&quot;,20,&quot;蓝翔厨师&quot;,&quot;22222222222&quot;),
                    new Student(&quot;黄五&quot;,&quot;女&quot;,25,&quot;电大&quot;,&quot;33333333333&quot;)
                    );
            studentMapper.insert(studentList);
            //没有开启自动提交,就会对缓存进行操作,只有这样才能会提交缓存中的数据到数据库,更新数据.
            sqlSession.commit();
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
</code></pre>
<h3 id="第二种是简单的sql语句逻辑实现foreach">第二种是简单的sql语句,逻辑实现foreach</h3>
<p>1.mapper.xml中</p>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;
&lt;!DOCTYPE mapper
        PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot;
        &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;
&lt;mapper namespace=&quot;com.lanou.mapper.StudentMapper&quot;&gt;
    &lt;!--  这是forEacher的第二种  --&gt;
    &lt;insert id=&quot;insert2&quot; &gt;
        insert into student(s_name,sex,age,subject,phone) values
             (#{sName},
            #{sex},
            #{age},
            #{subject},
            #{phone})
    &lt;/insert&gt;
&lt;/mapper&gt;
</code></pre>
<p>2.然后定义mapper接口</p>
<pre><code class="language-java">public interface StudentMapper {
    int insert2(Student student);
}
</code></pre>
<p>3.然后测试</p>
<pre><code class="language-java">    /**
     * 这是forEach的第二种方法,和批处理
     */
    @Test
    public void testForEach2(){
        String xmlPath= &quot;mybatis-config.xml&quot;;
        try {
            InputStream inputStream = Resources.getResourceAsStream(xmlPath);
            SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream);
            //开启自动提交:如果不开启则会看到一级缓存的作用true
            //ExecutorType默认是simple一条一执行,还有就是batch使用这个得  sqlSession.flushStatements()才会提交数据

            SqlSession sqlSession = sqlSessionFactory.openSession(ExecutorType.BATCH,true);
            StudentMapper studentMapper = sqlSession.getMapper(StudentMapper.class);
            //String sName, String sex, int age, String subject, String phone
            List&lt;Student&gt; studentList = new ArrayList&lt;&gt;();
            Collections.addAll(studentList,
                    new Student(&quot;黄三&quot;,&quot;女&quot;,23,&quot;蓝翔挖掘机&quot;,&quot;11111111111&quot;),
                    new Student(&quot;黄四&quot;,&quot;男&quot;,20,&quot;蓝翔厨师&quot;,&quot;22222222222&quot;),
                    new Student(&quot;黄五&quot;,&quot;女&quot;,25,&quot;电大&quot;,&quot;33333333333&quot;)
            );

//            对缓存的操作之批量插入:
            int count = 0;
            for(Student student : studentList ){
                studentMapper.insert2(student);
                count++;
                if(count % 2 == 0){
                    sqlSession.flushStatements();
                }
            }
//          对剩余得处理:
            if(count % 2 != 0){
               sqlSession.flushStatements();
            }
            //没有开启自动提交,就会对缓存进行操作,只有这样才能会提交缓存中的数据到数据库,更新数据.
            sqlSession.commit();
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
</code></pre>
]]></content>
    </entry>
</feed>