<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://yihuaikun.github.io</id>
    <title>向java工程师迈进</title>
    <updated>2019-12-12T12:58:21.361Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://yihuaikun.github.io"/>
    <link rel="self" href="https://yihuaikun.github.io/atom.xml"/>
    <subtitle>温故而知新</subtitle>
    <logo>https://yihuaikun.github.io/images/avatar.png</logo>
    <icon>https://yihuaikun.github.io/favicon.ico</icon>
    <rights>All rights reserved 2019, 向java工程师迈进</rights>
    <entry>
        <title type="html"><![CDATA[ Mybatis实现批量插入]]></title>
        <id>https://yihuaikun.github.io/post/mybatis-shi-xian-pi-liang-cha-ru</id>
        <link href="https://yihuaikun.github.io/post/mybatis-shi-xian-pi-liang-cha-ru">
        </link>
        <updated>2019-12-12T12:35:45.000Z</updated>
        <content type="html"><![CDATA[<h1 id="mybatis实现批量插入">Mybatis实现批量插入</h1>
<p>环境配置</p>
<p>1.依赖</p>
<pre><code class="language-xml"> &lt;!-- https://mvnrepository.com/artifact/org.mybatis/mybatis --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.mybatis&lt;/groupId&gt;
            &lt;artifactId&gt;mybatis&lt;/artifactId&gt;
            &lt;version&gt;3.5.2&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;!-- https://mvnrepository.com/artifact/mysql/mysql-connector-java --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;mysql&lt;/groupId&gt;
            &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;
            &lt;version&gt;5.1.47&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;!-- https://mvnrepository.com/artifact/mysql/mysql-connector-java --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;mysql&lt;/groupId&gt;
            &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;
            &lt;version&gt;5.1.47&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;!-- https://mvnrepository.com/artifact/com.alibaba/druid --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;com.alibaba&lt;/groupId&gt;
            &lt;artifactId&gt;druid&lt;/artifactId&gt;
            &lt;version&gt;1.1.20&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;
            &lt;artifactId&gt;lombok&lt;/artifactId&gt;
            &lt;version&gt;1.18.10&lt;/version&gt;
        &lt;/dependency&gt;
</code></pre>
<p>2.application.xml中的配置</p>
<pre><code class="language-yml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;
&lt;!DOCTYPE configuration
        PUBLIC &quot;-//mybatis.org//DTD Config 3.0//EN&quot;
        &quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;&gt;
&lt;configuration&gt;
    &lt;properties resource=&quot;jdbc.properties&quot; /&gt;
    &lt;settings&gt;
        &lt;setting name=&quot;mapUnderscoreToCamelCase&quot; value=&quot;true&quot;/&gt;
&lt;!--        &lt;setting name=&quot;cacheEnabled&quot; value=&quot;true&quot;/&gt;--&gt;
&lt;!--        &lt;setting name=&quot;localCacheScope&quot; value=&quot;SESSION&quot;/&gt;--&gt;
    &lt;/settings&gt;
    &lt;environments default=&quot;development&quot;&gt;
        &lt;environment id=&quot;development&quot;&gt;
            &lt;transactionManager type=&quot;JDBC&quot;/&gt;
            &lt;dataSource type=&quot;POOLED&quot;&gt;
                &lt;property name=&quot;driver&quot; value=&quot;${jdbc.driver}&quot;/&gt;
                &lt;property name=&quot;url&quot; value=&quot;${jdbc.url}&quot;/&gt;
                &lt;property name=&quot;username&quot; value=&quot;${jdbc.user}&quot;/&gt;
                &lt;property name=&quot;password&quot; value=&quot;${jdbc.password}&quot;/&gt;
            &lt;/dataSource&gt;
        &lt;/environment&gt;
    &lt;/environments&gt;
    &lt;mappers&gt;
        &lt;mapper resource=&quot;mappers/studentMapper.xml&quot;/&gt;
        &lt;mapper resource=&quot;mappers/userMapper.xml&quot;/&gt;
    &lt;/mappers&gt;
&lt;/configuration&gt;
</code></pre>
<p>2.jdbc.properties</p>
<pre><code class="language-properties">jdbc.driver=com.mysql.jdbc.Driver
jdbc.url=jdbc:mysql://localhost/day03?characterEncoding=utf-8
jdbc.user=root
jdbc.password=123456
</code></pre>
<p>6.创建数据库student</p>
<h2 id="实现技术mybatis的动态sql">实现技术:Mybatis的动态sql</h2>
<h3 id="第一种是mapperxml中的foreach动态sql语句">第一种是mapper.xml中的foreach动态sql语句</h3>
<p>1.首先创建测试类:Student</p>
<pre><code class="language-java">@Setter
@Getter
@ToString
public class Student {
    private int sId;
    private String sName;
    private String sex;
    private int age;
    private String subject;
    private String phone;

    public Student() {
    }

    public Student(int sId, String sName, String sex, int age, String subject, String phone) {
        this.sId = sId;
        this.sName = sName;
        this.sex = sex;
        this.age = age;
        this.subject = subject;
        this.phone = phone;
    }

    public Student(String sName, String sex, int age, String subject, String phone) {
        this.sName = sName;
        this.sex = sex;
        this.age = age;
        this.subject = subject;
        this.phone = phone;
    }
    public Student(int sId, String sName) {
        this.sId = sId;
        this.sName = sName;
    }
}
</code></pre>
<p>2.然后创建mapper接口</p>
<pre><code class="language-java">public interface StudentMapper {
    int insert(List&lt;Student&gt; studentList);
}
</code></pre>
<p>3.然后配置mapper.xml</p>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;
&lt;!DOCTYPE mapper
        PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot;
        &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;
&lt;mapper namespace=&quot;com.lanou.mapper.StudentMapper&quot;&gt;

&lt;!--    &lt;cache/&gt;--&gt;
&lt;!--  这是测试forEach的第一种  --&gt;
    &lt;insert id=&quot;insert&quot; &gt;
        insert into student(s_name,sex,age,subject,phone) values
        &lt;foreach collection=&quot;list&quot; item=&quot;stu&quot; separator=&quot;,&quot; &gt;
           ( #{stu.sName},
            #{stu.sex},
            #{stu.age},
            #{stu.subject},
            #{stu.phone})
        &lt;/foreach&gt;
    &lt;/insert&gt;
&lt;/mapper&gt;
</code></pre>
<p>3.然后测试一下</p>
<pre><code class="language-java">    /**
     *这是测试forEach的第一种方法:
     */
    @Test
    public void testForEacher(){
        String xmlPath= &quot;mybatis-config.xml&quot;;
        try {
            InputStream inputStream = Resources.getResourceAsStream(xmlPath);
            SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream);
            //开启自动提交:如果不开启则会看到一级缓存的作用true
            SqlSession sqlSession = sqlSessionFactory.openSession();
            StudentMapper studentMapper = sqlSession.getMapper(StudentMapper.class);
            //String sName, String sex, int age, String subject, String phone
            List&lt;Student&gt; studentList = new ArrayList&lt;&gt;();
            Collections.addAll(studentList,
                    new Student(&quot;黄三&quot;,&quot;女&quot;,23,&quot;蓝翔挖掘机&quot;,&quot;11111111111&quot;),
                    new Student(&quot;黄四&quot;,&quot;男&quot;,20,&quot;蓝翔厨师&quot;,&quot;22222222222&quot;),
                    new Student(&quot;黄五&quot;,&quot;女&quot;,25,&quot;电大&quot;,&quot;33333333333&quot;)
                    );
            studentMapper.insert(studentList);
            //没有开启自动提交,就会对缓存进行操作,只有这样才能会提交缓存中的数据到数据库,更新数据.
            sqlSession.commit();
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
</code></pre>
<h3 id="第二种是简单的sql语句逻辑实现foreach">第二种是简单的sql语句,逻辑实现foreach</h3>
<p>1.mapper.xml中</p>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;
&lt;!DOCTYPE mapper
        PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot;
        &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;
&lt;mapper namespace=&quot;com.lanou.mapper.StudentMapper&quot;&gt;
    &lt;!--  这是forEacher的第二种  --&gt;
    &lt;insert id=&quot;insert2&quot; &gt;
        insert into student(s_name,sex,age,subject,phone) values
             (#{sName},
            #{sex},
            #{age},
            #{subject},
            #{phone})
    &lt;/insert&gt;
&lt;/mapper&gt;
</code></pre>
<p>2.然后定义mapper接口</p>
<pre><code class="language-java">public interface StudentMapper {
    int insert2(Student student);
}
</code></pre>
<p>3.然后测试</p>
<pre><code class="language-java">    /**
     * 这是forEach的第二种方法,和批处理
     */
    @Test
    public void testForEach2(){
        String xmlPath= &quot;mybatis-config.xml&quot;;
        try {
            InputStream inputStream = Resources.getResourceAsStream(xmlPath);
            SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream);
            //开启自动提交:如果不开启则会看到一级缓存的作用true
            //ExecutorType默认是simple一条一执行,还有就是batch使用这个得  sqlSession.flushStatements()才会提交数据

            SqlSession sqlSession = sqlSessionFactory.openSession(ExecutorType.BATCH,true);
            StudentMapper studentMapper = sqlSession.getMapper(StudentMapper.class);
            //String sName, String sex, int age, String subject, String phone
            List&lt;Student&gt; studentList = new ArrayList&lt;&gt;();
            Collections.addAll(studentList,
                    new Student(&quot;黄三&quot;,&quot;女&quot;,23,&quot;蓝翔挖掘机&quot;,&quot;11111111111&quot;),
                    new Student(&quot;黄四&quot;,&quot;男&quot;,20,&quot;蓝翔厨师&quot;,&quot;22222222222&quot;),
                    new Student(&quot;黄五&quot;,&quot;女&quot;,25,&quot;电大&quot;,&quot;33333333333&quot;)
            );

//            对缓存的操作之批量插入:
            int count = 0;
            for(Student student : studentList ){
                studentMapper.insert2(student);
                count++;
                if(count % 2 == 0){
                    sqlSession.flushStatements();
                }
            }
//          对剩余得处理:
            if(count % 2 != 0){
               sqlSession.flushStatements();
            }
            //没有开启自动提交,就会对缓存进行操作,只有这样才能会提交缓存中的数据到数据库,更新数据.
            sqlSession.commit();
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[接入阿里大于短信服务]]></title>
        <id>https://yihuaikun.github.io/post/jie-ru-a-li-da-yu-duan-xin-fu-wu</id>
        <link href="https://yihuaikun.github.io/post/jie-ru-a-li-da-yu-duan-xin-fu-wu">
        </link>
        <updated>2019-12-12T12:35:11.000Z</updated>
        <content type="html"><![CDATA[<p><a href="https://blog.csdn.net/cool_summer_moon/article/details/53648093">阿里云大于短信服务开发</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[SpringCloud]]></title>
        <id>https://yihuaikun.github.io/post/springcloud</id>
        <link href="https://yihuaikun.github.io/post/springcloud">
        </link>
        <updated>2019-12-12T12:34:13.000Z</updated>
        <content type="html"><![CDATA[<h1 id="springcloud之netflix">springcloud之Netflix</h1>
<h2 id="netflix体系简介">Netflix体系简介</h2>
<p>Netflix这可是个大boss，地位仅次于老大，老大各项服务依赖与它，与各种Netflix OSS组件集成，组成微服务的核心，它的小弟主要有Eureka, Hystrix, Zuul, Archaius… 太多了</p>
<h3 id="核心成员">核心成员</h3>
<h4 id="netflix-eureka">Netflix Eureka</h4>
<p>服务中心，云端服务发现，一个基于  REST  的服务，用于定位服务，以实现云端中间层服务发现和故障转移。这个可是springcloud最牛鼻的小弟，服务中心，任何小弟需要其它小弟支持什么都需要从这里来拿，同样的你有什么独门武功的都赶紧过报道，方便以后其它小弟来调用；它的好处是你不需要直接找各种什么小弟支持，只需要到服务中心来领取，也不需要知道提供支持的其它小弟在哪里，还是几个小弟来支持的，反正拿来用就行，服务中心来保证稳定性和质量。</p>
<h4 id="netflix-ribbon">Netflix Ribbon</h4>
<p>Ribbon是一个客户端负载均衡组件，帮我们实现后端服务节点动态扩容，而不影响调用方。</p>
<h4 id="netflix-hystrix">Netflix Hystrix</h4>
<p>熔断器，容错管理工具，旨在通过熔断机制控制服务和第三方库的节点,从而对延迟和故障提供更强大的容错能力。比如突然某个小弟生病了，但是你还需要它的支持，然后调用之后它半天没有响应，你却不知道，一直在等等这个响应；有可能别的小弟也正在调用你的武功绝技，那么当请求多之后，就会发生严重的阻塞影响老大的整体计划。这个时候Hystrix就派上用场了，当Hystrix发现某个小弟不在状态不稳定立马马上让它下线，让其它小弟来顶上来，或者给你说不用等了这个小弟今天肯定不行，该干嘛赶紧干嘛去别在这排队了。</p>
<h4 id="netflix-zuul">Netflix Zuul</h4>
<p>Zuul  是在云平台上提供动态路由,监控,弹性,安全等边缘服务的框架。Zuul 相当于是设备和 Netflix 流应用的 Web  网站后端所有请求的前门。当其它门派来找大哥办事的时候一定要先经过zuul,看下有没有带刀子什么的给拦截回去，或者是需要找那个小弟的直接给带过去。</p>
<h4 id="netflix-archaius">Netflix Archaius</h4>
<p>配置管理API，包含一系列配置管理API，提供动态类型化属性、线程安全配置操作、轮询框架、回调机制等功能。可以实现动态获取配置，   原理是每隔60s（默认，可配置）从配置源读取一次内容，这样修改了配置文件后不需要重启服务就可以使修改后的内容生效，前提使用archaius的API来读取。</p>
<h1 id="eureka和ribbon">Eureka和Ribbon</h1>
<h3 id="单机模式的eureka和ribbon">单机模式的Eureka和Ribbon</h3>
<h4 id="前置工作">前置工作</h4>
<h5 id="1首先是依赖的搭配使用">1.首先是依赖的搭配使用</h5>
<p>详细介绍参见<a href="https://spring.io/projects/spring-cloud">Springcloud依赖版本搭配配置参见</a></p>
<h5 id="2然后再公用模块加依赖">2.然后再公用模块加依赖</h5>
<pre><code class="language-xml">  &lt;properties&gt;
        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;
        &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt;
        &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt;
        &lt;springboot.version&gt;2.1.6.RELEASE&lt;/springboot.version&gt;
        &lt;springcloud.version&gt;Greenwich.SR2&lt;/springcloud.version&gt;
    &lt;/properties&gt;
    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;junit&lt;/groupId&gt;
            &lt;artifactId&gt;junit&lt;/artifactId&gt;
            &lt;version&gt;4.12&lt;/version&gt;
            &lt;scope&gt;test&lt;/scope&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;
            &lt;artifactId&gt;lombok&lt;/artifactId&gt;
            &lt;version&gt;1.18.10&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt;
            &lt;artifactId&gt;logback-classic&lt;/artifactId&gt;
            &lt;version&gt;1.2.3&lt;/version&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;
    &lt;dependencyManagement&gt;
        &lt;dependencies&gt;
            &lt;dependency&gt;
                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
                &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;
                &lt;!-- 注意：SpringCloud最新的Greenwich版本是基于SpringBoot2.1.x(Greenwich)版本构建的
                    所以这里不支持SpringBoot2.2.x版本
                    具体SpringBoot与SpringCloud版本对应关系参见：https://spring.io/projects/spring-cloud页面最下方的Release Trains
                 --&gt;
                &lt;!--&lt;version&gt;2.2.1.RELEASE&lt;/version&gt;--&gt;
                &lt;version&gt;${springboot.version}&lt;/version&gt;
                &lt;type&gt;pom&lt;/type&gt;
                &lt;scope&gt;import&lt;/scope&gt;
            &lt;/dependency&gt;

            &lt;dependency&gt;
                &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
                &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt;
                &lt;version&gt;${springcloud.version}&lt;/version&gt;
                &lt;type&gt;pom&lt;/type&gt;
                &lt;scope&gt;import&lt;/scope&gt;
            &lt;/dependency&gt;
        &lt;/dependencies&gt;
    &lt;/dependencyManagement&gt;
</code></pre>
<h3 id="然后创建euraka-server模块">然后创建Euraka-server模块</h3>
<h4 id="1创建项目启动类">1.创建项目启动类</h4>
<pre><code class="language-java">@SpringBootApplication
//这是开启Eureka的注解
@EnableEurekaServer
public class EurekaApplication {
    public static void main(String[] args) throws IOException {
        SpringApplication.run(EurekaApplication.class,args);
    }
}

</code></pre>
<p>需要注意的是,这两个注解一个是统用的,一个是专用的.</p>
<pre><code class="language-java">@EnableDiscoveryClient
@EnableEurekaServer
</code></pre>
<h4 id="2然后配置下yml文件">2.然后配置下yml文件</h4>
<pre><code class="language-yml">server:
  port: 8761

spring:
  application:
    name: eureka-server
eureka:
  instance:
    prefer-ip-address: true
    hostname: localhost
  client:
 # 这个是要不要注册当前的服务注册到eureka中
    register-with-eureka: false
 # 是否从eureka中拉取服务表,即当前服务取注册中心拉取服务   
    fetch-registry: false
    service-url:
      defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/
</code></pre>
<p>[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-nmBlNO8h-1576064827399)(D:\总结\springcloud\eureks名字.png)]</p>
<h4 id="3启动项目访问eureka日志中的地址出现管理界面">3.启动项目访问Eureka日志中的地址出现管理界面</h4>
<h3 id="创建服务提供者">创建服务提供者</h3>
<h4 id="1创建模块启动类">1.创建模块启动类</h4>
<pre><code class="language-java">@SpringBootApplication
@EnableEurekaClient
public class EurekaProviderApplication {
    public static void main(String[] args) {
        SpringApplication.run(EurekaProviderApplication.class,args);
    }
}

</code></pre>
<h4 id="2配置yml文件">2.配置yml文件</h4>
<pre><code class="language-yml">spring:
  application:
    name: eureka-provider

eureka:
#  这个是客户端的配置
  client:
#    这个是是否把当前服务注册到注册中心
    register-with-eureka: true
#    这个是是否要拉取服务,一般在集群中用到
    fetch-registry: false
    service-url:
#      这个是服务要提交服务所到的地址,同时也是eureka在浏览器的访问地址,一般是和eureka的server保持一致,
#      表明提交服务到的地址是eureka-server的地址
      defaultZone: http://${eureka.instance.hostname}:8761/eureka/
#      这个是实例,即你的服务的相关配置
  instance:
    hostname: localhost
    prefer-ip-address: true
#    这个是实例在注册中心的id
    instance-id: ${spring.application.name}:${spring.application.instance_id:${server.port}}
server:
  port: 8082
</code></pre>
<h4 id="3启动模块查看eureka控制home实例">3.启动模块,查看eureka控制home实例</h4>
<h3 id="创建consumer模块">创建consumer模块</h3>
<h4 id="1创建模块启动类-2">1.创建模块启动类</h4>
<pre><code class="language-java">@SpringBootApplication
@EnableEurekaClient
public class EurekaConsumerApplication {
    public static void main(String[] args) {
        SpringApplication.run(EurekaConsumerApplication.class,args);
    }
}
</code></pre>
<h4 id="2配置yml文件-2">2.配置yml文件</h4>
<pre><code class="language-yml">server:
  port: 8081

spring:
  application:
    name: eureka-consumer

eureka:
  client:
#    这个是要把服务注册到eureka-server的地址
    service-url: http://${eureka.instance.hostname}:8761/eureka/
#      这个是是否把自己的服务注册到注册中心
    register-with-eureka: true
#    这个是启动时是否拉取服务列表
    fetch-registry: false
  instance:
    hostname: localhost
    instance-id: ${spring.application.name}:${spring.application.instance_id:${server.port}}
#     在某些情况下，Eureka优先使用IP地址而不是主机名
#    。设置为true，当应用程序向eureka注册时，它将使用其IP地址而不是其主机名
    prefer-ip-address: true

</code></pre>
<h4 id="3启动模块查看服务是否注册成功">3.启动模块查看服务是否注册成功.</h4>
<h4 id="4访问localhost8081看服务有问题否">4.访问localhost:8081,看服务有问题否</h4>
<h2 id="出现的问题总结">出现的问题总结:</h2>
<h3 id="1ribbon的理解">1.Ribbon的理解</h3>
<p>​		**ribbon:**是在客户端的负载均衡,也就是说ribbon的负载均衡不在服务端,而是在客户端,这样它启动后就是先拉取服务,放在缓存中,,第二次用的就是缓存中的服务列表,然后即使服务器挂了,本地还有缓存中的服务列表,短暂的也不会影响客户端的使用</p>
<p>​		这样上面的配置就有问题:fetch-registry: false:表示不拉取服务,这样就会访问localhost:8081出现500错误,错误信息是没有instances可用,所以把fetch-registry: true即可则会正常访问</p>
<h1 id="eureka集群的搭建">Eureka集群的搭建</h1>
<p>模块的启动类:注意启动不同的节点要改变生产环境</p>
<pre><code class="language-java">@SpringBootApplication
@EnableEurekaServer
public class EurekaCloudApplication {
    public static void main(String[] args) {
        SpringApplication.run(EurekaCloudApplication.class,args);
    }
}

</code></pre>
<p>主要的配置文件如下:</p>
<p>这样节能直接启动:</p>
<p>​     <strong>注意:</strong> 1.启动不同的节点要改变生产环境</p>
<p>​				2.注意节点启动时会报错,因为还没启动完,最后一个启动不会报错,因为他们之间会互相拉取数据.</p>
<pre><code class="language-yml">spring:
  application:
    name:eureka-cloud-server
  profiles:
    active:

#eureka集群的搭建
eureka:
  client:
#    首先这两个要打开,一个是把当前服务注册到注册中心,一个是拉取其他注册中心的服务
#    高可用
    fetch-registry: true
    register-with-eureka: true
  instance:
    prefer-ip-address: true

---

spring:
  profiles: dev

eureka:
  client:
    service-url:
      defaultZone: http://ip2:port/eureka/,http://ip3:port/eureka/
  instance:
  instance:
    hostname: 主机的ip或主机名

---
spring:
  profiles: node1

eureka:
  client:
    service-url: 
      defaultZone: http://ip1:port/eureka/,http://ip3:port/eureka/
  instance:
    hostname: 主机的ip或主机名
---
spring:
  profiles: node2

eureka:
  client:
    service-url:
      defaultZone: http://ip1:port/eureka/,http://ip2:port/eureka/
  instance:
    hostname: 主机的ip或主机名
</code></pre>
<h1 id="spring-cloud">Spring-Cloud</h1>
<h2 id="netflix-feign组件">netflix---Feign(组件)</h2>
<h3 id="使用底层封装了httpclient">使用:底层封装了HttpClient</h3>
<h4 id="1添加依赖">1.添加依赖</h4>
<pre><code class="language-xml">      &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-starter-feign&lt;/artifactId&gt;
            &lt;version&gt;1.4.6.RELEASE&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
        &lt;/dependency&gt;

</code></pre>
<h4 id="2模块启动类">2.模块启动类</h4>
<pre><code class="language-java">@SpringBootApplication
//@EnableEurekaClient
@EnableFeignClients
public class EurekaFeignConsumerApplication {
    public static void main(String[] args) {
        SpringApplication.run(EurekaFeignConsumerApplication.class,args);
    }
}

</code></pre>
<h4 id="3service层的使用">3.service层的使用</h4>
<pre><code class="language-java">@FeignClient(&quot;eureka-provider:8082&quot;)
@Service
public interface CalcService {
    @GetMapping(&quot;/calc/add/{num1}/{num2}&quot;)
    public ResponseInfo add(@PathVariable(&quot;num1&quot;) int num1, @PathVariable(&quot;num2&quot;) int num2);
}
</code></pre>
<p>4.controller层</p>
<pre><code class="language-java">@Controller
@RequestMapping(&quot;/calc&quot;)
@Slf4j
public class CalcController {


    @Autowired
    private CalcService calcService;

    @RequestMapping(&quot;/add&quot;)
    public String add(@RequestParam int num1, @RequestParam int num2, Model model) {

        System.out.println(num1+ &quot;    &quot; + num2);
        // 以前使用SpringMVC方式，直接通过IP+端口号来调用服务
//        ResponseEntity&lt;ResponseInfo&gt; entity = restTemplate.getForEntity(&quot;http://localhost:8081/calc/add/&quot;+num1+&quot;/&quot;+num2, ResponseInfo.class);
        // 引入Ribbon后，通过微服务ID访问远程服务
//        ResponseEntity&lt;ResponseInfo&gt; entity = restTemplate.getForEntity(&quot;http://eureka-provider:8082/calc/add/&quot;+num1+&quot;/&quot;+num2, ResponseInfo.class);
        ResponseInfo info = calcService.add(num1, num2);
//        ResponseInfo info = entity.getBody();
        Map data = (Map) info.getData();
        model.addAttribute(&quot;result&quot;, data.get(&quot;result&quot;));
        model.addAttribute(&quot;num1&quot;, num1);
        model.addAttribute(&quot;num2&quot;, num2);

        return &quot;index&quot;;
    }
}

</code></pre>
<p>4.yml的配置</p>
<pre><code class="language-yml">spring:
  application:
    name: eureka-feign-consumer

eureka:
  #  这个是客户端的配置
  client:
    #    这个是是否把当前服务注册到注册中心
    register-with-eureka: true
    #    这个是是否要拉取服务,一般在集群中用到
    fetch-registry: true
    service-url:
      #      这个是服务要提交服务所到的地址,同时也是eureka在浏览器的访问地址,一般是和eureka的server保持一致,
      #      表明提交服务到的地址是eureka-server的地址
      defaultZone: http://${eureka.instance.hostname}:8761/eureka/
  #      这个是实例,即你的服务的相关配置
  instance:
    hostname: localhost
    prefer-ip-address: true
    #    这个是实例在注册中心的id
    instance-id: ${spring.application.name}:${spring.application.instance_id:${server.port}}
server:
  port: 8088
  
feign:
  client:
    config:
      #      calc-service-provider:  这一级可以写具体的微服务名称或者default，default代表全局配置，影响所有微服务的调用
      default:
        connectTimeout: 1000
        readTimeout: 2000  
</code></pre>
<h4 id="5提供者和eureka服务的创建">5.提供者和Eureka服务的创建</h4>
<h1 id="spring-cloud-hystrix组件">Spring-Cloud---hystrix(组件)</h1>
<p><strong>两种方式分别是:hystrix和riboon的整合使用;hystrix和feign整合使用</strong></p>
<h2 id="hystrix熔断器和ribbon的整合使用">Hystrix(熔断器)和Ribbon的整合使用</h2>
<p>​		Hystrix和ribbon的使用主要是hystrix和ReatTemplate的使用.</p>
<p>什么是hystrix?</p>
<blockquote>
<p>在分布式环境中，许多服务依赖项中的一些不可避免地会失败。<br>
Hystrix是一个库，可通过添加延迟容错和容错逻辑来帮助您控制这些分布式服务之间的交互。<br>
Hystrix通过隔离服务之间的访问点，阻止它们之间的级联故障以及提供后备选项来实现这一目标，这些都可以提高系统的整体恢复能力</p>
</blockquote>
<blockquote>
<p>通俗的说Hystrix是Netflix公司开源的一个用于服务调用的断路器组件，给我们提供了包括服务熔断、降级、超时、资源隔离在内的完整解决方案。</p>
</blockquote>
<h2 id="具体使用">具体使用</h2>
<h3 id="1导入用到的依赖">1.导入用到的依赖</h3>
<pre><code class="language-xml">    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;
            &lt;version&gt;2.1.2.RELEASE&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;
</code></pre>
<h3 id="2启动类开启hystrix熔断">2.启动类开启Hystrix熔断</h3>
<pre><code class="language-java">@SpringBootApplication
@EnableCircuitBreaker //开启熔断
@EnableEurekaClient
public class HystrixRestTemplateApplication {
    @LoadBalanced //tibbon的使用,主要用来请求远程服务和负载均衡使用
    @Bean
    public RestTemplate restTemplate(){
        return new RestTemplate();
    }
    public static void main(String[] args) {
        SpringApplication.run(HystrixRestTemplateApplication.class,args);
    }
}

</code></pre>
<h3 id="3web控制层的使用">3.web控制层的使用</h3>
<pre><code class="language-java">/**
 * 计算器
 */
@Controller
@RequestMapping(&quot;/calc&quot;)
@Slf4j
public class CalcController {
    @Autowired
    private RestTemplate restTemplate;
    /**
     * 下面是熔断的使用
     * @param num1
     * @param num2
     * @param model
     * @return
     */
    @HystrixCommand(
            /**
             * 这是熔断点的定义
            */
            fallbackMethod = &quot;addFallback&quot;,
            /**
             * commandKey用于在Properties文件中配置此Command的参数，也可以直接用注解在这里配置参数
            */
            commandKey = &quot;calc_add_command&quot;
    )
    @RequestMapping(&quot;/add&quot;)
    public String add(@RequestParam int num1, @RequestParam int num2, Model model) {

        System.out.println(num1+ &quot;    &quot; + num2);
        // 以前使用SpringMVC方式，直接通过IP+端口号来调用服务
//        ResponseEntity&lt;ResponseInfo&gt; entity = restTemplate.getForEntity(&quot;http://localhost:8081/calc/add/&quot;+num1+&quot;/&quot;+num2, ResponseInfo.class);
        // 引入Ribbon后，通过微服务ID访问远程服务
        ResponseEntity&lt;ResponseInfo&gt; entity = restTemplate.getForEntity(&quot;http://eureka-provider:8082/calc/add/&quot;+num1+&quot;/&quot;+num2, ResponseInfo.class);
        ResponseInfo info = entity.getBody();
        Map data = (Map) info.getData();

        model.addAttribute(&quot;result&quot;, data.get(&quot;result&quot;));
        model.addAttribute(&quot;num1&quot;, num1);
        model.addAttribute(&quot;num2&quot;, num2);
        return &quot;index&quot;;
    }
    /**
     * 熔断方法,当服务发生熔断是调用此方法
     * @param num1
     * @param num2
     * @param model
     * @return
     */
    public String addFallback(@RequestParam int num1, @RequestParam int num2, Model model){
        model.addAttribute(&quot;num1&quot;, num1);
        model.addAttribute(&quot;num2&quot;, num2);
        model.addAttribute(&quot;result&quot;, &quot;-1&quot;);
        return &quot;index&quot;;
    }
}
</code></pre>
<p><strong>注意</strong>:这里的 @HystrixCommand中的参数commandkey的使用是,用于在Properties文件中配置此Command的参数，也可以直接用注解在这里配置参数.</p>
<h3 id="4最重要的yml中的配置">4.最重要的yml中的配置</h3>
<pre><code class="language-yml">spring:
  application:
    name: eureka-consumer-rest_template-hystrix
    
eureka:
  #  这个是客户端的配置
  client:
    #    这个是是否把当前服务注册到注册中心
    register-with-eureka: true
    #    这个是是否要拉取服务,一般在集群中用到
    fetch-registry: true
    service-url:
      #      这个是服务要提交服务所到的地址,同时也是eureka在浏览器的访问地址,一般是和eureka的server保持一致,
      #      表明提交服务到的地址是eureka-server的地址
      defaultZone: http://${eureka.instance.hostname}:8761/eureka/
  #      这个是实例,即你的服务的相关配置
  instance:
    hostname: localhost
    prefer-ip-address: true
    #    这个是实例在注册中心的id
    instance-id: ${spring.application.name}:${spring.application.instance_id:${server.port}}
    # hystrix中的核心配置
hystrix:
  command:
    calc_add_command:
      execution:
        isolation:
          thread:
            timeoutInMilliseconds: 2000 #设置熔断器判定超时的时间，超过此时间的请求会执行降级逻辑，默认1s
      circuitBreaker:
        requestVolumeThreshold: 2 #设置熔断阈值，在熔断统计窗口期内，错误请求（超时、异常）次数达到阈值就会触发熔断，执行降级逻辑，默认20
        sleepWindowInMilliseconds: 10000  #设置熔断器多久进入半开状态，然后再次尝试确定熔断器是否应再次关闭，默认5s
        errorThresholdPercentage: 50  #设置在熔断统计窗口期内，错误请求达到百分之多少触发熔断，默认50
      metrics:
        rollingStats:
          timeInMilliseconds: 5000 #熔断度量窗口期时间， 默认10s
server:
  port: 8099
</code></pre>
<h3 id="5启动项目测试">5.启动项目测试</h3>
<h2 id="hystrix和feign的整合使用">Hystrix和Feign的整合使用</h2>
<h3 id="1导入依赖">1.导入依赖</h3>
<pre><code class="language-xml">&lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;
</code></pre>
<h3 id="2web控制层">2.web控制层</h3>
<pre><code class="language-java">@Controller
@RequestMapping(&quot;/calc&quot;)
@Slf4j
public class CalcController {
    @Autowired
    private CalcService calcService;

    @RequestMapping(&quot;/add&quot;)
    public String add(@RequestParam int num1, @RequestParam int num2, Model model) {
        System.out.println(num1+ &quot;    &quot; + num2);
        // 以前使用SpringMVC方式，直接通过IP+端口号来调用服务
//        ResponseEntity&lt;ResponseInfo&gt; entity = restTemplate.getForEntity(&quot;http://localhost:8081/calc/add/&quot;+num1+&quot;/&quot;+num2, ResponseInfo.class);
        // 引入Ribbon后，通过微服务ID访问远程服务
//        ResponseEntity&lt;ResponseInfo&gt; entity = restTemplate.getForEntity(&quot;http://eureka-provider:8082/calc/add/&quot;+num1+&quot;/&quot;+num2, ResponseInfo.class);
        ResponseInfo info = calcService.add(num1, num2);
//        ResponseInfo info = entity.getBody();
        Map data = (Map) info.getData();
        model.addAttribute(&quot;result&quot;, data.get(&quot;result&quot;));
        model.addAttribute(&quot;num1&quot;, num1);
        model.addAttribute(&quot;num2&quot;, num2);
        return &quot;index&quot;;
    }
}
</code></pre>
<h3 id="3service层">3.service层</h3>
<pre><code class="language-java">@FeignClient(value = &quot;eureka-provider:8082&quot;,fallback = FallbackClient.class)
@Service
public interface CalcService {
    @GetMapping(&quot;/calc/add/{num1}/{num2}&quot;)
    public ResponseInfo add(@PathVariable(&quot;num1&quot;) int num1,@PathVariable(&quot;num2&quot;) int num2);
}
</code></pre>
<p>需要注意的是fallback熔断方法的实现要和实现的接口的请求地址分开,因为实现接口会默认继承GetMappig 的请求地址,防止出现暧昧关系</p>
<p>熔断方法</p>
<pre><code class="language-java">@Component
@RequestMapping(&quot;/fallback&quot;)
public class FallbackClient implements CalcService {
    @Override
    public ResponseInfo add(int num1, int num2) {
        Map data = new HashMap();
        data.put(&quot;num1&quot;, num1);
        data.put(&quot;num2&quot;, num2);
        data.put(&quot;result&quot;, -1);
        ResponseInfo responseInfo = new ResponseInfo(203,  &quot;降级结果&quot;, data);
        return responseInfo;
    }
}
</code></pre>
<h3 id="4配置文件">4.配置文件</h3>
<pre><code class="language-yml">spring:
  application:
    name: eureka-consumer-feign-hystrix


eureka:
  #  这个是客户端的配置
  client:
    #    这个是是否把当前服务注册到注册中心
    register-with-eureka: true
    #    这个是是否要拉取服务,一般在集群中用到
    fetch-registry: true
    service-url:
      #      这个是服务要提交服务所到的地址,同时也是eureka在浏览器的访问地址,一般是和eureka的server保持一致,
      #      表明提交服务到的地址是eureka-server的地址
      defaultZone: http://${eureka.instance.hostname}:8761/eureka/
  #      这个是实例,即你的服务的相关配置
  instance:
    hostname: localhost
    prefer-ip-address: true
    #    这个是实例在注册中心的id
    instance-id: ${spring.application.name}:${spring.application.instance_id:${server.port}}

hystrix:
  command:
#    default:  # 设置全局熔断参数
    CalcService#add(int,int): #设置某个feign client的熔断参数
      execution:
        isolation:
          thread:
            timeoutInMilliseconds: 2000 #设置熔断器判定超时的时间，超过此时间的请求会执行降级逻辑，默认1s
        circuitBreaker:
          requestVolumeThreshold: 2 #设置熔断阈值，在熔断统计窗口期内，错误请求（超时、异常）次数达到阈值就会触发熔断，执行降级逻辑，默认20
          sleepWindowInMilliseconds: 10000  #设置熔断器多久进入半开状态，然后再次尝试确定熔断器是否应再次关闭，默认5s
          errorThresholdPercentage: 50  #设置在熔断统计窗口期内，错误请求达到百分之多少触发熔断，默认50
        metrics:
          rollingStats:
            timeInMilliseconds: 5000 #熔断度量窗口期时间， 默认10s

feign:
  client:
    config:
      #      calc-service-provider:  这一级可以写具体的微服务名称或者default，default代表全局配置，影响所有微服务的调用
      default:
        connectTimeout: 1000
        readTimeout: 2000
  hystrix:
    enabled: true
server:
  port: 8100

</code></pre>
<h3 id="5需要注意的问题">5.需要注意的问题</h3>
<p>​		在feign中默认的hystrix是默认关闭的,如果不打开的话,会出现找不到fallback的错误,错误类型是500.</p>
<h1 id="监控工具">监控工具</h1>
<h2 id="springboot-actuator">SpringBoot Actuator</h2>
<p>SpringBoot Actuactor是SpringBoot提供的一个监控工具，通过他我们可以看到应用运行工程中的很多有用的信息：</p>
<table>
<thead>
<tr>
<th style="text-align:left">ID</th>
<th style="text-align:left">Description</th>
<th style="text-align:left">Enabled by default</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">auditevents</td>
<td style="text-align:left">Exposes audit events information for the current application.</td>
<td style="text-align:left">Yes</td>
</tr>
<tr>
<td style="text-align:left">beans</td>
<td style="text-align:left">Displays a complete list of all the Spring beans in your application.</td>
<td style="text-align:left">Yes</td>
</tr>
<tr>
<td style="text-align:left">conditions</td>
<td style="text-align:left">Shows the conditions that were evaluated on configuration and auto-configuration classes and the reasons why they did or did not match.</td>
<td style="text-align:left">Yes</td>
</tr>
<tr>
<td style="text-align:left">configprops</td>
<td style="text-align:left">Displays a collated list of all <code class="literal">@ConfigurationProperties</code>.</td>
<td style="text-align:left">Yes</td>
</tr>
<tr>
<td style="text-align:left">env</td>
<td style="text-align:left">Exposes properties from Spring’s <code class="literal">ConfigurableEnvironment</code>.</td>
<td style="text-align:left">Yes</td>
</tr>
<tr>
<td style="text-align:left">flyway</td>
<td style="text-align:left">Shows any Flyway database migrations that have been applied.</td>
<td style="text-align:left">Yes</td>
</tr>
<tr>
<td style="text-align:left">health</td>
<td style="text-align:left">Shows application health information.</td>
<td style="text-align:left">Yes</td>
</tr>
<tr>
<td style="text-align:left">httptrace</td>
<td style="text-align:left">Displays HTTP trace information (by default, the last 100 HTTP request-response exchanges).</td>
<td style="text-align:left">Yes</td>
</tr>
<tr>
<td style="text-align:left">info</td>
<td style="text-align:left">Displays arbitrary application info.</td>
<td style="text-align:left">Yes</td>
</tr>
<tr>
<td style="text-align:left">loggers</td>
<td style="text-align:left">Shows and modifies the configuration of loggers in the application.</td>
<td style="text-align:left">Yes</td>
</tr>
<tr>
<td style="text-align:left">liquibase</td>
<td style="text-align:left">Shows any Liquibase database migrations that have been applied.</td>
<td style="text-align:left">Yes</td>
</tr>
<tr>
<td style="text-align:left">metrics</td>
<td style="text-align:left">Shows ‘metrics’ information for the current application.</td>
<td style="text-align:left">Yes</td>
</tr>
<tr>
<td style="text-align:left">mappings</td>
<td style="text-align:left">Displays a collated list of all <code class="literal">@RequestMapping paths</code>.</td>
<td style="text-align:left">Yes</td>
</tr>
<tr>
<td style="text-align:left">scheduledtasks</td>
<td style="text-align:left">Displays the scheduled tasks in your application.</td>
<td style="text-align:left">Yes</td>
</tr>
<tr>
<td style="text-align:left">sessions</td>
<td style="text-align:left">Allows retrieval and deletion of user sessions from a Spring Session-backed session store. Not available when using Spring Session’s support for reactive web applications.</td>
<td style="text-align:left">Yes</td>
</tr>
<tr>
<td style="text-align:left">shutdown</td>
<td style="text-align:left">Lets the application be gracefully shutdown.</td>
<td style="text-align:left">No</td>
</tr>
<tr>
<td style="text-align:left">threaddump</td>
<td style="text-align:left">Performs a thread dump.</td>
<td style="text-align:left">Yes</td>
</tr>
</tbody>
</table>
<p><font color="orange">如果应用是一个Web应用（指引入了SpringMVC、Spring WebFlux或者Jersey），就可以用下面这些监控端点</font></p>
<table>
<thead>
<tr>
<th style="text-align:left">ID</th>
<th style="text-align:left">Description</th>
<th style="text-align:left">Enabled by default</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">heapdump</td>
<td style="text-align:left">Returns an hprof heap dump file.</td>
<td style="text-align:left">Yes</td>
</tr>
<tr>
<td style="text-align:left">jolokia</td>
<td style="text-align:left">Exposes JMX beans over HTTP (when Jolokia is on the classpath, not available for WebFlux).</td>
<td style="text-align:left">Yes</td>
</tr>
<tr>
<td style="text-align:left">logfile</td>
<td style="text-align:left">Returns the contents of the logfile (if logging.file or logging.path properties have been set). Supports the use of the HTTP Range header to retrieve part of the log file’s content.</td>
<td style="text-align:left">Yes</td>
</tr>
<tr>
<td style="text-align:left">prometheus</td>
<td style="text-align:left">Exposes metrics in a format that can be scraped by a Prometheus server.</td>
<td style="text-align:left">Yes</td>
</tr>
</tbody>
</table>
<p>除了上面列出来的，其他第三方模块还会提供一些特有的监控端点，如zuul提供的/routes</p>
<h1 id="springcloud-zuul路由网关">Springcloud-zuul(路由网关)</h1>
<h2 id="zuul介绍">Zuul介绍</h2>
<blockquote>
<p>Zuul是Netflx开源的微服务网关。可以和Eureka、Ribbon、Hystrix配合使用，一个主要的功能就是可以将后端众多的微服务屏蔽、整合，对前端提供一套统一的服务(有点像是后端的Facade)。</p>
</blockquote>
<p>Zuul提供了以下几项支持：</p>
<ul>
<li>认证安全: 识别每一个资源的验证要求，并拒绝那些不符的请求</li>
<li>监控</li>
<li>动态路由: 动态将请求路由到不同后端集群</li>
<li>压力测试: 逐渐增加指向集群的流量，以了解性能</li>
<li>金丝雀测试: 灰度发布</li>
<li>流量控制: 为每一种负载类型分配对应容量，并弃用超出限定值的请求</li>
<li>服务迁移</li>
<li>静态资源响应处理: 边缘位置进行响应，避免转发到内部集群</li>
</ul>
<h2 id="zuul用的地方是">zuul用的地方是</h2>
<p>一般用在服务的提供者</p>
<h3 id="1加依赖">1.加依赖</h3>
<pre><code class="language-xml">     &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;
        &lt;/dependency&gt;
</code></pre>
<h3 id="2创建springcloud-zuul">2.创建springcloud-zuul</h3>
<pre><code class="language-java">@SpringBootApplication
@EnableZuulProxy
@EnableEurekaClient
public class ZuulApplication {
    public static void main(String[] args) {
        SpringApplication.run(ZuulApplication.class, args);
    }

}
</code></pre>
<h3 id="3配置">3.配置</h3>
<pre><code class="language-yml">server:
  port: 10003
spring:
  application:
    name: zuul-server

eureka:
  #  这个是客户端的配置
  client:
    #    这个是是否把当前服务注册到注册中心
    register-with-eureka: true
    #    这个是是否要拉取服务,一般在集群中用到
    fetch-registry: true
    service-url:
      #      这个是服务要提交服务所到的地址,同时也是eureka在浏览器的访问地址,一般是和eureka的server保持一致,
      #      表明提交服务到的地址是eureka-server的地址
      defaultZone: http://${eureka.instance.hostname}:8761/eureka/
  #      这个是实例,即你的服务的相关配置
  instance:
    hostname: localhost
    prefer-ip-address: true
    #    这个是实例在注册中心的id
    instance-id: ${spring.application.name}:${spring.application.instance_id:${server.port}}
management:
  endpoints:
    web:
      exposure:
        include: &quot;*&quot;
zuul:
  routes:
    # 这种方式配置路由规则：前面的key是微服务名称，后面是匹配路径
    #    calc-service-provider: /calcApi/**
    # 这种方式配置路由规则：第一级的key可以随便取（路由名称），下面可以配置更多key、value（相比上面一种配置更强大）
    calc-proxy:
      serviceId: eureka-provider # 有效的微服务名称
      path: /calc/**  # 访问路径
      strip-prefix: false # 是否在网关层面消耗掉指定服务的路由规则前缀
    #    taotao-rest-proxy:
    #      serviceId: taotao-rest
    #      path: /rest/**

</code></pre>
<p><strong>注意上上面的strip-prefix: 值的用法</strong></p>
<p>1.上面的strip-prefix: false设置false代表你访问**localhost:10003/calc/****会跳转到对应的服务是eureka-provider,然后到注册中心找到对应的服务,localhost:8082/calc/add/55/66</p>
<pre><code>2.   上面的strip-prefix: false设置false代表你访问localhost:**10003/calc/calc/****会跳转到对应的服务是eureka-provider,然后到注册中心找到对应的服务,localhost:8082/calc/add/55/66
</code></pre>
<h3 id="代理传统的服务">代理传统的服务</h3>
<p>配置如下</p>
<pre><code class="language-yml">server:
  port: 9100
spring:
  application:
    name: zuul-server

eureka:
  client:
    service-url:
      defaultZone: http://${eureka.instance.hostname}:${eureka.client.eureka-server-port}/eureka/
    eureka-server-port: 8761
  instance:
    prefer-ip-address: true #在某些情况下，Eureka优先使用IP地址而不是主机名。设置为true，当应用程序向eureka注册时，它将使用其IP地址而不是其主机名
    instance-id: ${spring.application.name}:${spring.application.instance_id:${server.port}}
    hostname: node1.john.com

management:
  endpoints:
    web:
      exposure:
        include: &quot;*&quot;

zuul:
  routes:
    # 这种方式配置路由规则：前面的key是微服务名称，后面是匹配路径
#    calc-service-provider: /calcApi/**
    # 这种方式配置路由规则：第一级的key可以随便取（路由名称），下面可以配置更多key、value（相比上面一种配置更强大）
    calc-proxy:
      serviceId: calc-service-provider # 有效的微服务名称
      path: /calc/**  # 访问路径
      strip-prefix: false # 是否在网关层面消耗掉指定服务的路由规则前缀
      #代理传统的服务:
#    taotao-rest-proxy:
#      serviceId: taotao-rest
#      path: /rest/**
    taotao-rest-proxy-forward: # 使用forward本地转发(就是将匹配到路由规则的请求，转发到网关本地应用中去处理)
      path: /rest-f/**
      url: forward:/rest
    # 比如浏览器访问：http://localhost:9100/api/rest-f/content/getall/89
    # 会被转发到：http://localhost:9100/rest/content/getall/89


  ignored-services: &quot;*&quot; # 忽略所有未显示配置路由规则的微服务
  prefix: /api
  strip-prefix: true  # 是否在网关层面消耗掉全局前缀


# 使用Zuul代理未接入Eureka的传统服务
taotao-rest:
  ribbon:
    NIWSServerListClassName: com.netflix.loadbalancer.ConfigurationBasedServerList #如果不配置ServerList类型为ConfigurationBasedServerList的话就需要禁用ribbon的eureka支持
    ConnectTimeout: 500
    ReadTimeout: 2000
    listOfServers: http://localhost:8081

calc-service-provider:
  ribbon:
    ReadTimeout: 2000
    ConnectTimeout: 500

</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Linux的基本命令]]></title>
        <id>https://yihuaikun.github.io/post/linux-de-ji-ben-ming-ling</id>
        <link href="https://yihuaikun.github.io/post/linux-de-ji-ben-ming-ling">
        </link>
        <updated>2019-12-12T12:32:05.000Z</updated>
        <content type="html"><![CDATA[<h1 id="linux学习">Linux学习</h1>
<h2 id="介绍">介绍:</h2>
<p>​		Linux是一套免费使用和自由传播的<a href="https://baike.baidu.com/item/%E7%B1%BBUnix">类Unix</a><a href="https://baike.baidu.com/item/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/192">操作系统</a>，是一个基于<a href="https://baike.baidu.com/item/POSIX">POSIX</a>和Unix的多用户、<a href="https://baike.baidu.com/item/%E5%A4%9A%E4%BB%BB%E5%8A%A1/1011764">多任务</a>、支持<a href="https://baike.baidu.com/item/%E5%A4%9A%E7%BA%BF%E7%A8%8B/1190404">多线程</a>和多<a href="https://baike.baidu.com/item/CPU">CPU</a>的操作系统。它能运行主要的Unix工具软件、应用程序和网络协议。它支持<a href="https://baike.baidu.com/item/32%E4%BD%8D/5812218">32位</a>和<a href="https://baike.baidu.com/item/64%E4%BD%8D">64位</a>硬件。Linux继承了Unix以网络为核心的设计思想，是一个性能稳定的多用户网络操作系统。</p>
<h2 id="发行版本">发行版本</h2>
<p>RedHat(红帽)</p>
<p>CentOS</p>
<p>ubuntu</p>
<p>Debian</p>
<p>Open SuSE(变色龙)</p>
<h2 id="指令相关">指令相关</h2>
<h3 id="常用指令及其了解">常用指令及其了解:</h3>
<h4 id="插件的安装及其查看">插件的安装及其查看</h4>
<p>yum和rpm</p>
<p><a href="http://www.yanghengfei.com/tag/yum/">		yum</a>（全称为 Yellow dog Updater, Modified）是一个在Fedora和RedHat以及SUSE中的Shell前端软件包管理器。基於RPM包(RPM 是 Red Hat Package Manager 的缩写，本意是Red Hat 软件包管理，顾名思义是Red Hat 贡献出来的软件包管理)管理，能够从指定的服务器自动下载RPM包并且安装，可以自动处理依赖性关系，并且一次安装所有依赖的软体包，无须繁琐地一次次下载、安装。yum提供了查找、安装、删除某一个、一组甚至全部软件包的命令，而且命令简洁而又好记。</p>
<p>​		yum的命令形式一般是如下：yum [options] [command] [package ...]<br>
其中的[options]是可选的，选项包括-h（帮助），-y（当安装过程提示选择全部为&quot;yes&quot;），-q（不显示安装的过程）等等。[command]为所要进行的操作，[package ...]是操作的对象。</p>
<p>1 安装<br>
yum install 全部安装<br>
yum install package1 安装指定的安装包package1<br>
yum groupinsall group1 安装程序组group1</p>
<p>2 更新和升级<br>
yum update 全部更新<br>
yum update package1 更新指定程序包package1<br>
yum check-update 检查可更新的程序<br>
yum upgrade package1 升级指定程序包package1<br>
yum groupupdate group1 升级程序组group1</p>
<p>3 查找和显示<br>
yum info package1 显示安装包信息package1<br>
yum list 显示所有已经安装和可以安装的程序包<br>
yum list package1 显示指定程序包安装情况package1<br>
yum groupinfo group1 显示程序组group1信息yum search string 根据关键字string查找安装包</p>
<p>4 删除程序<br>
yum remove | erase package1 删除程序包package1<br>
yum groupremove group1 删除程序组group1<br>
yum deplist package1 查看程序package1依赖情况</p>
<p>5 清除缓存<br>
yum clean packages 清除缓存目录下的软件包<br>
yum clean headers 清除缓存目录下的 headers<br>
yum clean oldheaders 清除缓存目录下旧的 headers<br>
yum clean, yum clean</p>
<h4 id="cd命令">cd命令</h4>
<p>用来切换目录的:</p>
<p><strong>cd  ..</strong> :切换到父级目录</p>
<p><strong>cd ../目录</strong>:进入当前目录的父级目录下的目录</p>
<p><strong>cd /目录/目录/</strong>:进入指定的目录</p>
<p><strong>cd ~</strong>:用户的家目录</p>
<p><strong>cd</strong>:切换到用户登陆时的工作目录</p>
<h4 id="pwd">pwd</h4>
<p>查看所在的当前目录</p>
<h4 id="ls和ll命令">ls和ll命令:</h4>
<p>用来列出文件或文件的相关信息</p>
<p>ll的效果和ls -l是一样的</p>
<p>ls:</p>
<p>-a:显示所有的文件,包括隐藏的文件</p>
<p>-A:显示指定目录下的所有的子目录下的所有文件,包括隐藏的文件</p>
<p>-l</p>
<h4 id="cat命令显示文件和合并文件">cat命令:显示文件和合并文件</h4>
<p>cat [参数]  文件名</p>
<pre><code class="language-linux">1 cat 文件1 文件2 &gt; 文件3  这时文件3虽然把文件1和文件2中的都合并了但是文件3中原来的内容被覆盖了如图1
2.cat 文件1 文件2 &gt;&gt; 文件3 把文件1和文件2中的内容追加到文件3 如图2
</code></pre>
<p>图一</p>
<p>[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-TiPY6wRz-1576064731384)(D:\总结\Linux\cat文件合并.png)]</p>
<p>图二</p>
<p>[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-qfv9vWPU-1576064731386)(D:\总结\Linux\cat文件合并1.png)]</p>
<p>cat 文件名来浏览比较小的文件,因为较大的文件,cat只能看到后面的一部分,这时你需要用到less,more,tail命令</p>
<h4 id="cp命令拷贝文件">cp:命令拷贝文件</h4>
<p>cp source_file target_file : cp 要拷贝的文件  拷贝到什么地方</p>
<h4 id="mv移动文件到指定地方">mv:移动文件到指定地方</h4>
<p>mv 文件名  目标全限定地址</p>
<h3 id="文件相关">文件相关:</h3>
<h4 id="rm删除文件">rm:删除文件</h4>
<p>-i:删除文件时提示用户</p>
<h4 id="touch创建文件或修改文件的日期">touch:创建文件或修改文件的日期</h4>
<p>1.touch:创建一个空的文件</p>
<p>touch [参数] 文件名或目录名</p>
<p>​	-d  yyyymmmdd:修改文件修改或存取的日期,</p>
<p>例如 touch -d 2003.03.03 文件名</p>
<p>[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-88iQnfVw-1576064731387)(D:\总结\Linux\touch修改文件日期.png)]</p>
<p>​	-a:只修改存取时间</p>
<p>​	-m:把文件的修改时间改成当前时间</p>
<h4 id="mkdir创建目录">mkdir:创建目录</h4>
<p>mkdir [参数] 文件名</p>
<p>-p:例如mkdir -p 目录1/目录2/目录3/文件名,如果父级目录不存在会自动创建.</p>
<h4 id="rmdir删除目录">rmdir:删除目录</h4>
<p>-p:同上,连同父级目录一并删除.</p>
<h4 id="cp拷贝文件">cp:拷贝文件</h4>
<p>cp [参数] 文件名  目标地址全限定名</p>
<p>-a:尽量全得取拷贝,包括权限等.</p>
<p>-f:如果目标地址中存在则删除在覆盖</p>
<p>-i:如果目标地址存在同名文件,提示在覆盖</p>
<p>-R:递归赋值</p>
<h4 id="mv移动文件">mv:移动文件</h4>
<p>软连接   得到目标文件下取执行:ln -s 源文件  到目标目录的目标文件</p>
<p>硬链接  得到目标文件下取执行:ln 源文件   到目标目录的目标文件</p>
<h4 id="文件的解压与压缩">文件的解压与压缩</h4>
<p>gzip与gunzip:文件的压缩与解压,解压和压缩的文件都是以.gz为后缀的</p>
<p>tar:文件的打包与解包,最常用的时解压包</p>
<h4 id="软链接">软链接</h4>
<pre><code class="language-linux">ln -s src dst
</code></pre>
<h4 id="硬链接">硬链接</h4>
<pre><code class="language-linux">ln src dst
</code></pre>
<h4 id="home">/home</h4>
<p>其他用户共用的一个家目录。 比如下面可以有： /home/user1、/home/user2。分别代表user1、user2的家目录</p>
<h4 id="root">/root</h4>
<p>root用户得家目录</p>
<h4 id="usr-usrlocal-usrbin">/usr     /usr/local     /usr/bin</h4>
<p>软件安装目录，类似于windows下的program files目录</p>
<h4 id="opt">/opt</h4>
<p>软件安装目录，类似于windows下的program files目录</p>
<h4 id="bin">/bin</h4>
<p>可执行文件， 系统及应用运行命令存储目录</p>
<h4 id="etc">/etc</h4>
<p>配置目录，存放系统、应用程序全局的配置信息</p>
<h4 id="var">/var</h4>
<p>存储经常变动的数据， 比如日志、邮件</p>
<h4 id="系统默认会查找命令得目录">系统默认会查找命令得目录</h4>
<p>/bin</p>
<p>/sbin</p>
<p>/usr/bin</p>
<p>/usr/sbin</p>
<h1 id="系统配置与管理">系统配置与管理</h1>
<h2 id="linux服务器的用户和组">linux服务器的用户和组</h2>
<h3 id="1添加用户组">1.添加用户组</h3>
<p>语法：</p>
<pre><code>groupadd 选项 组名
</code></pre>
<p>选项：</p>
<ul>
<li>-g GID 指定新用户组的组标识号（GID）。</li>
<li>-o 一般与-g选项同时使用，表示新用户组的GID可以与系统已有用户组的GID相同</li>
</ul>
<h3 id="2删除用户组">2.删除用户组</h3>
<p>语法:</p>
<pre><code class="language-linux">groupadd 选项 组名
</code></pre>
<p>选项：</p>
<ul>
<li>-g GID 指定新用户组的组标识号（GID）。</li>
<li>-o 一般与-g选项同时使用，表示新用户组的GID可以与系统已有用户组的GID相同</li>
</ul>
<h3 id="3修改用户组">3.修改用户组</h3>
<p>语法:</p>
<pre><code>groupmod 选项 组名
</code></pre>
<p>选项：</p>
<ul>
<li>-g GID 为用户组指定新的组标识号。</li>
<li>-o 与-g选项同时使用，用户组的新GID可以与系统已有用户组的GID相同。</li>
<li>-n新用户组 将用户组的名字改为新名字</li>
</ul>
<h3 id="4切换用户组">4.切换用户组</h3>
<p>语法</p>
<pre><code>newgrp 组名
</code></pre>
<p>如果一个用户同属于多个用户组时使用</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Linux下安装tomcat]]></title>
        <id>https://yihuaikun.github.io/post/linux</id>
        <link href="https://yihuaikun.github.io/post/linux">
        </link>
        <updated>2019-12-12T12:31:01.000Z</updated>
        <content type="html"><![CDATA[<h1 id="linux下安装tomcat">Linux下安装tomcat</h1>
<h2 id="jdk的安装">jdk的安装</h2>
<p>1.下载JDK与Tomcat.<br>
<a href="http://www.oracle.com/technetwork/java/javase/downloads/jdk7-downloads-1880260.html">jdk下载地址</a><br>
<a href="http://tomcat.apache.org/download-70.cgi">tomcat下载地址</a></p>
<pre><code class="language-linux">tar.gz包:解压缩
# mkdir /usr/java
# cd /usr/java
# tar -zxvf /software/jdk-7u55-linux-x64.tar.gz
生成链接以便版本升级
# ln -s jdk1.7.0_55 latest
# ln -s latest default
</code></pre>
<p>(2)配置环境变量</p>
<pre><code class="language-linux">    export JAVA_HOME=/usr/java/default
    export JAVA_BIN=$JAVA_HOME/bin
    export PATH=$PATH:$JAVA_HOME/bin
    export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
    export PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$PATH
</code></pre>
<p>使配置生效</p>
<pre><code class="language-linux">  source /etc/profile
</code></pre>
<p>测试jdk安装成功否</p>
<pre><code class="language-linux">java -version
javac -version
</code></pre>
<h2 id="安装tomcat">安装tomcat</h2>
<p>1.下载tomcat在上面的网站上可以下载</p>
<p>2.在/usr/local/下创建tomcat目录</p>
<pre><code class="language-linux">  # mkdir /usr/local/tomcat
  #  cd /usr/local/tomcat
  #  tar -zxvf /software/apache-tomcat-7.0.54.tar.gz
  加上软链接,方便进入并且版 
  # ln -s apache-tomcat-7.0.54 server
</code></pre>
<p>3.启动tomcat</p>
<pre><code class="language-linux">   # cd /usr/local/tomcat/server/bin
    # ./startup.sh
    Using CATALINA_BASE: /usr/local/tomcat/server
    Using CATALINA_HOME: /usr/local/tomcat/server
    Using CATALINA_TEMDIR: /usr/local/tomcat/server/temp
    Using JRE_HOME: /usr/java/default
    Using CLASS_PATH: /usr/local/tomcat/server/bin/bootstrap.jar:/usr/local/tomcat/server/bin/tomcat-juli.jar
    Tomcat started.
</code></pre>
<p>测试tomcat</p>
<pre><code class="language-linux"> 打开防火墙,使外部能访问
    # /sbin/iptables -I INPUT -p tcp --dport 8080 -j ACCEPT
    # service iptables save
    # service iptables restart
    #systemctl restart iptables.service
    或直接修改文件/etc/sysconfig/iptables.
    # vi /etc/sysconfig/iptables
    -A INPUT -p tcp -m tcp --dport 8080 -j ACCEPT
    # service iptables restart
    在浏览器输入: http://192.168.16.133:8080
    如在本机可以输入: http://localhost:8080
    出现tomcat的页面表示安装成功.
</code></pre>
<p>4.停止tomcat</p>
<pre><code class="language-linux"> # ./shutdown.sh
</code></pre>
<h1 id="问题">问题</h1>
<h2 id="1重启systemctl-restart-iptablesservice时的错误">1.重启systemctl restart iptables.service时的错误</h2>
<p>如果不能#service restart iptables.service有可能就是linux版本命令改变成systemctl restart iptables.service</p>
<h2 id="2在linux环境能访问在浏览器不能访问">2.在linux环境能访问在浏览器不能访问</h2>
<p>#curl http://39.97.252.228:8080能访问但是在浏览器上不能访问的问题:</p>
<p>在本地应该访问你的远程服务器加端口</p>
<h2 id="3关于shudownsh报cataline错误">3.关于./shudown.sh报cataline错误</h2>
<h3 id="解决方法">解决方法</h3>
<p>正常启动<br>
<img src="https://img-blog.csdnimg.cn/20191211193430275.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzg2MjI4MA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p>#.shutdown.sh出现下面这种错误</p>
<p>图示信息:</p>
<pre><code class="language-java">SEVERE: Could not contact localhost:8005. Tomcat may not be running.
Jul 20, 2018 3:17:45 PM org.apache.catalina.startup.Catalina stopServer
SEVERE: Catalina.stop: 
java.net.ConnectException: Connection refused (Connection refused)
    at java.net.PlainSocketImpl.socketConnect(Native Method)
    at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl
    at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSoc
    at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.j
    at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
    at java.net.Socket.connect(Socket.java:589)
    at java.net.Socket.connect(Socket.java:538)
    at java.net.Socket.&lt;init&gt;(Socket.java:434)
    at java.net.Socket.&lt;init&gt;(Socket.java:211)
    at org.apache.catalina.startup.Catalina.stopServer(Catalina.java:498)
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorIm
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAc
    at java.lang.reflect.Method.invoke(Method.java:498)
    at org.apache.catalina.startup.Bootstrap.stopServer(Bootstrap.java:34
    at org.apache.catalina.startup.Bootstrap.main(Bootstrap.java:430)
</code></pre>
<p>上面显示的时8005端口没有起来</p>
<p>先说问题解决方法:</p>
<p>先查看8080端口和8005端口的使用情况:</p>
<p>#netstat -tunlp | grep 8080</p>
<p>#netstat -tunlp | grep 8005</p>
<p>这里如果出现上面错五可能会有异常.</p>
<p>具体的解决方法:</p>
<p>1.进入jdk文件</p>
<p>cd /usr/java/jdk1.8.0_51/jre/lib</p>
<figure data-type="image" tabindex="1"><img src="https://img-blog.csdnimg.cn/20191211193342581.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzg2MjI4MA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></figure>
<p>进入security文件修改Java.security文件</p>
<p>#vim java.security</p>
<pre><code class="language-xml">securerandom.source=file:/dev/random
改为：
securerandom.source=file:/dev/urandom
</code></pre>
<figure data-type="image" tabindex="2"><img src="https://img-blog.csdnimg.cn/20191211193505844.png" alt="在这里插入图片描述"></figure>
<p>查找快捷键</p>
<p>a 后Esc然后/securerandom.source=file:/dev/random</p>
<p>然后干掉8080端口进程和8005端口进程</p>
<p>重新启动tomcat然后检查8005端口和端口8080启动正常</p>
<p>回复正常.</p>
<h3 id="原因">原因</h3>
<p>上面设计到两方面的知识</p>
<h4 id="8005端口和8080端口还有8009端口的作用">8005端口和8080端口还有8009端口的作用:</h4>
<pre><code class="language-xml">&lt;Server port=&quot;8005&quot; shutdown=&quot;SHUTDOWN&quot;&gt;
</code></pre>
<p><strong>1.8005端口是用来关闭TOMCAT服务的端口。</strong></p>
<pre><code class="language-xml">&lt;Connector port=&quot;8009&quot; protocol=&quot;AJP/1.3&quot; redirectPort=&quot;8443&quot; /&gt;
</code></pre>
<p><strong>2.连接器监听8009端口，负责和其他的HTTP服务器建立连接。在把Tomcat与其他HTTP服务器集成时，就需要用到这个连接器</strong></p>
<pre><code class="language-xml">&lt;Connector port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot;
               connectionTimeout=&quot;20000&quot;
               redirectPort=&quot;8443&quot; /&gt;
</code></pre>
<p><strong>3.连接器监听8080端口，负责建立HTTP连接。在通过浏览器访问Tomcat服务器的Web应用时，使用的就是这个连接器</strong></p>
<p><strong>Tomcat1端口分配表(tomcat全部采用默认配置)</strong></p>
<p><strong>端口号</strong></p>
<p><strong>关闭指令端口</strong></p>
<p><strong>8005</strong></p>
<p><strong>http端口</strong></p>
<p><strong>8080</strong></p>
<p><strong>https端口</strong></p>
<p><strong>8443</strong></p>
<p><strong>Ajp端口</strong></p>
<p><strong>8009</strong></p>
<h4 id="jdk和jre基本概念">jdk和jre基本概念</h4>
<p><strong>JRE： Java Runtime Environment<br>
JDK：Java Development Kit</strong><br>
JRE顾名思义是java运行时环境，包含了java虚拟机，java基础类库。是使用java语言编写的程序运行所需要的软件环境，是提供给想运行java程序的用户使用的。<br>
JDK顾名思义是java开发工具包，是程序员使用java语言编写java程序所需的开发工具包，是提供给程序员使用的。JDK包含了JRE，同时还包含了编译java源码的编译器javac，还包含了很多java程序调试和分析的工具：jconsole，jvisualvm等工具软件，还包含了java程序编写所需的文档和demo例子程序。</p>
<h4 id="securerandomsourcefiledevrandom相关">/securerandom.source=file:/dev/random相关</h4>
<h5 id="securerandom的正确使用">SecureRandom的正确使用</h5>
<h6 id="安全随机数">安全随机数</h6>
<p>在安全应用场景，随机数应该使用安全的随机数。密码学意义上的安全随机数，要求必须保证其<strong>不可预测性</strong>。</p>
<h6 id="怎么获得安全的随机数">怎么获得安全的随机数</h6>
<p>​		可以直接使用真随机数产生器产生的随机数。或者使用真随机数产生器产生的随机数做种子，输入密码学安全的伪随机数产生器产生密码学安全随机数。</p>
<blockquote>
<p>非物理真随机数产生器有：</p>
<ol>
<li>Linux操作系统的**/dev/random**设备接口</li>
<li>Windows操作系统的CryptGenRandom接口</li>
</ol>
<p>密码学安全的伪随机数产生器,包括JDK的java.security.SecureRandom等。</p>
</blockquote>
<h5 id="securerandom最佳实践">SecureRandom最佳实践</h5>
<h6 id="基本用法">基本用法</h6>
<p>java.security.SecureRandom基本用法：</p>
<pre><code class="language-java">byte[] values = new byte[128];
SecureRandom random = new SecureRandom();
random.nextBytes(values);
</code></pre>
<h6 id="关于种子的设置">关于种子的设置</h6>
<p>要保证得到安全的随机数，需要使用真随机数产生器产生的随机数做种子。</p>
<p>可能的<strong>不当用法</strong>：</p>
<pre><code class="language-java"> byte[] salt = new byte[128];
 SecureRandom secureRandom = new SecureRandom();
 secureRandom.setSeed(System.currentTimeMillis());  
//使用系统时间作为种子
 secureRandom.nextBytes(salt);
</code></pre>
<p>此处指定了当前系统时间作为种子，替代系统默认随机源。如果同一毫秒连续调用，则得到的随机数则是相同的。</p>
<blockquote>
<p>小结：不要自己指定种子。应当使用系统随机源。</p>
</blockquote>
<p>系统默认的随机源是什么？</p>
<p>这取决于$JAVA_HOME/jre/lib/security/java.security配置中的securerandom.source属性。例如jdk1.8中该配置为：</p>
<pre><code class="language-xml">securerandom.source=file:/dev/random
</code></pre>
<p>使用无参构造函数实例化SecureRandom，在大多数系统中，默认的算法是“nativePRNG”，从/dev/random获取随机数。</p>
<h6 id="熵源不足时阻塞问题">熵源不足时阻塞问题</h6>
<p><strong>概念回顾</strong>：</p>
<ul>
<li>&quot;熵值&quot;：即是随机值的不确定性度量值。<br>
&quot;熵源&quot;：即是随机数的来源。<br>
&quot;熵输入&quot;：是伪随机数产生器描述从熵源获取的bit串，用来产生种子。<br>
&quot;种子&quot;：即是输入到伪随机数产生器用于初始化的bit串。</li>
</ul>
<p><strong>问题描述</strong><br>
在Linux系统中，/dev/random是系统提供的安全随机数接口。当通过/dev/random读取随机数的速度可以为产品所接受时，可以直接使用/dev/random读取的随机数。<br>
有时无法满足产品对随机数的使用要求，熵源不足时存在阻塞，会导致得到随机数的速度太慢。</p>
<pre><code>在读取时，/dev/random设备会返回小于熵池噪声总数的随机字节。/dev/random可生成高随机性的公钥或一次性密码本。若熵池空了，对/dev/random的读操作将会被阻塞，直到收集到了足够的环境噪声为止。
</code></pre>
<p><strong>解决方法</strong><br>
提高系统随机数产生器产生随机数速度的一种方法：</p>
<ul>
<li>采用haveged守护进程增加系统熵池熵值以提高/dev/random读取随机数的速度。</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Docker基础]]></title>
        <id>https://yihuaikun.github.io/post/docker-ji-chu</id>
        <link href="https://yihuaikun.github.io/post/docker-ji-chu">
        </link>
        <updated>2019-12-12T12:30:28.000Z</updated>
        <content type="html"><![CDATA[<h1 id="docker基础1">Docker基础1</h1>
<p>​		Docker 是一个开源的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的镜像中，然后发布到任何流行的 Linux或Windows 机器上，也可以实现虚拟化。容器是完全使用沙箱机制，相互之间不会有任何接口</p>
<h2 id="一个完整的docker有以下几个部分组成">一个完整的Docker有以下几个部分组成：</h2>
<ol>
<li>DockerClient客户端</li>
<li>Docker Daemon守护进程</li>
<li>Docker Image镜像</li>
<li>DockerContainer容器</li>
</ol>
<h2 id="让我来介绍下-docker-解决了哪些痛点">让我来介绍下 docker 解决了哪些痛点：</h2>
<ol>
<li>
<p>简化环境管理</p>
<p>传统的软件开发与发布环境复杂，配置繁琐，经常有读者在微信上问：我的代码开发环境可以运行，一旦部署到服务器上就运行不了了。这个问题很常见，也确实很烦人，但是问题总要解决，开发环境、测试环境、生产环境，每个环节都有可能出现这样那样的问题，如果能够在各个环境中实现一键部署，就会方便很多，例如一键安装  linux 、一键安装 mysql、一键安装 nginx 等，docker 彻底解决了这个问题。</p>
</li>
<li>
<p>虚拟化更加轻量级</p>
<p>说到容器，说到虚拟化，很多人总会想到虚拟机，想到 VMware、VirtualBox 等工具，不同于这些虚拟技术，docker  虚拟化更加轻量级，传统的虚拟机都是先虚拟出一个操作系统，然后在操作系统上完成各种各样的配置，这样并不能充分的利用物理机的性能，docker  则是一种操作系统级别的虚拟技术，它运行在操作系统之上的用户空间，所有的容器都共用一个系统内核甚至公共库，容器引擎提供了进程级别的隔离，让每个容器都像运行在单独的系统之上，但是又能够共享很多底层资源。因此  docker 更为轻量、快速和易于管理。</p>
</li>
<li>
<p>程序可移植</p>
<p>有了前面介绍的两个特点，程序可移植就是顺理成章的事情了。</p>
</li>
</ol>
<h2 id="docker-与传统容器">docker 与传统容器</h2>
<p>不同与传统容器，docker 早起基于 LXC，后来基于自研的 libContainer，docker 对于传统容器做了许多优化，如下：</p>
<ol>
<li>跨平台的可移植性</li>
<li>面向应用</li>
<li>版本控制</li>
<li>组件复用</li>
<li>共享性</li>
<li>工具生态系统</li>
</ol>
<p>docker 应用场景</p>
<ol>
<li>加速本地开发<br>
自动打包和部署应用<br>
3. 创建轻量、私有的PaaS环境<br>
自动化测试和持续集成/部署<br>
5. 部署并扩展Web应用、数据库和后端服务器<br>
创建安全沙盒<br>
7. 轻量级的桌面虚拟化</li>
</ol>
<h2 id="1docker的安装">1.Docker的安装</h2>
<pre><code class="language-linux">#安装
yum -y install docker
#启动服务
systemctl start docker
#查看版本
docker -v
</code></pre>
<h2 id="2查看容器">2.查看容器</h2>
<pre><code class="language-linux">查看正在运行的docker容器
docker ps
查看所有容器
docker ps -a
//查看最新创建的docker
docker ps -l
//查看最新创建的几个容器
docker ps -x=xxx
</code></pre>
<h2 id="3容器的创建">3.容器的创建</h2>
<pre><code class="language-linux">//创建容器,创建出来之后容器处于停止状态,名字是随机的
docker create nginx
//指定名字
docker create --name=nginx nginx
//创建容器加启动
docker run --name nginx1 -d -p 8080:80 nginx
//用create创建的容器的启动
docker start
</code></pre>
<h2 id="4容器的停止">4.容器的停止</h2>
<pre><code class="language-linux">docker stop
</code></pre>
<h2 id="5容器删除">5.容器删除</h2>
<pre><code class="language-linux">docker rm xx
</code></pre>
<h1 id="镜像">镜像</h1>
<p>​	总体来说，镜像是一个包含程序运行必要以来环境和代码的只读文件，它采用分层的文件系统，将每一层的改变以读写层的形式增加到原来的只读文件上。这有点像洋葱，一层一层的，当我们后面学习了 Dockerfile ，相信大家对于这样的架构理解将更为准确。</p>
<h1 id="镜像与容器的关系">镜像与容器的关系</h1>
<h2 id="相关理解">相关理解</h2>
<p>​		前文已经向读者介绍过容器的使用了，细心的读者可能已经发现，容器在启动或者创建时，必须指定一个镜像的名称或者  id  ，其实，这时镜像所扮演的角色就是容器的模版，不同的镜像可以构造出不同的容器，同一个镜像，我们也可以通过配置不同参数来构造出不通的容器。如下命令：</p>
<pre><code class="language-linux">docker run -itd --name nginx nginx
</code></pre>
<p>​		令中的最后一个 nginx 即表示创建该容器所需要的镜像（模版），当然这里还省略了一些信息，例如版本号等，这些我们后文会详细介绍。</p>
<h2 id="镜像的体系结构">镜像的体系结构</h2>
<p>镜像的最底层是一个启动文件系统（bootfs）镜像，bootfs 的上层镜像叫做根镜像，一般来说，根镜像是一个操作系统，例如 Ubuntu、CentOS 等，用户的镜像必须构建于根镜像之上，在根镜像之上，用户可以构建出各种各样的其他镜像。<br>
从上面的介绍读者可以看出，镜像的本质其实就是一系列文件的集合，一层套一层的结构有点类似于 Git ，也有点类似于生活中的洋葱。</p>
<figure data-type="image" tabindex="1"><img src="https://img-blog.csdnimg.cn/20191211192533714.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzg2MjI4MA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></figure>
<h2 id="镜像的写时复制机制">镜像的写时复制机制</h2>
<p>​		通过 <code>docker run</code>  命令指定一个容器创建镜像时，实际上是在该镜像之上创建一个空的可读写的文件系统层级，可以将这个文件系统层级当成一个临时的镜像来对待，而命令中所指的模版镜像则可以称之为父镜像。父镜像的内容都是以只读的方式挂载进来的，容器会读取共享父镜像的内容，用户所做的所有修改都是在文件系统中，不会对父镜像造成任何影响。当然用户可以通过其他一些手段使修改持久化到父镜像中，这个我们后面会详细介绍到。</p>
<p>简而言之，镜像就是一个固定的不会变化的模版文件，容器是根据这个模版创建出来的，容器会在模版的基础上做一些修改，这些修改本身并不会影响到模版，我们还可以根据模版（镜像）创建出来更多的容器。</p>
<p>如果有必要，我们是可以修改模版（镜像）的。</p>
<p>查看镜像;</p>
<pre><code class="language-linux">docker images
</code></pre>
<p>这里一共有五个参数，含义分别如下：</p>
<ul>
<li>TAG: TAG用于区分同一仓库中的不同镜像，默认为latest。</li>
<li>IMAGE ID: IMAGE ID是镜像的一个唯一标识符。</li>
<li>CREATED: CREATED表示镜像的创建时间。</li>
<li>SIZE: SIZE表示镜像的大小。</li>
<li>REPOSITORY:仓库名称，仓库一般用来存放同一类型的镜像。仓库的名称由其创建者指定。如果没有指定则为 <code>&lt;none&gt;</code> 。一般来说，仓库名称有如下几种不同的形式:</li>
</ul>
<figure data-type="image" tabindex="2"><img src="https://img-blog.csdnimg.cn/20191211192555394.png" alt="在这里插入图片描述"></figure>
<p>镜像的删除</p>
<pre><code class="language-linux">docker rmi xxx
</code></pre>
<p>用nginx在linux上启动一个项目</p>
<pre><code class="language-linux">docker run --name containerName -d -p 8081:81 nginx
java -jar xxx.xxx.jar
</code></pre>
<p>访问端口ip:81出现结果为</p>
<figure data-type="image" tabindex="3"><img src="https://img-blog.csdnimg.cn/20191211192603296.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzg2MjI4MA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></figure>
<h2 id="commint-创建本地镜像">commint 创建本地镜像</h2>
<p>命令解释：</p>
<ol>
<li>参数 -m 是对创建的该镜像的一个简单描述。</li>
<li>–author 表示该镜像的作者。</li>
<li>ce1fe32739402 表示创建镜像所依据的容器的 id。</li>
<li>sang/nginx 则表示仓库名，sang 是名称空间，nginx 是镜像名。</li>
<li>v1 表示仓库的 tag。</li>
<li>创建完成后，通过 docker images 命令就可以查看到刚刚创建的镜像。</li>
<li>通过刚刚创建的镜像运行一个容器，访问该容器，发现 nginx 默认的首页已经发生改变。</li>
</ol>
<p>这是我们通过 commint 方式创建本地镜像的方式，但是 commit 方式存在一些问题，比如不够透明化，无法重复，体积较大，为了解决这些问题，可以考虑使用 Dockerfile ，实际上，主流方案也是 Dockerfile。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Solr]]></title>
        <id>https://yihuaikun.github.io/post/solr</id>
        <link href="https://yihuaikun.github.io/post/solr">
        </link>
        <updated>2019-12-12T12:30:07.000Z</updated>
        <content type="html"><![CDATA[<h1 id="1-solr入门">1. Solr入门</h1>
<h2 id="11-solr下载安装">1.1. Solr下载安装</h2>
<p>官方下载地址：https://archive.apache.org/dist/lucene/solr/</p>
<p>Windows系统下载zip包，Linux、MaxOS系统下载tgz包</p>
<figure data-type="image" tabindex="1"><img src="https://img-blog.csdnimg.cn/20191207115834376.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzg2MjI4MA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></figure>
<h2 id="111-solr目录结构">1.1.1. Solr目录结构</h2>
<p>[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-WoPP5VHl-1575691051854)(solr-folder.png)]</p>
<ul>
<li>bin： 存放solr的可执行文件</li>
<li>contrib： 存放solr提供的扩展包</li>
<li>dist: Solr运行需要的jar包</li>
<li>docs: 文档目录</li>
<li>example: 官方提供的示例目录，配合官方示例教程，体验Solr功能</li>
<li>licences: 协议目录</li>
<li>server: solr工作的主目录，里面有默认的配置，将来创建的核心也会默认存储到此目录下，Solr Admin程序也在此目录下</li>
</ul>
<h2 id="12-solr入门">1.2. Solr入门</h2>
<h3 id="121-运行官方示例项目">1.2.1. 运行官方示例项目</h3>
<p>官方示例教程文档： https://lucene.apache.org/solr/guide/8_2/solr-tutorial.html</p>
<p>官方提供了三个示例教程，从Solr怎么简单使用，到怎么创建自己的搜索库，一步一步有引导，推荐跟着练习一遍。</p>
<h3 id="122-solr-admin-ui的使用">1.2.2. Solr Admin UI的使用</h3>
<p>Solr Admin是Solr给我们提供的一个方便查询和管理Solr的Web控制台应用，通过此应用，我们不需要编写任何程序就可以对Solr的很多功能进行操作。</p>
<p>默认访问地址： http://localhost:8983/solr</p>
<figure data-type="image" tabindex="2"><img src="https://img-blog.csdnimg.cn/2019120711592061.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzg2MjI4MA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></figure>
<h4 id="1221-简单查询">1.2.2.1. 简单查询</h4>
<h4 id="1222-按照某个字段搜索">1.2.2.2. 按照某个字段搜索</h4>
<h4 id="1223-搜索短语">1.2.2.3. 搜索短语</h4>
<h4 id="1224-搜索结果中只返回某些字段">1.2.2.4. 搜索结果中只返回某些字段</h4>
<h4 id="1225-搜索结果分页">1.2.2.5. 搜索结果分页</h4>
<figure data-type="image" tabindex="3"><img src="https://img-blog.csdnimg.cn/20191207115940813.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzg2MjI4MA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></figure>
<h4 id="1226-搜索结果高亮显示">1.2.2.6. 搜索结果高亮显示</h4>
<p>搜索参数设置：<br>
<img src="https://img-blog.csdnimg.cn/20191207115958930.png" alt="在这里插入图片描述"></p>
<p>搜索结果展示：</p>
<h4 id="1227-删除solr索引库中的数据">1.2.2.7. 删除Solr索引库中的数据</h4>
<figure data-type="image" tabindex="4"><img src="https://img-blog.csdnimg.cn/20191207120017879.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzg2MjI4MA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></figure>
<h1 id="2-深入solr">2. 深入Solr</h1>
<h2 id="21-solr配置文件">2.1. Solr配置文件</h2>
<h3 id="211-managed-schema文件">2.1.1. managed-schema文件</h3>
<p>managed-schema文件是Solr中core或collection的搜索库定义配置文件，里面配置了搜索库有哪些Field和FieldType等。</p>
<p>Solr的工作流程大体如下：</p>
<ul>
<li>创建用于存储被搜索数据的core或collection(集群模式)；</li>
<li>定义创建的core有哪些字段，以及哪些字段需要索引、哪些字段只存储，不需要索引。具体来说，就是通过Solr提供的SchemaAPI去管理core中的字段；</li>
<li>将数据导入到Solr中，在此过程中，Solr会对导入的数据建索引（所以一定要先定义Schema字段，再导入数据）；</li>
<li>调用Solr的HttpAPI搜索数据</li>
</ul>
<blockquote>
<p>managed-schema文件就是用来管理某个core中有哪些字段或者字段类型，可以把Solr当成是一个数据库，里面有字段、有字段类型、能存储、能查询（搜索）</p>
</blockquote>
<h4 id="2111-solr中常用的数据类型">2.1.1.1. Solr中常用的数据类型</h4>
<p>Solr中主要的数据类型由实现类和类型定义两部分组成， 数据类型是由Solr中定义好的Java类，类型定义是在managed-schema文件中定义的，数据类型不能直接使用，必须在managed-schema中定义后才能直接在字段中引用。</p>
<p>在managed-schema中定义字段类型时，会将数据类型和其他属性（如：是否多值、是否存储）组合到一起</p>
<p>默认的managed-schema配置文件中已经定义了一些常用的数据类型，如</p>
<pre><code class="language-xml">&lt;fieldType name=&quot;string&quot; class=&quot;solr.StrField&quot; sortMissingLast=&quot;true&quot; docValues=&quot;true&quot; /&gt;
&lt;fieldType name=&quot;strings&quot; class=&quot;solr.StrField&quot; sortMissingLast=&quot;true&quot; multiValued=&quot;true&quot; docValues=&quot;true&quot; /&gt;
&lt;fieldType name=&quot;boolean&quot; class=&quot;solr.BoolField&quot; sortMissingLast=&quot;true&quot;/&gt;
&lt;fieldType name=&quot;booleans&quot; class=&quot;solr.BoolField&quot; sortMissingLast=&quot;true&quot; multiValued=&quot;true&quot;/&gt;
&lt;fieldType name=&quot;pint&quot; class=&quot;solr.IntPointField&quot; docValues=&quot;true&quot;/&gt;
&lt;fieldType name=&quot;pfloat&quot; class=&quot;solr.FloatPointField&quot; docValues=&quot;true&quot;/&gt;
&lt;fieldType name=&quot;plong&quot; class=&quot;solr.LongPointField&quot; docValues=&quot;true&quot;/&gt;
&lt;fieldType name=&quot;pdouble&quot; class=&quot;solr.DoublePointField&quot; docValues=&quot;true&quot;/&gt;

&lt;fieldType name=&quot;pints&quot; class=&quot;solr.IntPointField&quot; docValues=&quot;true&quot; multiValued=&quot;true&quot;/&gt;
&lt;fieldType name=&quot;pfloats&quot; class=&quot;solr.FloatPointField&quot; docValues=&quot;true&quot; multiValued=&quot;true&quot;/&gt;
&lt;fieldType name=&quot;plongs&quot; class=&quot;solr.LongPointField&quot; docValues=&quot;true&quot; multiValued=&quot;true&quot;/&gt;
&lt;fieldType name=&quot;pdoubles&quot; class=&quot;solr.DoublePointField&quot; docValues=&quot;true&quot; multiValued=&quot;true&quot;/&gt;
&lt;fieldType name=&quot;random&quot; class=&quot;solr.RandomSortField&quot; indexed=&quot;true&quot;/&gt;
&lt;fieldType name=&quot;pdate&quot; class=&quot;solr.DatePointField&quot; docValues=&quot;true&quot;/&gt;
&lt;fieldType name=&quot;pdates&quot; class=&quot;solr.DatePointField&quot; docValues=&quot;true&quot; multiValued=&quot;true&quot;/&gt;
&lt;fieldType name=&quot;binary&quot; class=&quot;solr.BinaryField&quot;/&gt;
</code></pre>
<p>可以看到每个字段类型定义都由类型的实现类和若干个其他属性组合而成</p>
<p>除了上面定义的简单类型之外默认的managed-schema文件中还定义了一些特殊的字段类型</p>
<pre><code class="language-xml">&lt;!-- ignored类型本身是一个StrField类型，但是将stored和indexed都定义成了false，代表不存储、不建索引，实际上就是忽略数据中的此字段不处理 --&gt;
&lt;fieldType name=&quot;ignored&quot; stored=&quot;false&quot; indexed=&quot;false&quot; multiValued=&quot;true&quot; class=&quot;solr.StrField&quot; /&gt;
</code></pre>
<p>带分词功能的字段类型</p>
<pre><code class="language-xml">&lt;!-- text_general类型和上面的字段类型定义语法一样，本身数据solr.TextField类型，但是声明时通过内部的子标签指定了数据存储索引和数据搜索索引的分词器 --&gt;
&lt;fieldType name=&quot;text_general&quot; class=&quot;solr.TextField&quot; positionIncrementGap=&quot;100&quot; multiValued=&quot;true&quot;&gt;
    &lt;analyzer type=&quot;index&quot;&gt;
        &lt;tokenizer class=&quot;solr.StandardTokenizerFactory&quot;/&gt;
        &lt;filter class=&quot;solr.StopFilterFactory&quot; ignoreCase=&quot;true&quot; words=&quot;stopwords.txt&quot; /&gt;
        &lt;!-- in this example, we will only use synonyms at query time
        &lt;filter class=&quot;solr.SynonymGraphFilterFactory&quot; synonyms=&quot;index_synonyms.txt&quot; ignoreCase=&quot;true&quot; expand=&quot;false&quot;/&gt;
        &lt;filter class=&quot;solr.FlattenGraphFilterFactory&quot;/&gt;
        --&gt;
        &lt;filter class=&quot;solr.LowerCaseFilterFactory&quot;/&gt;
    &lt;/analyzer&gt;
    &lt;analyzer type=&quot;query&quot;&gt;
        &lt;tokenizer class=&quot;solr.StandardTokenizerFactory&quot;/&gt;
        &lt;filter class=&quot;solr.StopFilterFactory&quot; ignoreCase=&quot;true&quot; words=&quot;stopwords.txt&quot; /&gt;
        &lt;filter class=&quot;solr.SynonymGraphFilterFactory&quot; synonyms=&quot;synonyms.txt&quot; ignoreCase=&quot;true&quot; expand=&quot;true&quot;/&gt;
        &lt;filter class=&quot;solr.LowerCaseFilterFactory&quot;/&gt;
    &lt;/analyzer&gt;
&lt;/fieldType&gt;
</code></pre>
<h4 id="2112-添加字段类型定义fieldtype">2.1.1.2. 添加字段类型定义(FieldType)</h4>
<p>我们添加自定义字段类型的一个重要应用场景就是当我们的字段需要支持中文分词时，指定字段的实现类型是</p>
<p>solr.TextField，然后指定数据存储索引和搜索的索引分词器为支持中文的分词器。</p>
<p>语法参见上一章节 带分词功能的字段类型，中文分词器的配置参见配置中文分词器章节</p>
<h4 id="2113-solr中的无模式模式和字段类型自动推测">2.1.1.3. Solr中的&quot;无模式&quot;模式和字段类型自动推测</h4>
<p>我们在将数据导入到Solr中时，如果事先没有添加字段，Solr会根据数据的内容，自动推测应该用什么字段类型，并且自动生成field配置标签到当前core对应的managed-schema配置文件中</p>
<h4 id="2114-添加字段field">2.1.1.4. 添加字段(Field)</h4>
<p>前面说过managed-schema中主要就是定义了fieldType和field， 在以前老版本的solr中managed-schema的名字叫做schema.xml，可以直接手动编辑文件维护其中的字段定义。</p>
<p>而在新版本的Solr中，官方不建议手动修改此文件，改用Schema API的方式来维护字段</p>
<p>配置示例</p>
<pre><code class="language-xml">&lt;field name=&quot;price&quot; type=&quot;float&quot; default=&quot;0.0&quot; indexed=&quot;true&quot; stored=&quot;true&quot;/&gt;
</code></pre>
<p>定义字段需要指定字段的名称、类型(引用上面声明的fieldType的名称)、默认值、是否存储、是否索引等。</p>
<h4 id="2115-添加拷贝字段copy-field">2.1.1.5. 添加拷贝字段(Copy Field)</h4>
<p>Solr支持通过配置Copy Field，将多个字段拷贝到某个字段上，这样在搜索时，可以只用一个字段实现同时搜索多个字段内容的效果。</p>
<p>配置示例</p>
<pre><code class="language-xml">&lt;copyField source=&quot;cat&quot; dest=&quot;text&quot; maxChars=&quot;30000&quot; /&gt;
</code></pre>
<h4 id="2116-动态字段dynamic-fields">2.1.1.6. 动态字段(Dynamic Fields)</h4>
<p>Solr可以通过配置动态字段来实现对某些名称相似的字段统一管理，因为动态字段定义时名称中允许包含通配符。</p>
<p>动态字段和普通字段作用一致，唯一不同的就是名称中允许包含通配符，Solr在索引数据时会优先查找配置中定义的准确字段(通过field配置的字段)，如果没有找到匹配的，就从动态字段中找是否有匹配的，如果找到，就用动态字段的字段定义来索引数据。</p>
<p>配置示例</p>
<pre><code class="language-xml">&lt;dynamicField name=&quot;*_i&quot; type=&quot;int&quot; indexed=&quot;true&quot;  stored=&quot;true&quot;/&gt;
</code></pre>
<h3 id="212-schema-api">2.1.2. Schema API</h3>
<p>为了减少手动编辑managed-schema文件引入的错误，新版本的Solr提供了一套基于HTTP协议的Schema API来维护managed-schema文件</p>
<p>Schema API可以完成以下操作</p>
<h4 id="2121-add-field">2.1.2.1. add-field</h4>
<p>使用示例</p>
<pre><code class="language-bash">curl -X POST -H 'Content-type:application/json' --data-binary '{
  &quot;add-field&quot;:{
     &quot;name&quot;:&quot;sell_by&quot;,
     &quot;type&quot;:&quot;pdate&quot;,
     &quot;stored&quot;:true }
}' http://localhost:8983/api/cores/gettingstarted/schema
</code></pre>
<h4 id="2122-delete-field">2.1.2.2. delete-field</h4>
<p>使用示例</p>
<pre><code class="language-bash">curl -X POST -H 'Content-type:application/json' --data-binary '{
  &quot;delete-field&quot; : { &quot;name&quot;:&quot;sell_by&quot; }
}' http://localhost:8983/api/cores/gettingstarted/schema
</code></pre>
<h4 id="2123-replace-field">2.1.2.3. replace-field</h4>
<p>使用示例</p>
<pre><code class="language-bash">curl -X POST -H 'Content-type:application/json' --data-binary '{
  &quot;replace-field&quot;:{
     &quot;name&quot;:&quot;sell_by&quot;,
     &quot;type&quot;:&quot;date&quot;,
     &quot;stored&quot;:false }
}' http://localhost:8983/api/cores/gettingstarted/schema

</code></pre>
<h4 id="2124-add-dynamic-field">2.1.2.4. add-dynamic-field</h4>
<p>使用示例</p>
<pre><code class="language-bash">curl -X POST -H 'Content-type:application/json' --data-binary '{
  &quot;add-dynamic-field&quot;:{
     &quot;name&quot;:&quot;*_s&quot;,
     &quot;type&quot;:&quot;string&quot;,
     &quot;stored&quot;:true }
}' http://localhost:8983/api/cores/gettingstarted/schema

</code></pre>
<h4 id="2125-delete-dynamic-field">2.1.2.5. delete-dynamic-field</h4>
<p>使用示例</p>
<pre><code class="language-bash">curl -X POST -H 'Content-type:application/json' --data-binary '{
  &quot;delete-dynamic-field&quot;:{ &quot;name&quot;:&quot;*_s&quot; }
}' http://localhost:8983/api/cores/gettingstarted/schema

</code></pre>
<h4 id="2126-replace-dynamic-field">2.1.2.6. replace-dynamic-field</h4>
<p>使用示例</p>
<pre><code class="language-bash">curl -X POST -H 'Content-type:application/json' --data-binary '{
  &quot;replace-dynamic-field&quot;:{
     &quot;name&quot;:&quot;*_s&quot;,
     &quot;type&quot;:&quot;text_general&quot;,
     &quot;stored&quot;:false }
}' http://localhost:8983/solr/gettingstarted/schema

</code></pre>
<h4 id="2127-add-field-type">2.1.2.7. add-field-type</h4>
<p>使用示例</p>
<pre><code class="language-bash">curl -X POST -H 'Content-type:application/json' --data-binary '{
  &quot;add-field-type&quot;:{
     &quot;name&quot;:&quot;myNewTextField&quot;,
     &quot;class&quot;:&quot;solr.TextField&quot;,
     &quot;indexAnalyzer&quot;:{
        &quot;tokenizer&quot;:{
           &quot;class&quot;:&quot;solr.PathHierarchyTokenizerFactory&quot;,
           &quot;delimiter&quot;:&quot;/&quot; }},
     &quot;queryAnalyzer&quot;:{
        &quot;tokenizer&quot;:{
           &quot;class&quot;:&quot;solr.KeywordTokenizerFactory&quot; }}}
}' http://localhost:8983/api/cores/gettingstarted/schema

</code></pre>
<h4 id="2128-delete-field-type">2.1.2.8. delete-field-type</h4>
<p>使用示例</p>
<pre><code class="language-bash">curl -X POST -H 'Content-type:application/json' --data-binary '{
  &quot;delete-field-type&quot;:{ &quot;name&quot;:&quot;myNewTxtField&quot; }
}' http://localhost:8983/api/cores/gettingstarted/schema

</code></pre>
<h4 id="2129-replace-field-type">2.1.2.9. replace-field-type</h4>
<p>使用示例</p>
<pre><code class="language-bash">curl -X POST -H 'Content-type:application/json' --data-binary '{
  &quot;replace-field-type&quot;:{
     &quot;name&quot;:&quot;myNewTxtField&quot;,
     &quot;class&quot;:&quot;solr.TextField&quot;,
     &quot;positionIncrementGap&quot;:&quot;100&quot;,
     &quot;analyzer&quot;:{
        &quot;tokenizer&quot;:{
           &quot;class&quot;:&quot;solr.StandardTokenizerFactory&quot; }}}
}' http://localhost:8983/api/cores/gettingstarted/schema

</code></pre>
<h4 id="21210-add-copy-field">2.1.2.10. add-copy-field</h4>
<p>使用示例</p>
<pre><code class="language-bash">curl -X POST -H 'Content-type:application/json' --data-binary '{
  &quot;add-copy-field&quot;:{
     &quot;source&quot;:&quot;shelf&quot;,
     &quot;dest&quot;:[ &quot;location&quot;, &quot;catchall&quot; ]}
}' http://localhost:8983/api/cores/gettingstarted/schema

</code></pre>
<h4 id="21211-delete-copy-field">2.1.2.11. delete-copy-field</h4>
<p>使用示例</p>
<pre><code class="language-bash">curl -X POST -H 'Content-type:application/json' --data-binary '{
  &quot;delete-copy-field&quot;:{ &quot;source&quot;:&quot;shelf&quot;, &quot;dest&quot;:&quot;location&quot; }
}' http://localhost:8983/api/cores/gettingstarted/schema

</code></pre>
<h3 id="213-solrconfigxml文件">2.1.3. solrconfig.xml文件</h3>
<p>solrconfig.xml文件中定义了Solr core的数据目录、需要的第三方jar包、索引配置等。一般我们修改这个配置文件主要是配置中文分词器，因为Solr官方默认没有配置支持中文分词器的字段类型。</p>
<h2 id="22-core-vs-collection">2.2. Core VS Collection</h2>
<blockquote>
<p>在单机模式启动的Solr中一个搜索数据集叫做core，而在集群模式启动的Solr中搜索数据集的名称叫做collection</p>
</blockquote>
<h3 id="221-单机模式使用solr">2.2.1. 单机模式使用Solr</h3>
<h4 id="2211-以单机模式启动solr">2.2.1.1. 以单机模式启动Solr</h4>
<pre><code class="language-bash">bin/solr start  # linux、macos
bin\solr.cmd start # windows

</code></pre>
<p>启动成功后命令行会有如下输出</p>
<pre><code>Started Solr server on port 8983. Happy searching!

</code></pre>
<h4 id="2212-创建core核心">2.2.1.2. 创建core核心</h4>
<pre><code class="language-bash">bin/solr create -c 核心名  # linux、macos
bin\solr.cmd create -c 核心名 # windows

</code></pre>
<h4 id="2213-导入数据到solr">2.2.1.3. 导入数据到Solr</h4>
<blockquote>
<p>参见使用SpringBoot操作Solr章节</p>
</blockquote>
<h4 id="2214-停止单机版solr">2.2.1.4. 停止单机版Solr</h4>
<pre><code class="language-bash">bin/solr stop -all  # linux、macos
bin\solr.cmd stop -all # windows

</code></pre>
<h3 id="222-以集群模式启动solr">2.2.2. 以集群模式启动Solr</h3>
<h4 id="2221-以集群模式启动solr">2.2.2.1. 以集群模式启动Solr</h4>
<p>以集群模式启动Solr</p>
<pre><code class="language-bash">bin/solr start -c  # linux、macos
bin\solr.cmd start -c # windows

</code></pre>
<p>以集群模式启动后，如果没指定端口号，Solr默认会启动一个8983的节点；同时还会将内置的Zookeeper服务也启动起来，运行到9983端口上</p>
<p>向Solr集群中添加节点</p>
<pre><code class="language-bash">bin/solr start -c -p 节点端口号 -z localhost:9983 # linux、macos
bin\solr.cmd start -c -p 节点端口号 -z localhost:9983 # windows

</code></pre>
<p>-p参数指定节点运行的端口号，-z参数将新创建的节点添加到集群中</p>
<blockquote>
<p>Zookeeper是一个分布式管理框架，专门用来管理集群中各节点的状态。</p>
</blockquote>
<h4 id="2222-创建collection">2.2.2.2. 创建collection</h4>
<pre><code class="language-bash">bin/solr create -c collection名称 -s 2 -rf 2  # linux、macos
bin\solr.cmd create -c collection名称 -s 2 -rf 2 # windows

</code></pre>
<p>-c 参数指定创建的collection名称</p>
<p>-s 参数表示该collection要分布到几个分片上</p>
<p>-rf 参数表示每个分片有几个副本（用于容灾）</p>
<blockquote>
<p>Solr的集群模式和Reids集群类似，每个分片都有一个master节点和若干个slave节点组成，当master节点发生故障无法对外提供服务时，Solr集群会自动选举一个slave节点作为master对外服务。</p>
</blockquote>
<h4 id="2223-导入数据到solr集群">2.2.2.3. 导入数据到Solr集群</h4>
<blockquote>
<p>参见使用SpringBoot操作Solr章节</p>
</blockquote>
<h4 id="2224-停止solr集群">2.2.2.4. 停止Solr集群</h4>
<ul>
<li>
<p>停止集群中某个节点</p>
<pre><code class="language-bash">bin/solr stop -p 要停止的节点的端口号 # linux、macos
bin\solr.cmd stop -p 要停止的节点的端口号 # windows

</code></pre>
</li>
<li>
<p>停止整个Solr集群</p>
<pre><code class="language-bash">bin/solr stop -all # linux、macos
bin\solr.cmd stop -all # windows

</code></pre>
</li>
</ul>
<h2 id="23-配置中文分词器">2.3. 配置中文分词器</h2>
<p>分词器的作用在于将搜索的文本按照词组进行分割，可以大大的提高搜索的准确度。Solr对大部分的语言分词都进行了支持，其中也包括简体中文，但是遗憾的是截止最新的8.3.0版本，官方只是提供了中文分词的jar包，但是并没有对其进行配置。这就需要我们在用的时候配置中文分词器。</p>
<p>Solr官方提供了两种中文分词器：smartcn和icu</p>
<p>以smartcn分词器为例，配置方法如下：</p>
<h3 id="231-修改solrconfigxml配置文件添加中文分词器依赖">2.3.1. 修改solrconfig.xml配置文件，添加中文分词器依赖</h3>
<pre><code class="language-xml">......
&lt;lib dir=&quot;${solr.install.dir:../../../..}/dist/&quot; regex=&quot;solr-ltr-\d.*\.jar&quot; /&gt;
&lt;!-- 添加这行 --&gt;
&lt;lib dir=&quot;${solr.install.dir:../../../..}/contrib/analysis-extras/lucene-libs&quot; regex=&quot;.*\.jar&quot; /&gt;
......

</code></pre>
<h3 id="232-修改managed-schema配置文件新建fieldtype">2.3.2. 修改managed-schema配置文件，新建fieldType</h3>
<pre><code class="language-xml">&lt;!-- 添加自定义的支持中文分词的字段类型 --&gt;
&lt;fieldType name=&quot;text_zh&quot; class=&quot;solr.TextField&quot; positionIncrementGap=&quot;100&quot;&gt;
    &lt;analyzer type=&quot;index&quot;&gt;
        &lt;tokenizer class=&quot;org.apache.lucene.analysis.cn.smart.HMMChineseTokenizerFactory&quot;/&gt;
        &lt;filter class=&quot;solr.CJKWidthFilterFactory&quot;/&gt;
        &lt;filter class=&quot;solr.StopFilterFactory&quot;
                words=&quot;org/apache/lucene/analysis/cn/smart/stopwords.txt&quot;/&gt;
        &lt;filter class=&quot;solr.PorterStemFilterFactory&quot;/&gt;
        &lt;filter class=&quot;solr.LowerCaseFilterFactory&quot;/&gt;
    &lt;/analyzer&gt;
    &lt;analyzer type=&quot;query&quot;&gt;
        &lt;tokenizer class=&quot;org.apache.lucene.analysis.cn.smart.HMMChineseTokenizerFactory&quot;/&gt;
        &lt;filter class=&quot;solr.CJKWidthFilterFactory&quot;/&gt;
        &lt;filter class=&quot;solr.StopFilterFactory&quot;
                words=&quot;org/apache/lucene/analysis/cn/smart/stopwords.txt&quot;/&gt;
        &lt;filter class=&quot;solr.PorterStemFilterFactory&quot;/&gt;
        &lt;filter class=&quot;solr.LowerCaseFilterFactory&quot;/&gt;
    &lt;/analyzer&gt;
&lt;/fieldType&gt;

</code></pre>
<blockquote>
<p>在%solr安装目录%/server/configsets/_default/conf目录下有一份默认的配置文件managed-schema、solrconfig.xml。建议配置中文分词器时直接修改这个默认配置文件。因为在新建核心时，Solr会将这里的默认配置文件拷贝一份作为新核心的配置文件。</p>
</blockquote>
<h2 id="24-使用springboot操作solr">2.4. 使用SpringBoot操作Solr</h2>
<p>添加依赖</p>
<pre><code class="language-xml">&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-data-solr&lt;/artifactId&gt;
&lt;/dependency&gt;

</code></pre>
<p>application.yml中配置</p>
<pre><code class="language-yml">spring:
  data:
    solr:
      host: http://localhost:8983/solr/

</code></pre>
<p>通过Java代码导入数据到Solr和搜索</p>
<pre><code class="language-java">@Slf4j
@Service
public class SolrService {

    @Autowired
    private SolrClient solrClient;

    @Autowired
    private MessageDao messageDao;

    public static final int BATCH_SIZE = 10;

    public static final String CORE_NAME = &quot;lanou3g&quot;;

    /**
     * 将数据批量导入Solr中
     * @throws IOException
     * @throws SolrServerException
     */
    public void importData2Solr() throws IOException, SolrServerException {
        List&lt;Message&gt; messages = messageDao.loadAllMessage();
        List&lt;SolrInputDocument&gt; batchList = new ArrayList&lt;&gt;();
        messages.forEach((message -&gt; {

            // 将message对象转换成solr的inputDocument
            SolrInputDocument inDoc = new SolrInputDocument();
            inDoc.addField(&quot;id&quot;, message.getId());
            inDoc.addField(&quot;from_id&quot;, message.getFromId());
            inDoc.addField(&quot;to_id&quot;, message.getToId());
            inDoc.addField(&quot;subject&quot;, message.getSubject());
            inDoc.addField(&quot;content&quot;, message.getContent());
            inDoc.addField(&quot;createtime&quot;, message.getCreatetime());
            inDoc.addField(&quot;status&quot;, message.getStatus());
            inDoc.addField(&quot;attachment&quot;, message.getAttachment());

            batchList.add(inDoc);
            if(batchList.size() % BATCH_SIZE == 0) {
                try {
                    solrClient.add(CORE_NAME ,batchList);
                    batchList.clear();
                    log.info(&quot;批量导入&quot;+BATCH_SIZE+&quot;条到solr.&quot;);
                } catch (SolrServerException e) {
                    e.printStackTrace();
                } catch (IOException e) {
                    e.printStackTrace();
                }
            }
        }));

        if(batchList.size() &gt; 0) {
            solrClient.add(CORE_NAME, batchList);
            log.info(&quot;批量导入&quot;+batchList.size()+&quot;条到solr.&quot;);
            batchList.clear();
        }
        log.info(&quot;数据导入完成！&quot;);

        // 提交数据到solr
//        solrClient.commit();  // 无参的需要在配置文件中将核心名称添加到solr url中，参见application.yml
        solrClient.commit(CORE_NAME);
    }


    /**
     * 从Solr中分页搜索数据
     * @param q 搜索关键字
     * @param fields 限制返回的结果集中只允许哪个字段
     * @param start 分页参数
     * @param pageSize   分页参数
     */
    public void searchFromSolr(String q, String[] fields, int start, int pageSize) {

        SolrQuery params = new SolrQuery(q);
        if(fields != null &amp;&amp; fields.length &gt; 0) {
            params.setFields(fields);
        }

        // 分页参数
        params.setStart(start);
        params.setRows(pageSize);

        // 不设置按照哪个字段搜索的时候，默认搜索哪个字段
        // （一般会将系统中所有支持检索的字段通过CopyField的方式拷贝到一个统一的字段上，用于搜索，比如下面的keywords）
        params.setParam(&quot;df&quot;, &quot;keywords&quot;);

        // 设置搜索结果高亮显示
        params.setHighlight(true);
        // 设置往搜索结果中所有匹配关键字的地方添加指定的前缀和后缀（内容随意）
        params.setHighlightSimplePre(&quot;&lt;i class=\&quot;keywords\&quot;&gt;&quot;);
        params.setHighlightSimplePost(&quot;&lt;/i&gt;&quot;);

        try {
//            QueryResponse queryResp = solrClient.query(params);
            QueryResponse queryResp = solrClient.query(CORE_NAME, params);
            SolrDocumentList results = queryResp.getResults();
            long numFound = results.getNumFound();
            System.out.println(&quot;总共搜索到&quot;+numFound+&quot;条结果&quot;);
            results.forEach((solrDoc) -&gt; {
                StringBuilder sb = new StringBuilder();
                sb.append(&quot;{&quot;);
                Collection&lt;String&gt; fieldNames = solrDoc.getFieldNames();
                fieldNames.forEach((fieldName) -&gt; {
                    Object fieldValue = solrDoc.getFieldValue(fieldName);
                    sb.append(&quot;\&quot;&quot;+fieldName+&quot;\&quot;:\&quot;&quot;+fieldValue+&quot;\&quot;,&quot;);
                });
                if(sb.length() &gt; 1) {
                    sb.deleteCharAt(sb.length() - 1);
                }
                sb.append(&quot;}&quot;);

                System.out.println(&quot;row: &quot; + sb.toString());
            });
        } catch (SolrServerException e) {
            e.printStackTrace();
        } catch (IOException e) {
            e.printStackTrace();
        }

    }
}

</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[MongoDB基本操作]]></title>
        <id>https://yihuaikun.github.io/post/mongodb-ji-ben-cao-zuo</id>
        <link href="https://yihuaikun.github.io/post/mongodb-ji-ben-cao-zuo">
        </link>
        <updated>2019-12-12T12:29:32.000Z</updated>
        <content type="html"><![CDATA[<h1 id="mongodb基本操作">MongoDB基本操作</h1>
<h2 id="1robo-3t下载">1.robo 3T下载</h2>
<p>下载地址<a href="https://robomongo.org/download">robo 3T下载</a></p>
<p>robo 3T是练习mongodb命令的第三方工具,当然也可以直接再linux服务器练习</p>
<p>下载安装直接略(过于简单)</p>
<p>使用界面</p>
<figure data-type="image" tabindex="1"><img src="https://img-blog.csdnimg.cn/20191205195556646.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzg2MjI4MA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></figure>
<h2 id="2shell-简介">2.shell 简介</h2>
<p><strong>在此之前需要解决一个可能存在的操作环境问题</strong></p>
<p>敲命令是Backspace键不能回退,而是复制前面的内容</p>
<p>需要修改配置</p>
<figure data-type="image" tabindex="2"><img src="https://img-blog.csdnimg.cn/2019120519562184.png" alt="在这里插入图片描述"></figure>
<p>点击选项----&gt;会话设置----&gt;仿真设置----&gt;终端-----&gt;修改成linux</p>
<p>暂时我们所有的操作都先放在 test 数据库中进行(默认情况下，test  数据库为空，这里不显示空的数据库，此时执行可以选中 CentOS 菜单，右键单击点击 Open Shell，默认打开 test 数据库)，选中  test ，右键单击，选择 Open Shell，如下：</p>
<figure data-type="image" tabindex="3"><img src="https://img-blog.csdnimg.cn/20191205195646335.png" alt="在这里插入图片描述"></figure>
<p><strong>需要注意的是</strong>:</p>
<ol>
<li>use 命令，表示切换到某一个数据库中去，如果我们想切换到一个并不存在的数据库中去，系统就会自动的帮我们创建这个数据库。但是一个空的数据库系统并不会显示出来，往这个数据库中插入一条记录，我们就可以看到数据库存在了</li>
<li>直接在命令行通过 mongo 命令来启动 shell,，shell 会连接到 MongoDB 服务器的 test 数据库，并将数据库连接赋值给全局变量 db，我们将通过 db 这个变量实现很多功能，我们也可以查看 db 当前指向哪个数据库，直接使用 db 命令</li>
<li>在 MongoDB 中，我们插入的每一条记录都是一个 json 字符串，这个 json 字符串我们称作<strong>文档</strong>，多个文档可以组成一个<strong>集合</strong>，这个文档就类似于我们关系型数据库中的一行数据，而集合就类似于关系型数据库中的一张表，集合也不用专门去创建，直接输入向哪个集合中插入数据即可，此时集合就会被自动的创建出来了</li>
</ol>
<h2 id="3基本操作crud">3.基本操作(CRUD)</h2>
<h3 id="增">增</h3>
<p>在添加之前我们先来说说数据库的创建，上文我们提到了 use  命令，表示切换到某一个数据库中去，如果我们想切换到一个并不存在的数据库中去，系统就会自动的帮我们创建这个数据库。但是一个空的数据库系统并不会显示出来，往这个数据库中插入一条记录，我们就可以看到数据库存在了，如下：</p>
<figure data-type="image" tabindex="4"><img src="https://img-blog.csdnimg.cn/20191205195712752.png" alt="在这里插入图片描述"></figure>
<p>在 MongoDB 中，我们插入的每一条记录都是一个 json 字符串，这个 json 字符串我们称作<strong>文档</strong>，多个文档可以组成一个<strong>集合</strong>，这个文档就类似于我们关系型数据库中的一行数据，而集合就类似于关系型数据库中的一张表，集合也不用专门去创建，直接输入向哪个集合中插入数据即可，此时集合就会被自动的创建出来了。</p>
<p>当然我们也可以批量的添加文档，如下(<strong>批量添加一样也可以使用insert方法来完成</strong>)：</p>
<pre><code class="language-linux">db.wang_collect.insertMany([{x:1},{x:2},{x:3}])
</code></pre>
<p>如果在插入某一个文档时出错，则其后面的文档就会插入失败，而在其之前已经插入的文档则不受影响，如下：</p>
<h3 id="查">查</h3>
<p>数据添加成功之后我们再来看看查询，利用 <code>db.wang.find()</code> 方法我们可以查看所有文档(所有记录)，如果只查看一个文档(一条记录)，可以通过 <code>db.wang.findOne()</code> 命令，在查看之前我先用一个 for 循环多插入几条数据，如下：</p>
<pre><code class="language-linux">for(var i = 2;i&lt;100;i++)db.wang_collect.insert({x:i})
</code></pre>
<p>查找一个</p>
<pre><code class="language-linux">db.集合名.findOne()
</code></pre>
<p>查找全部</p>
<pre><code class="language-linux">db.wang_collect.find()
</code></pre>
<figure data-type="image" tabindex="5"><img src="https://img-blog.csdnimg.cn/20191205195741189.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzg2MjI4MA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></figure>
<h3 id="改">改</h3>
<p>update 操作可以用来更新数据，它接收两个参数，第一个参数表示更新条件，第二个参数表示要更新的数据，比如我将所有 x:1 的数据改为 x:999,如下：</p>
<pre><code class="language-linux">db.wang_collect.update({x:1},{x:999})
</code></pre>
<p>然后我们可以用db查看修改后的结果</p>
<h3 id="删">删</h3>
<p>remove 操作可以用来删除数据，如下：</p>
<pre><code class="language-linux">db.wang_collect.remove({x:999})
</code></pre>
<figure data-type="image" tabindex="6"><img src="https://img-blog.csdnimg.cn/20191205195751798.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzg2MjI4MA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></figure>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[MongoDB入门]]></title>
        <id>https://yihuaikun.github.io/post/mongodb-ru-men</id>
        <link href="https://yihuaikun.github.io/post/mongodb-ru-men">
        </link>
        <updated>2019-12-12T12:29:01.000Z</updated>
        <content type="html"><![CDATA[<h1 id="mongodb入门">MongoDB入门</h1>
<h2 id="什么是mongodb">什么是mongoDB?</h2>
<pre><code>	是一种面向文档的数据库管理系统,它是介于一个关系型数据库和非关系型数据库的之间的一种产品,MongoDb的功能丰富,它是一种支持类似JSON和BSON数据格式,既可以支持简单的数据格式,也可以存储复杂的数据类型.MongoDB最大的特点是它支持的查询语言非常强大,并且还支持数据建立索引.总体来说,mongDB是一款应用相当广泛的nosql型数据库
</code></pre>
<h2 id="mongodb的安装">MongoDB的安装</h2>
<h3 id="1下载地址是">1.下载地址是</h3>
<p><a href="https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-3.4.9.tgz">mongodb下载地址</a></p>
<pre><code class="language-linux">wget  https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-3.4.9.tgz
</code></pre>
<h3 id="2下载下来后解压缩">2.下载下来后解压缩</h3>
<pre><code class="language-linux">[root@iz2zejf0fjkrgyd7kckmfxz mongodb]# tar -zxvf mongodb-linux-x86_64-3.4.9.tgz
</code></pre>
<h3 id="3进入mongodb根目录创建db和logs">3.进入mongodb根目录创建db和logs</h3>
<pre><code class="language-linux">mkdir db
mkdir logs
</code></pre>
<h3 id="4进入bin目录配置配置文件在里面可能没有配置文件创建即可">4.进入bin目录配置配置文件,在,里面可能没有配置文件,创建即可</h3>
<pre><code class="language-linux">vim mongodb.conf
</code></pre>
<h3 id="5配置文件内容">5.配置文件内容</h3>
<pre><code class="language-linux">dbpath=/opt/mongodb/db #这个是自己的文件目录地址
logpath=/opt/mongodb/logs/mongodb.log #这个也是自己的文件目录地址
port=27017
fork=true
nohttpinterface=true
</code></pre>
<h3 id="6启动mongodb">6.启动mongodb</h3>
<pre><code class="language-linux">./mongod -f mongodb.conf
</code></pre>
<p>启动成功标识</p>
<figure data-type="image" tabindex="1"><img src="https://img-blog.csdnimg.cn/20191205170726651.png" alt="在这里插入图片描述"></figure>
<h3 id="7客户端访问">7.客户端访问</h3>
<pre><code class="language-linux">./mongo 
</code></pre>
<p>访问成功界面</p>
<figure data-type="image" tabindex="2"><img src="https://img-blog.csdnimg.cn/2019120517074226.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzg2MjI4MA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></figure>
<h3 id="8切换用户命令">8.切换用户命令</h3>
<pre><code class="language-linux">use 用户名
#退出客户端访问必须在admin用户下
use admin
db.shutdownServer()
</code></pre>
<h1 id="安全管理">安全管理</h1>
<p>上面我们所做的所有的操作都没有涉及到用户，我们在用 Oracle、MySQL 或者 MSSQL 时都有用户名密码需要登录才可以操作，MongoDB 中当然也有，但是需要我们手动添加。在添加之前，我们先来说说 MongoDB 中用户管理的几个特点：</p>
<blockquote>
<ol>
<li>MongoDB 中的账号是在某一个库里边进行设置的，我们在哪一个库里边进行设置，就要在哪一个库里边进行验证。</li>
<li>创建用户时，我们需要指定用户名、用户密码和用户角色，用户角色表示了该用户的权限。</li>
</ol>
</blockquote>
<h2 id="创建用户">创建用户</h2>
<p>给admin创建一个用户;</p>
<pre><code class="language-linux">use admin
db.createUser({user:&quot;root&quot;,pwd:&quot;123&quot;,roles:[{role:&quot;userAdminAnyDatabase&quot;,db:&quot;admin&quot;}]})
</code></pre>
<p>user 表示用户名，pwd 表示密码，role 表示角色，db 表示这个用户应用在哪个数据库上。用户的角色，有如下几种(<a href="https://www.cnblogs.com/shiyiwen/p/5552750.html">参考资料</a>)：</p>
<table>
<thead>
<tr>
<th style="text-align:left">角色名</th>
<th style="text-align:left">备注</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">Read</td>
<td style="text-align:left">允许用户读取指定数据库</td>
</tr>
<tr>
<td style="text-align:left">readWrite</td>
<td style="text-align:left">允许用户读写指定数据库</td>
</tr>
<tr>
<td style="text-align:left">dbAdmin</td>
<td style="text-align:left">允许用户在指定数据库中执行管理函数，如索引创建、删除，查看统计或访问system.profile</td>
</tr>
<tr>
<td style="text-align:left">userAdmin</td>
<td style="text-align:left">允许用户向system.users集合写入，可以找指定数据库里创建、删除和管理用户</td>
</tr>
<tr>
<td style="text-align:left">clusterAdmin</td>
<td style="text-align:left">只在admin数据库中可用，赋予用户所有分片和复制集相关函数的管理权限。</td>
</tr>
<tr>
<td style="text-align:left">readAnyDatabase</td>
<td style="text-align:left">只在admin数据库中可用，赋予用户所有数据库的读权限</td>
</tr>
<tr>
<td style="text-align:left">readWriteAnyDatabase</td>
<td style="text-align:left">只在admin数据库中可用，赋予用户所有数据库的读写权限</td>
</tr>
<tr>
<td style="text-align:left">userAdminAnyDatabase</td>
<td style="text-align:left">只在admin数据库中可用，赋予用户所有数据库的userAdmin权限</td>
</tr>
<tr>
<td style="text-align:left">dbAdminAnyDatabase</td>
<td style="text-align:left">只在admin数据库中可用，赋予用户所有数据库的dbAdmin权限。</td>
</tr>
<tr>
<td style="text-align:left">root</td>
<td style="text-align:left">只在admin数据库中可用。超级账号，超级权限</td>
</tr>
</tbody>
</table>
<p>创建用户成功后需要关闭mongodb服务,以security的方式启动.然后进入.查看dbs</p>
<pre><code class="language-linux">mongod -f /opt/mongodb/bin/mongodb.conf --auth
./mongo
show dbs
</code></pre>
<p>此时我们看到没有权限</p>
<figure data-type="image" tabindex="3"><img src="https://img-blog.csdnimg.cn/20191205170801226.png" alt="在这里插入图片描述"></figure>
<p>此时我们需要先进入到 admin 数据库中，然后授权，操作如下：</p>
<pre><code class="language-linux">use admin
db.auth(&quot;root&quot;,&quot;123&quot;)
</code></pre>
<figure data-type="image" tabindex="4"><img src="https://img-blog.csdnimg.cn/20191205170819702.png" alt="在这里插入图片描述"></figure>
<p>auth 方法执行结果返回 1 表示认证成功。然后再去执行 show dbs 就可以看到预期结果了。此时我再在 sang 库下创建一个只读用户，如下：</p>
<pre><code class="language-linux">use sang
db.createUser({user:&quot;readuser&quot;,pwd:&quot;123&quot;,roles:[{role:&quot;read&quot;,db:&quot;sang&quot;}]})
</code></pre>
<p>创建成功之后，再按照上面的流程进入到 sang 库中，使用 readuser 用户进行认证，认证成功之后一切我们就可以在 sang 库中执行查询操作了，步骤如下：</p>
<pre><code>use sang
db.auth(&quot;readuser&quot;,&quot;123&quot;)
</code></pre>
<p>做完这两步之后再执行查询操作就没有任何问题了，但是此时如果执行插入操作会提示没有权限，那我们可以创建一个有读写功能的用户执行相应的操作，这里就不再赘述。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[问题!!]]></title>
        <id>https://yihuaikun.github.io/post/wen-ti</id>
        <link href="https://yihuaikun.github.io/post/wen-ti">
        </link>
        <updated>2019-12-12T12:27:57.000Z</updated>
        <content type="html"><![CDATA[<h1 id="spring-cloud之eureka和ribbon使用问题">spring-cloud之eureka和ribbon使用问题</h1>
<h2 id="提供服务层端">提供服务层端</h2>
<pre><code class="language-java">@Service
@Slf4j
public class ContentServiceImpl implements ContentService {
    @Autowired
    private TbContentMapper tbContentMapper;
    @Autowired
    private CacheManagerService cacheManagerService;
    @Autowired
    private RedisTemplate redisTemplate;
    @Override
    public TaotaoResult getContent(Long cId) {
        List&lt;TbContent&gt; tbContents = cacheManagerService.getTbContentFromCache(cId);
        /**
         * 如果缓存中没有数据就从数据库中查
         * 查完之后将数据放入缓存,以便下次查找
         */
        if(tbContents == null){
            TbContentExample tbContentExample = new TbContentExample();
            TbContentExample.Criteria criteria = tbContentExample.createCriteria();
            criteria.andCategoryIdEqualTo(cId);
            tbContents = tbContentMapper.selectByExampleWithBLOBs(tbContentExample);
            /**
             * 将数据放入缓存
             */
            cacheManagerService.pushTbContent2Cache(cId,tbContents);
        }
        for(TbContent tbContent : tbContents){
            System.out.println(tbContent.toString());
        }
        return TaotaoResult.ok(tbContents);
    }
}

</code></pre>
<p>上面是提供服务的服务层</p>
<p>下面是提供服务的web控制层</p>
<pre><code class="language-java">@RestController
public class ContentController {
    @Autowired
    private ContentService  contentService;
    @GetMapping(&quot;/content/{cId}&quot;)
    public TaotaoResult getContent(@PathVariable Long cId){
        TaotaoResult taotaoResult = contentService.getContent(cId);
        return taotaoResult;
    }
}
</code></pre>
<p>我们把返回的结果封装在一个对象中,然后TaotaoResult的data字段我们在服务层用list存进去</p>
<h2 id="消费端">消费端</h2>
<pre><code class="language-java">@Service
@PropertySource(&quot;classpath:resources.properties&quot;)
public class AdServiceImpl implements AdService {
    /**
     * '
     * ribbon的方式
     */
    @Autowired
    private RestTemplate restTemplate;
    @Value(&quot;${INDEX_ADI_URL}&quot;)
    private String INDEX_ADI_URL;
    @Override
    public String getAdItemList() {
        //调用服务层的查询打广告的数据
        //发起http的Get请求
//        String result = HttpUtil.doGet(REST_BASE_URL+INDEX_ADI_URL);
        TaotaoResult taotaoResult = restTemplate.getForObject(&quot;http://taotao-rest-provider:8081&quot; + INDEX_ADI_URL, TaotaoResult.class);
//        System.out.println(taotaoResult.toString());
        String dataJson = JsonUtils.objectToJson(taotaoResult.getData());
        List&lt;TbContent&gt; contentList = JsonUtils.jsonToList(dataJson, TbContent.class);
        List&lt;ADItem&gt; adItemList = new ArrayList&lt;&gt;();
        for (TbContent tbContent : contentList) {
            ADItem adItem = new ADItem();
            adItem.setHeight(240);
            adItem.setWidth(670);
            adItem.setSrc(tbContent.getPic());
            adItem.setHeightB(240);
            adItem.setWidthB(550);
            adItem.setSrcB(tbContent.getPic2());
            adItem.setSrcB(tbContent.getPic2());
            adItem.setAlt(tbContent.getTitleDesc());
            adItem.setHref(tbContent.getUrl());
            adItemList.add(adItem);
        }
        return JsonUtils.objectToJson(adItemList);
    }
}
</code></pre>
<p>返回来的TaotaoResult的data字段还是ArrayList类型,但是ArrayLIst里面的每个是以LinkedhashMap存储的,就像下面这样拆分</p>
<pre><code class="language-java">		ArrayList arrayList = new ArrayList();
        LinkedHashMap map = new LinkedHashMap();
        map.put(&quot;id&quot;,101);
        map.put(&quot;name&quot;,&quot;张三&quot;);
        map.put(&quot;age&quot;,24);
        LinkedHashMap map1 = new LinkedHashMap();
        map1.put(&quot;id&quot;,102);
        map1.put(&quot;name&quot;,&quot;张三&quot;);
        map1.put(&quot;age&quot;,2);
        arrayList.add(map);
        arrayList.add(map1);
        System.out.println(arrayList);
</code></pre>
<p>所以直接用会报类型转换异常:LinkedHashMap  不能转换成某一个bean对象</p>
<p>正确的写法是</p>
<pre><code class="language-java">@Service
@PropertySource(&quot;classpath:resources.properties&quot;)
public class AdServiceImpl implements AdService {
    /**
     * '
     * ribbon的方式
     */
    @Autowired
    private RestTemplate restTemplate;
    @Value(&quot;${INDEX_ADI_URL}&quot;)
    private String INDEX_ADI_URL;
    @Override
    public String getAdItemList() {
        //调用服务层的查询打广告的数据
        //发起http的Get请求
//        String result = HttpUtil.doGet(REST_BASE_URL+INDEX_ADI_URL);
//        TaotaoResult taotaoResult = restTemplate.getForObject(&quot;http://taotao-rest-provider:8081&quot; + INDEX_ADI_URL, TaotaoResult.class);
//        String result = restTemplate.getForObject(&quot;http://taotao-rest-provider:8081&quot; + INDEX_ADI_URL, String.class);
        String result = restTemplate.getForObject(&quot;http://taotao-rest-provider&quot; + INDEX_ADI_URL, String.class);
        System.out.println(result);
        //        System.out.println(taotaoResult.toString());
        TaotaoResult taotaoResult = TaotaoResult.formatToList(result, TbContent.class);
//        System.out.println(taotaoResult.getData().getClass());
        List&lt;TbContent&gt; contentList = (List&lt;TbContent&gt;) taotaoResult.getData();
       /* String dataJson = JsonUtils.objectToJson(taotaoResult.getData());
        List&lt;TbContent&gt; contentList = JsonUtils.jsonToList(dataJson, TbContent.class);*/
        List&lt;ADItem&gt; adItemList = new ArrayList&lt;&gt;();
        for (TbContent tbContent : contentList) {
            ADItem adItem = new ADItem();
            adItem.setHeight(240);
            adItem.setWidth(670);
            adItem.setSrc(tbContent.getPic());
            adItem.setHeightB(240);
            adItem.setWidthB(550);
            adItem.setSrcB(tbContent.getPic2());
            adItem.setSrcB(tbContent.getPic2());
            adItem.setAlt(tbContent.getTitleDesc());
            adItem.setHref(tbContent.getUrl());
            adItemList.add(adItem);
        }
        return JsonUtils.objectToJson(adItemList);
    }
}

</code></pre>
<p><strong>直接把上面的data数据转换成json串,然后再转bean对象,还有就是服务不要写端口号,注册中心有端口号,不然没办法做客户端的负载均衡.</strong></p>
]]></content>
    </entry>
</feed>